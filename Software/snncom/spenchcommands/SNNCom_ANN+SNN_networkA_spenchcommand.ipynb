{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import math\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.cuda import amp\n",
    "import torch.distributed.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from spikingjelly.activation_based import layer,functional,neuron\n",
    "\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "np.int = int\n",
    "\n",
    "train_tb_writer = None\n",
    "te_tb_writer = None\n",
    "device = torch.device('cuda:3')\n",
    "deviceIds = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "\n",
    "    parser.add_argument('--device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--data-path', default='./data/', help='dataset')\n",
    "    parser.add_argument('--epochs', default=320, type=int, metavar='N',\n",
    "                        help='number of total epochs to pre-train')\n",
    "    parser.add_argument('-j', '--workers', default=16, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', default=0.0025, type=float, help='initial learning rate')\n",
    "\n",
    "    parser.add_argument('--print-freq', default=10, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='./logs', help='path where to save')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--tb', action='store_true',\n",
    "                        help='Use TensorBoard to record logs')\n",
    "    parser.add_argument(\n",
    "        \"--cache-dataset\",\n",
    "        dest=\"cache_dataset\",\n",
    "        help=\"Cache the datasets for quicker initialization. It also serializes the transforms\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(args=['--data-path','../data','--lr','0.1','-b','128','--epochs','100','--print-freq','100','--tb','--cache-dataset'])\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkA, self).__init__()\n",
    "        self.T = 10\n",
    "        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, padding=1) \n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.sn1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1)    \n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.sn2 = nn.ReLU()\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96, 128, kernel_size=3, padding=1) \n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.sn3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1) \n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.sn4 = nn.ReLU()\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1) \n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.sn5 = nn.ReLU()\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, padding=1) \n",
    "        self.bn8 = nn.BatchNorm2d(512)\n",
    "        self.sn8 = nn.ReLU()\n",
    "\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, padding=1) \n",
    "        self.bn10 = nn.BatchNorm2d(512)\n",
    "        self.sn10 = nn.ReLU()\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 256, kernel_size=3, padding=1) \n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "        self.sn11 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.conv13 = layer.SeqToANNContainer(nn.Conv2d(256, 128, kernel_size=3, padding=1)) \n",
    "        self.bn13 = layer.SeqToANNContainer(nn.BatchNorm2d(128))\n",
    "        self.sn13 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.pool5 = layer.SeqToANNContainer(nn.MaxPool2d(kernel_size=2, stride=2)) \n",
    "\n",
    "        self.linear1 = layer.SeqToANNContainer(nn.Linear(256, 35),nn.BatchNorm1d(35)) \n",
    "        self.sn14 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        T = self.T\n",
    "        \n",
    "        x = self.sn1(self.bn1(self.conv1(x)))\n",
    "        x = self.sn2(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.sn3(self.bn3(self.conv3(x)))\n",
    "        x = self.sn4(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.sn5(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.sn8(self.bn8(self.conv8(x)))\n",
    "        x = self.sn10(self.bn10(self.conv10(x)))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.bn11(self.conv11(x))\n",
    "  \n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.repeat(T, 1, 1, 1, 1)\n",
    "        x = self.sn11(x)\n",
    "        \n",
    "        x = self.sn13(self.bn13(self.conv13(x)))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = torch.flatten(x,2)\n",
    "\n",
    "        x = self.sn14(self.linear1(x))\n",
    "\n",
    "        return x.mean(0)\n",
    "    \n",
    "    def set_T(self, T):\n",
    "        self.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "max_test_acc1 = 0.\n",
    "test_acc5_at_max_test_acc1 = 0.\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "print(args)\n",
    "output_dir = os.path.join(args.output_dir, f'b_{args.batch_size}_lr{args.lr}')\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "output_dir += f'_{time_now.year}_{time_now.month}_{time_now.day}_{time_now.hour}__{time_now.minute}'\n",
    "\n",
    "\n",
    "if output_dir:\n",
    "    utils.mkdir(output_dir)\n",
    "\n",
    "class SpeechDataLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, mfccs, labels, label_dict):\n",
    "        self.mfccs = mfccs\n",
    "        self.labels = labels\n",
    "        self.label_dict = label_dict\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.mfccs)    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels[idx] in self.label_dict:\n",
    "            out_labels = self.label_dict.index(self.labels[idx])\n",
    "            return self.mfccs[idx], out_labels\n",
    "        else:\n",
    "            raise ValueError(\"Label not found in label_dict.\")\n",
    "\n",
    "def save_dataset(mfccs, labels, label_dict, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((mfccs, labels, label_dict), f)\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# 预处理和加载数据\n",
    "def preprocess_and_load_data():\n",
    "    train_audio_path = './data/SpeechCommands/speech_commands_v0.02/'\n",
    "    labels_dict = [label for label in os.listdir(train_audio_path) if label not in ['_background_noise_', 'LICENSE', 'README.md', 'validation_list.txt', 'testing_list.txt', '.DS_Store']]\n",
    "\n",
    "    a = torchaudio.datasets.SPEECHCOMMANDS('./data/', url='speech_commands_v0.02', \n",
    "                                            folder_in_archive='SpeechCommands', download=True)\n",
    "    \n",
    "    mfccs = []\n",
    "    labels = []\n",
    "    transform = nn.Sequential(\n",
    "        torchaudio.transforms.MFCC(log_mels=False)\n",
    "    )\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        if a[i][0].shape == (1, 16000):\n",
    "            waveform = a[i][0]\n",
    "            mfcc = transform(waveform)\n",
    "            mfccs.append(mfcc)\n",
    "            labels.append(a[i][2])\n",
    "\n",
    "    return mfccs, labels, labels_dict\n",
    "\n",
    "dataset_filename = 'processed_dataset.pkl'\n",
    "\n",
    "if os.path.exists(dataset_filename):\n",
    "    mfccs, labels, labels_dict = load_dataset(dataset_filename)\n",
    "else:\n",
    "    mfccs, labels, labels_dict = preprocess_and_load_data()\n",
    "    save_dataset(mfccs, labels, labels_dict, dataset_filename)\n",
    "\n",
    "dataset = SpeechDataLoader(mfccs, labels, labels_dict)\n",
    "traindata, testdata = random_split(dataset, [round(len(dataset) * 0.8), round(len(dataset) * 0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(traindata, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(testdata, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "print(\"Creating model\")\n",
    "\n",
    "net = NetworkA().to(device)\n",
    "functional.set_step_mode(net,step_mode='m')\n",
    "functional.set_backend(net, backend='cupy')\n",
    "net.to(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    args.start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc1 = checkpoint['max_test_acc1']\n",
    "    test_acc5_at_max_test_acc1 = checkpoint['test_acc5_at_max_test_acc1']\n",
    "\n",
    "\n",
    "if args.tb and utils.is_main_process():\n",
    "    purge_step_train = args.start_epoch\n",
    "    purge_step_te = args.start_epoch\n",
    "    train_tb_writer = SummaryWriter(output_dir + '_logs/train', purge_step=purge_step_train)\n",
    "    te_tb_writer = SummaryWriter(output_dir + '_logs/te', purge_step=purge_step_te)\n",
    "    with open(output_dir + '_logs/args.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "\n",
    "    with open(output_dir + '_logs/resluts.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('Results\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(net, criterion, data_loader, device, epoch, print_freq, scaler=None,lr = 1e-2):\n",
    "    net.train()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        functional.reset_net(net)\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        loss_s = loss.item()\n",
    "        if math.isnan(loss_s):\n",
    "            raise ValueError('loss is Nan')\n",
    "        acc1_s = acc1.item()\n",
    "        acc5_s = acc5.item()\n",
    "\n",
    "        metric_logger.update(loss=loss_s, lr=lr)\n",
    "\n",
    "        metric_logger.meters['acc1'].update(acc1_s, n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5_s, n=batch_size)\n",
    "        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n",
    "        \n",
    "    scheduler.step()\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    return metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, data_loader, device, print_freq=100, header='Test:'):\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    with torch.no_grad():\n",
    "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = net(image)\n",
    "            loss = criterion(output, target)\n",
    "            functional.reset_net(net)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    loss, acc1, acc5 = metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg\n",
    "    print(f' * Acc@1 = {acc1}, Acc@5 = {acc5}, loss = {loss}')\n",
    "    return loss, acc1, acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0]  [  0/597]  eta: 1:07:17  lr: 0.1  img/s: 18.9625497078659  loss: 3.5798 (3.5798)  acc1: 3.1250 (3.1250)  acc5: 11.7188 (11.7188)  time: 6.7624  data: 0.0122  max mem: 0\n",
      "Epoch: [0]  [100/597]  eta: 0:01:47  lr: 0.1  img/s: 859.840918409184  loss: 3.3620 (3.4443)  acc1: 7.8125 (6.8920)  acc5: 36.7188 (29.0919)  time: 0.1505  data: 0.0015  max mem: 0\n",
      "Epoch: [0]  [200/597]  eta: 0:01:10  lr: 0.1  img/s: 866.3274407826899  loss: 3.2512 (3.3688)  acc1: 10.1562 (8.4655)  acc5: 46.0938 (36.2484)  time: 0.1488  data: 0.0015  max mem: 0\n",
      "Epoch: [0]  [300/597]  eta: 0:00:48  lr: 0.1  img/s: 865.4001898857623  loss: 3.1638 (3.3144)  acc1: 12.5000 (9.4451)  acc5: 53.1250 (41.1207)  time: 0.1340  data: 0.0014  max mem: 0\n",
      "Epoch: [0]  [400/597]  eta: 0:00:30  lr: 0.1  img/s: 1016.5949551890053  loss: 3.1211 (3.2735)  acc1: 12.5000 (10.4037)  acc5: 61.7188 (45.4567)  time: 0.1413  data: 0.0014  max mem: 0\n",
      "Epoch: [0]  [500/597]  eta: 0:00:15  lr: 0.1  img/s: 857.4048594763622  loss: 3.0499 (3.2363)  acc1: 15.6250 (11.3897)  acc5: 70.3125 (49.7022)  time: 0.1507  data: 0.0014  max mem: 0\n",
      "Epoch: [0] Total time: 0:01:34\n",
      "Test:  [  0/150]  eta: 0:08:34  loss: 3.0752 (3.0752)  acc1: 19.5312 (19.5312)  acc5: 69.5312 (69.5312)  time: 3.4269  data: 0.0075  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:04  loss: 3.0763 (3.0830)  acc1: 17.9688 (19.4539)  acc5: 70.3125 (69.0517)  time: 0.0459  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:14\n",
      " * Acc@1 = 19.58173908480771, Acc@5 = 69.14932648541637, loss = 3.081288046836853\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:01:49 max_test_acc1 19.58173908480771 test_acc5_at_max_test_acc1 69.14932648541637 train_acc1 12.76682172556704 train_acc5 12.76682172556704\n",
      "Epoch: [1]  [  0/597]  eta: 0:01:21  lr: 0.1  img/s: 1018.1874787826605  loss: 2.9821 (2.9821)  acc1: 25.0000 (25.0000)  acc5: 75.7812 (75.7812)  time: 0.1357  data: 0.0100  max mem: 0\n",
      "Epoch: [1]  [100/597]  eta: 0:01:24  lr: 0.1  img/s: 749.3592094243761  loss: 2.9386 (2.9767)  acc1: 31.2500 (28.0399)  acc5: 82.0312 (79.8809)  time: 0.1736  data: 0.0014  max mem: 0\n",
      "Epoch: [1]  [200/597]  eta: 0:01:08  lr: 0.1  img/s: 740.8385935861346  loss: 2.9121 (2.9543)  acc1: 38.2812 (31.7125)  acc5: 85.1562 (81.7125)  time: 0.1739  data: 0.0015  max mem: 0\n",
      "Epoch: [1]  [300/597]  eta: 0:00:51  lr: 0.1  img/s: 669.024698804189  loss: 2.8534 (2.9323)  acc1: 45.3125 (35.4729)  acc5: 89.8438 (83.3835)  time: 0.1788  data: 0.0015  max mem: 0\n",
      "Epoch: [1]  [400/597]  eta: 0:00:35  lr: 0.1  img/s: 646.146574539555  loss: 2.8346 (2.9132)  acc1: 50.7812 (38.9943)  acc5: 89.8438 (84.7159)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [1]  [500/597]  eta: 0:00:17  lr: 0.1  img/s: 644.2871019190451  loss: 2.8087 (2.8967)  acc1: 57.8125 (42.0565)  acc5: 91.4062 (85.7551)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [1] Total time: 0:01:51\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.7671 (2.7671)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.0509  data: 0.0026  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.8163 (2.8184)  acc1: 58.5938 (58.7020)  acc5: 90.6250 (90.6405)  time: 0.0558  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:08\n",
      " * Acc@1 = 59.007285497343396, Acc@5 = 90.88526652340269, loss = 2.8151699749628705\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:03:49 max_test_acc1 59.007285497343396 test_acc5_at_max_test_acc1 90.88526652340269 train_acc1 44.77101487206779 train_acc5 44.77101487206779\n",
      "Epoch: [2]  [  0/597]  eta: 0:01:54  lr: 0.1  img/s: 735.3388741268319  loss: 2.7474 (2.7474)  acc1: 65.6250 (65.6250)  acc5: 95.3125 (95.3125)  time: 0.1917  data: 0.0176  max mem: 0\n",
      "Epoch: [2]  [100/597]  eta: 0:01:34  lr: 0.1  img/s: 650.3852514821931  loss: 2.7567 (2.7722)  acc1: 65.6250 (64.4183)  acc5: 93.7500 (93.2085)  time: 0.1949  data: 0.0017  max mem: 0\n",
      "Epoch: [2]  [200/597]  eta: 0:01:17  lr: 0.1  img/s: 648.0434064136718  loss: 2.7732 (2.7671)  acc1: 68.7500 (65.8621)  acc5: 92.9688 (93.3497)  time: 0.1988  data: 0.0015  max mem: 0\n",
      "Epoch: [2]  [300/597]  eta: 0:00:57  lr: 0.1  img/s: 716.7749813420132  loss: 2.7490 (2.7638)  acc1: 70.3125 (66.8786)  acc5: 95.3125 (93.4879)  time: 0.1757  data: 0.0015  max mem: 0\n",
      "Epoch: [2]  [400/597]  eta: 0:00:38  lr: 0.1  img/s: 644.7296732223939  loss: 2.7202 (2.7543)  acc1: 77.3438 (68.5941)  acc5: 96.0938 (94.1474)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [2]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 644.6452901961537  loss: 2.7152 (2.7478)  acc1: 74.2188 (69.8369)  acc5: 96.8750 (94.5047)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [2] Total time: 0:01:56\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.8422 (2.8422)  acc1: 58.5938 (58.5938)  acc5: 94.5312 (94.5312)  time: 0.0626  data: 0.0030  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.8440 (2.8460)  acc1: 57.8125 (59.1352)  acc5: 91.4062 (90.4162)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 59.295560564770625, Acc@5 = 90.41354368677604, loss = 2.844577514330546\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:05:55 max_test_acc1 59.295560564770625 test_acc5_at_max_test_acc1 90.41354368677604 train_acc1 71.11183908789059 train_acc5 71.11183908789059\n",
      "Epoch: [3]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 691.5088977505744  loss: 2.7126 (2.7126)  acc1: 77.3438 (77.3438)  acc5: 96.0938 (96.0938)  time: 0.2035  data: 0.0184  max mem: 0\n",
      "Epoch: [3]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 647.9448595480192  loss: 2.6869 (2.6891)  acc1: 82.0312 (80.5152)  acc5: 98.4375 (98.1590)  time: 0.1960  data: 0.0014  max mem: 0\n",
      "Epoch: [3]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 647.5501905726829  loss: 2.6764 (2.6865)  acc1: 83.5938 (81.4949)  acc5: 98.4375 (98.1421)  time: 0.1988  data: 0.0015  max mem: 0\n",
      "Epoch: [3]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 644.8582256009014  loss: 2.6706 (2.6846)  acc1: 83.5938 (82.1325)  acc5: 98.4375 (98.1728)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [3]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.4418097929802  loss: 2.6775 (2.6831)  acc1: 82.8125 (82.5086)  acc5: 98.4375 (98.1842)  time: 0.2002  data: 0.0017  max mem: 0\n",
      "Epoch: [3]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7652910368085  loss: 2.6720 (2.6820)  acc1: 84.3750 (82.7143)  acc5: 98.4375 (98.1677)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [3] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6758 (2.6758)  acc1: 82.8125 (82.8125)  acc5: 98.4375 (98.4375)  time: 0.0530  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6882 (2.6904)  acc1: 82.0312 (82.2014)  acc5: 97.6562 (97.5944)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 82.24749724828345, Acc@5 = 97.66235127627235, loss = 2.6917857281366984\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:08:03 max_test_acc1 82.24749724828345 test_acc5_at_max_test_acc1 97.66235127627235 train_acc1 83.16582585217122 train_acc5 83.16582585217122\n",
      "Epoch: [4]  [  0/597]  eta: 0:01:58  lr: 0.1  img/s: 697.7342383965669  loss: 2.6796 (2.6796)  acc1: 84.3750 (84.3750)  acc5: 98.4375 (98.4375)  time: 0.1982  data: 0.0148  max mem: 0\n",
      "Epoch: [4]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 648.668233349564  loss: 2.6561 (2.6637)  acc1: 87.5000 (86.5408)  acc5: 98.4375 (98.6773)  time: 0.1977  data: 0.0018  max mem: 0\n",
      "Epoch: [4]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.1803268000685  loss: 2.6615 (2.6634)  acc1: 87.5000 (86.6604)  acc5: 98.4375 (98.7212)  time: 0.1989  data: 0.0016  max mem: 0\n",
      "Epoch: [4]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.2190679496548  loss: 2.6636 (2.6615)  acc1: 87.5000 (87.1262)  acc5: 98.4375 (98.7256)  time: 0.1994  data: 0.0015  max mem: 0\n",
      "Epoch: [4]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.8032360811518  loss: 2.6603 (2.6621)  acc1: 86.7188 (87.2701)  acc5: 98.4375 (98.6577)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [4]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.8435091765158  loss: 2.6559 (2.6616)  acc1: 88.2812 (87.3675)  acc5: 98.4375 (98.6574)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [4] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.7177 (2.7177)  acc1: 83.5938 (83.5938)  acc5: 95.3125 (95.3125)  time: 0.0560  data: 0.0027  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6875 (2.6892)  acc1: 83.5938 (84.0347)  acc5: 97.6562 (97.6176)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 84.33356045994333, Acc@5 = 97.73573038419204, loss = 2.6876753918329874\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:10:11 max_test_acc1 84.33356045994333 test_acc5_at_max_test_acc1 97.73573038419204 train_acc1 87.48214636773119 train_acc5 87.48214636773119\n",
      "Epoch: [5]  [  0/597]  eta: 0:01:58  lr: 0.1  img/s: 704.1742679810916  loss: 2.6675 (2.6675)  acc1: 88.2812 (88.2812)  acc5: 98.4375 (98.4375)  time: 0.1981  data: 0.0163  max mem: 0\n",
      "Epoch: [5]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 648.9269727228004  loss: 2.6317 (2.6435)  acc1: 92.1875 (90.1841)  acc5: 99.2188 (99.0563)  time: 0.1966  data: 0.0018  max mem: 0\n",
      "Epoch: [5]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 649.4238600294186  loss: 2.6376 (2.6407)  acc1: 90.6250 (90.7183)  acc5: 99.2188 (99.1682)  time: 0.1987  data: 0.0017  max mem: 0\n",
      "Epoch: [5]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 644.9341420373527  loss: 2.6380 (2.6396)  acc1: 90.6250 (91.0688)  acc5: 99.2188 (99.1928)  time: 0.1995  data: 0.0016  max mem: 0\n",
      "Epoch: [5]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.0892248075966  loss: 2.6349 (2.6392)  acc1: 91.4062 (91.2387)  acc5: 99.2188 (99.1467)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [5]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6716091366047  loss: 2.6322 (2.6384)  acc1: 92.1875 (91.3563)  acc5: 100.0000 (99.1922)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [5] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6621 (2.6621)  acc1: 84.3750 (84.3750)  acc5: 98.4375 (98.4375)  time: 0.0566  data: 0.0033  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6558 (2.6558)  acc1: 89.8438 (88.9697)  acc5: 99.2188 (98.5999)  time: 0.0608  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 88.90927197482202, Acc@5 = 98.57959012526862, loss = 2.6559824657440188\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:12:19 max_test_acc1 88.90927197482202 test_acc5_at_max_test_acc1 98.57959012526862 train_acc1 91.39094542237368 train_acc5 91.39094542237368\n",
      "Epoch: [6]  [  0/597]  eta: 0:01:58  lr: 0.1  img/s: 699.4477489824952  loss: 2.6246 (2.6246)  acc1: 92.1875 (92.1875)  acc5: 100.0000 (100.0000)  time: 0.1992  data: 0.0162  max mem: 0\n",
      "Epoch: [6]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 655.8964387377372  loss: 2.6293 (2.6301)  acc1: 93.7500 (93.0770)  acc5: 99.2188 (99.4199)  time: 0.1968  data: 0.0016  max mem: 0\n",
      "Epoch: [6]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 653.7256857855361  loss: 2.6281 (2.6301)  acc1: 92.9688 (93.0698)  acc5: 99.2188 (99.4520)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [6]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.0635510335513  loss: 2.6272 (2.6309)  acc1: 92.9688 (93.0077)  acc5: 100.0000 (99.4212)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [6]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.8528036821901  loss: 2.6310 (2.6311)  acc1: 92.1875 (92.8752)  acc5: 99.2188 (99.4292)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [6]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6375497402819  loss: 2.6307 (2.6316)  acc1: 91.4062 (92.7442)  acc5: 99.2188 (99.4090)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [6] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6388 (2.6388)  acc1: 88.2812 (88.2812)  acc5: 99.2188 (99.2188)  time: 0.0577  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6476 (2.6467)  acc1: 89.0625 (90.4935)  acc5: 99.2188 (98.7469)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 90.56030190261544, Acc@5 = 98.78924471932491, loss = 2.6461846272150678\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:14:27 max_test_acc1 90.56030190261544 test_acc5_at_max_test_acc1 98.78924471932491 train_acc1 92.73275240738364 train_acc5 92.73275240738364\n",
      "Epoch: [7]  [  0/597]  eta: 0:01:49  lr: 0.1  img/s: 761.0343369967212  loss: 2.6230 (2.6230)  acc1: 92.1875 (92.1875)  acc5: 100.0000 (100.0000)  time: 0.1831  data: 0.0149  max mem: 0\n",
      "Epoch: [7]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 655.2344240666766  loss: 2.6297 (2.6279)  acc1: 93.7500 (93.8041)  acc5: 99.2188 (99.4817)  time: 0.1974  data: 0.0018  max mem: 0\n",
      "Epoch: [7]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 649.7468911757195  loss: 2.6268 (2.6272)  acc1: 93.7500 (93.9754)  acc5: 99.2188 (99.4908)  time: 0.1986  data: 0.0015  max mem: 0\n",
      "Epoch: [7]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.1974237906395  loss: 2.6269 (2.6278)  acc1: 93.7500 (93.8902)  acc5: 99.2188 (99.4783)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [7]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.2592681038983  loss: 2.6292 (2.6280)  acc1: 92.9688 (93.8630)  acc5: 99.2188 (99.4681)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [7]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.1495941309716  loss: 2.6368 (2.6289)  acc1: 92.9688 (93.7687)  acc5: 99.2188 (99.4402)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [7] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6260 (2.6260)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0613  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6401 (2.6428)  acc1: 91.4062 (91.4449)  acc5: 99.2188 (98.9171)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 91.44609256290316, Acc@5 = 98.9255202054615, loss = 2.642827838261922\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:16:35 max_test_acc1 91.44609256290316 test_acc5_at_max_test_acc1 98.9255202054615 train_acc1 93.58055428039634 train_acc5 93.58055428039634\n",
      "Epoch: [8]  [  0/597]  eta: 0:02:00  lr: 0.1  img/s: 690.7979695692733  loss: 2.6342 (2.6342)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.2013  data: 0.0160  max mem: 0\n",
      "Epoch: [8]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 647.951897615881  loss: 2.6270 (2.6275)  acc1: 93.7500 (94.2605)  acc5: 99.2188 (99.4740)  time: 0.1974  data: 0.0014  max mem: 0\n",
      "Epoch: [8]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.7231002161722  loss: 2.6251 (2.6268)  acc1: 95.3125 (94.2669)  acc5: 100.0000 (99.5336)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [8]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.0524908483975  loss: 2.6267 (2.6270)  acc1: 92.9688 (94.1757)  acc5: 100.0000 (99.5198)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [8]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.2700920795727  loss: 2.6271 (2.6272)  acc1: 94.5312 (94.1124)  acc5: 100.0000 (99.5285)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [8]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.411610360117  loss: 2.6315 (2.6283)  acc1: 93.7500 (94.0026)  acc5: 99.2188 (99.4948)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [8] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6540 (2.6540)  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.0643  data: 0.0050  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6560 (2.6514)  acc1: 90.6250 (91.0659)  acc5: 97.6562 (98.5535)  time: 0.0612  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 91.07395565845324, Acc@5 = 98.55862466626287, loss = 2.6518406232198077\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:18:43 max_test_acc1 91.44609256290316 test_acc5_at_max_test_acc1 98.9255202054615 train_acc1 93.96055821267116 train_acc5 93.96055821267116\n",
      "Epoch: [9]  [  0/597]  eta: 0:01:47  lr: 0.1  img/s: 768.9037722580987  loss: 2.6222 (2.6222)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1805  data: 0.0140  max mem: 0\n",
      "Epoch: [9]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 649.6965683658441  loss: 2.6226 (2.6253)  acc1: 93.7500 (94.3224)  acc5: 100.0000 (99.5900)  time: 0.1975  data: 0.0017  max mem: 0\n",
      "Epoch: [9]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.3666314024994  loss: 2.6254 (2.6252)  acc1: 94.5312 (94.4691)  acc5: 99.2188 (99.5919)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [9]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.785424585803  loss: 2.6252 (2.6255)  acc1: 94.5312 (94.4145)  acc5: 100.0000 (99.5536)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [9]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.9651334750115  loss: 2.6291 (2.6265)  acc1: 93.7500 (94.2858)  acc5: 100.0000 (99.5324)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [9]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.3195777431871  loss: 2.6268 (2.6271)  acc1: 92.9688 (94.1601)  acc5: 99.2188 (99.5337)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [9] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6529 (2.6529)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0549  data: 0.0051  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6517 (2.6484)  acc1: 92.1875 (92.0096)  acc5: 98.4375 (98.6618)  time: 0.0612  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 92.15367681744326, Acc@5 = 98.76303789506788, loss = 2.6472925662994387\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:20:52 max_test_acc1 92.15367681744326 test_acc5_at_max_test_acc1 98.76303789506788 train_acc1 94.145318743477 train_acc5 94.145318743477\n",
      "Epoch: [10]  [  0/597]  eta: 0:01:57  lr: 0.1  img/s: 711.5321260443615  loss: 2.6306 (2.6306)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.1968  data: 0.0169  max mem: 0\n",
      "Epoch: [10]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 648.3368781050968  loss: 2.6162 (2.6199)  acc1: 94.5312 (95.0495)  acc5: 100.0000 (99.6210)  time: 0.1971  data: 0.0017  max mem: 0\n",
      "Epoch: [10]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 647.83930687454  loss: 2.6157 (2.6185)  acc1: 96.0938 (95.3047)  acc5: 100.0000 (99.6657)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [10]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 644.3945939457955  loss: 2.6140 (2.6176)  acc1: 96.0938 (95.4475)  acc5: 100.0000 (99.6963)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [10]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.1927859457812  loss: 2.6185 (2.6173)  acc1: 95.3125 (95.4508)  acc5: 99.2188 (99.7078)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [10]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.8520870860427  loss: 2.6169 (2.6174)  acc1: 96.0938 (95.4139)  acc5: 99.2188 (99.6897)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [10] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6247 (2.6247)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0567  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6289 (2.6309)  acc1: 93.7500 (93.2782)  acc5: 99.2188 (99.0022)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.29105299059853, Acc@5 = 99.05655432674668, loss = 2.6307269875208537\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:23:00 max_test_acc1 93.29105299059853 test_acc5_at_max_test_acc1 99.05655432674668 train_acc1 95.43340103518312 train_acc5 95.43340103518312\n",
      "Epoch: [11]  [  0/597]  eta: 0:01:51  lr: 0.1  img/s: 742.8477307947753  loss: 2.6212 (2.6212)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1873  data: 0.0150  max mem: 0\n",
      "Epoch: [11]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 654.1151690081986  loss: 2.6118 (2.6142)  acc1: 96.0938 (95.6683)  acc5: 100.0000 (99.7447)  time: 0.1984  data: 0.0015  max mem: 0\n",
      "Epoch: [11]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 654.4053925243328  loss: 2.6119 (2.6131)  acc1: 95.3125 (95.9266)  acc5: 100.0000 (99.7901)  time: 0.1986  data: 0.0015  max mem: 0\n",
      "Epoch: [11]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.4843269821757  loss: 2.6115 (2.6136)  acc1: 96.0938 (95.8679)  acc5: 100.0000 (99.7612)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [11]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.9418896175428  loss: 2.6119 (2.6136)  acc1: 96.0938 (95.9165)  acc5: 100.0000 (99.7487)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [11]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.1364148707855  loss: 2.6123 (2.6137)  acc1: 96.8750 (95.9596)  acc5: 100.0000 (99.7443)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [11] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6207 (2.6207)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.0662  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6313 (2.6325)  acc1: 92.9688 (93.2472)  acc5: 99.2188 (99.0331)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.31201845000416, Acc@5 = 99.06179569159809, loss = 2.631949798266093\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:25:08 max_test_acc1 93.31201845000416 test_acc5_at_max_test_acc1 99.06179569159809 train_acc1 95.91037148540191 train_acc5 95.91037148540191\n",
      "Epoch: [12]  [  0/597]  eta: 0:01:53  lr: 0.1  img/s: 734.3089708448908  loss: 2.6138 (2.6138)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.1901  data: 0.0158  max mem: 0\n",
      "Epoch: [12]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 653.9900696295358  loss: 2.6087 (2.6133)  acc1: 96.0938 (96.1711)  acc5: 100.0000 (99.8066)  time: 0.1984  data: 0.0014  max mem: 0\n",
      "Epoch: [12]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.3901227768881  loss: 2.6106 (2.6128)  acc1: 96.0938 (96.1171)  acc5: 100.0000 (99.7979)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [12]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.0548231706657  loss: 2.6156 (2.6126)  acc1: 95.3125 (96.0366)  acc5: 100.0000 (99.8079)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [12]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.0093014203228  loss: 2.6104 (2.6126)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (99.7993)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [12]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.9566105327398  loss: 2.6103 (2.6126)  acc1: 96.0938 (96.0392)  acc5: 100.0000 (99.7988)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [12] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6528 (2.6528)  acc1: 93.7500 (93.7500)  acc5: 96.8750 (96.8750)  time: 0.0595  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6323 (2.6313)  acc1: 92.9688 (93.5412)  acc5: 99.2188 (98.9171)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.63698307039154, Acc@5 = 99.03034750248965, loss = 2.6299222040176393\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:27:16 max_test_acc1 93.63698307039154 test_acc5_at_max_test_acc1 99.03034750248965 train_acc1 96.01520015644323 train_acc5 96.01520015644323\n",
      "Epoch: [13]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 650.9025254300991  loss: 2.6099 (2.6099)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2115  data: 0.0148  max mem: 0\n",
      "Epoch: [13]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 677.9212386843903  loss: 2.6085 (2.6108)  acc1: 96.8750 (96.2949)  acc5: 100.0000 (99.8608)  time: 0.1980  data: 0.0015  max mem: 0\n",
      "Epoch: [13]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 647.447108821387  loss: 2.6082 (2.6107)  acc1: 96.8750 (96.3270)  acc5: 100.0000 (99.8834)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [13]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.6445161422017  loss: 2.6106 (2.6111)  acc1: 96.8750 (96.2962)  acc5: 100.0000 (99.8780)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [13]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.6027199890499  loss: 2.6097 (2.6113)  acc1: 96.8750 (96.2652)  acc5: 100.0000 (99.8675)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [13]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6476123691633  loss: 2.6087 (2.6115)  acc1: 96.0938 (96.2388)  acc5: 100.0000 (99.8425)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [13] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6220 (2.6220)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0529  data: 0.0036  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6321 (2.6315)  acc1: 92.1875 (93.4947)  acc5: 98.4375 (98.9325)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.29105299059853, Acc@5 = 98.90979611090728, loss = 2.6322977256774904\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:29:24 max_test_acc1 93.63698307039154 test_acc5_at_max_test_acc1 99.03034750248965 train_acc1 96.20782283914673 train_acc5 96.20782283914673\n",
      "Epoch: [14]  [  0/597]  eta: 0:01:49  lr: 0.1  img/s: 756.9824977968909  loss: 2.6092 (2.6092)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1833  data: 0.0142  max mem: 0\n",
      "Epoch: [14]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 686.4145611132562  loss: 2.6084 (2.6106)  acc1: 96.0938 (96.3026)  acc5: 100.0000 (99.8530)  time: 0.1978  data: 0.0015  max mem: 0\n",
      "Epoch: [14]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.0966028916646  loss: 2.6078 (2.6101)  acc1: 97.6562 (96.3075)  acc5: 100.0000 (99.8678)  time: 0.1986  data: 0.0015  max mem: 0\n",
      "Epoch: [14]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.1061821319097  loss: 2.6094 (2.6102)  acc1: 96.8750 (96.3429)  acc5: 100.0000 (99.8650)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [14]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.2511700243019  loss: 2.6098 (2.6103)  acc1: 96.8750 (96.3431)  acc5: 100.0000 (99.8675)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [14]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.1371370158362  loss: 2.6084 (2.6103)  acc1: 96.8750 (96.3261)  acc5: 100.0000 (99.8628)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [14] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6751 (2.6751)  acc1: 88.2812 (88.2812)  acc5: 96.8750 (96.8750)  time: 0.0531  data: 0.0032  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6291 (2.6322)  acc1: 93.7500 (93.8583)  acc5: 99.2188 (99.0022)  time: 0.0607  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.73132763811675, Acc@5 = 98.94648566486713, loss = 2.6323320643107095\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:31:32 max_test_acc1 93.73132763811675 test_acc5_at_max_test_acc1 98.94648566486713 train_acc1 96.31527222695408 train_acc5 96.31527222695408\n",
      "Epoch: [15]  [  0/597]  eta: 0:01:54  lr: 0.1  img/s: 720.4734957673747  loss: 2.6093 (2.6093)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.1912  data: 0.0135  max mem: 0\n",
      "Epoch: [15]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 727.2673126497725  loss: 2.6086 (2.6095)  acc1: 95.3125 (96.2562)  acc5: 100.0000 (99.8530)  time: 0.1966  data: 0.0015  max mem: 0\n",
      "Epoch: [15]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 647.4580401785822  loss: 2.6076 (2.6094)  acc1: 96.8750 (96.4280)  acc5: 100.0000 (99.8406)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [15]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 645.6376055877316  loss: 2.6072 (2.6091)  acc1: 96.8750 (96.4441)  acc5: 100.0000 (99.8650)  time: 0.2000  data: 0.0019  max mem: 0\n",
      "Epoch: [15]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 643.9239051561082  loss: 2.6078 (2.6091)  acc1: 96.0938 (96.3840)  acc5: 100.0000 (99.8617)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [15]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 647.2340211094836  loss: 2.6067 (2.6090)  acc1: 96.8750 (96.3588)  acc5: 100.0000 (99.8721)  time: 0.2001  data: 0.0020  max mem: 0\n",
      "Epoch: [15] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6221 (2.6221)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0532  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6312 (2.6287)  acc1: 93.7500 (93.9975)  acc5: 99.2188 (99.0640)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8466376648477, Acc@5 = 99.01986477278683, loss = 2.6296295595169066\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:33:40 max_test_acc1 93.8466376648477 test_acc5_at_max_test_acc1 99.01986477278683 train_acc1 96.35589333682762 train_acc5 96.35589333682762\n",
      "Epoch: [16]  [  0/597]  eta: 0:01:51  lr: 0.1  img/s: 745.7534782415433  loss: 2.6071 (2.6071)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.1861  data: 0.0145  max mem: 0\n",
      "Epoch: [16]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 718.0768995159506  loss: 2.6070 (2.6079)  acc1: 96.8750 (96.4032)  acc5: 100.0000 (99.9149)  time: 0.1966  data: 0.0015  max mem: 0\n",
      "Epoch: [16]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 653.541858038976  loss: 2.6071 (2.6081)  acc1: 96.0938 (96.4785)  acc5: 100.0000 (99.9067)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [16]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 644.5957544904428  loss: 2.6078 (2.6082)  acc1: 96.0938 (96.5532)  acc5: 100.0000 (99.8962)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [16]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 646.1823490825495  loss: 2.6073 (2.6082)  acc1: 96.0938 (96.4931)  acc5: 100.0000 (99.8987)  time: 0.2000  data: 0.0019  max mem: 0\n",
      "Epoch: [16]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 646.7841101026188  loss: 2.6076 (2.6082)  acc1: 96.0938 (96.5039)  acc5: 100.0000 (99.8955)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [16] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6200 (2.6200)  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.0611  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6275 (2.6295)  acc1: 93.7500 (93.8892)  acc5: 99.2188 (99.0408)  time: 0.0610  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.83615493474501, Acc@5 = 98.9936579485298, loss = 2.629864536921183\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:35:48 max_test_acc1 93.8466376648477 test_acc5_at_max_test_acc1 99.01986477278683 train_acc1 96.41616982204656 train_acc5 96.41616982204656\n",
      "Epoch: [17]  [  0/597]  eta: 0:01:56  lr: 0.1  img/s: 703.3624248649272  loss: 2.6076 (2.6076)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1955  data: 0.0135  max mem: 0\n",
      "Epoch: [17]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 680.2507675251037  loss: 2.6071 (2.6076)  acc1: 96.0938 (96.5114)  acc5: 100.0000 (99.9459)  time: 0.1979  data: 0.0015  max mem: 0\n",
      "Epoch: [17]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.9379541089342  loss: 2.6069 (2.6077)  acc1: 96.0938 (96.5368)  acc5: 100.0000 (99.9262)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [17]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.2764706023975  loss: 2.6068 (2.6078)  acc1: 96.8750 (96.5298)  acc5: 100.0000 (99.9066)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [17]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.1943318866473  loss: 2.6070 (2.6078)  acc1: 96.0938 (96.4483)  acc5: 100.0000 (99.9045)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [17]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.5098590500978  loss: 2.6066 (2.6078)  acc1: 96.8750 (96.4368)  acc5: 100.0000 (99.9096)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [17] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6440 (2.6440)  acc1: 91.4062 (91.4062)  acc5: 99.2188 (99.2188)  time: 0.0591  data: 0.0029  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6329 (2.6308)  acc1: 93.7500 (93.9279)  acc5: 98.4375 (98.9403)  time: 0.0612  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.914775407916, Acc@5 = 98.97793385397557, loss = 2.6299375740687054\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:37:56 max_test_acc1 93.914775407916 test_acc5_at_max_test_acc1 98.97793385397557 train_acc1 96.43320448062589 train_acc5 96.43320448062589\n",
      "Epoch: [18]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 670.8261792573655  loss: 2.6062 (2.6062)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2124  data: 0.0216  max mem: 0\n",
      "Epoch: [18]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 717.0190903821549  loss: 2.6067 (2.6078)  acc1: 96.0938 (96.3335)  acc5: 100.0000 (99.9149)  time: 0.1966  data: 0.0021  max mem: 0\n",
      "Epoch: [18]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.8438400003868  loss: 2.6065 (2.6076)  acc1: 96.8750 (96.4164)  acc5: 100.0000 (99.9300)  time: 0.1986  data: 0.0017  max mem: 0\n",
      "Epoch: [18]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 643.9571167773771  loss: 2.6069 (2.6076)  acc1: 96.8750 (96.3819)  acc5: 100.0000 (99.9247)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [18]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.7606450117514  loss: 2.6069 (2.6076)  acc1: 96.0938 (96.4191)  acc5: 100.0000 (99.9240)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [18]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.5560897069769  loss: 2.6063 (2.6076)  acc1: 96.8750 (96.4041)  acc5: 100.0000 (99.9189)  time: 0.2003  data: 0.0016  max mem: 0\n",
      "Epoch: [18] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6166 (2.6166)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.0543  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6298 (2.6307)  acc1: 94.5312 (93.7268)  acc5: 99.2188 (98.9171)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.87808585395615, Acc@5 = 98.9360029355642, loss = 2.6312373956044515\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:40:04 max_test_acc1 93.914775407916 test_acc5_at_max_test_acc1 98.97793385397557 train_acc1 96.43582519779181 train_acc5 96.43582519779181\n",
      "Epoch: [19]  [  0/597]  eta: 0:01:57  lr: 0.1  img/s: 720.9049761117631  loss: 2.6060 (2.6060)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1961  data: 0.0186  max mem: 0\n",
      "Epoch: [19]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 679.034188801716  loss: 2.6066 (2.6079)  acc1: 96.8750 (96.4650)  acc5: 100.0000 (99.9072)  time: 0.1980  data: 0.0014  max mem: 0\n",
      "Epoch: [19]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.467656391358  loss: 2.6061 (2.6076)  acc1: 96.0938 (96.3308)  acc5: 100.0000 (99.9262)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [19]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.1471840280277  loss: 2.6060 (2.6075)  acc1: 96.8750 (96.3844)  acc5: 100.0000 (99.9351)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [19]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 643.9517100009235  loss: 2.6073 (2.6076)  acc1: 95.3125 (96.3879)  acc5: 100.0000 (99.9299)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [19]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.2948339611818  loss: 2.6058 (2.6076)  acc1: 97.6562 (96.3947)  acc5: 100.0000 (99.9267)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [19] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6387 (2.6387)  acc1: 96.0938 (96.0938)  acc5: 97.6562 (97.6562)  time: 0.0588  data: 0.0030  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6272 (2.6308)  acc1: 93.7500 (93.8041)  acc5: 99.2188 (98.9403)  time: 0.0612  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77849992137952, Acc@5 = 98.94124430001573, loss = 2.6309723154703777\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:42:12 max_test_acc1 93.914775407916 test_acc5_at_max_test_acc1 98.97793385397557 train_acc1 96.43582519819171 train_acc5 96.43582519819171\n",
      "Epoch: [20]  [  0/597]  eta: 0:02:02  lr: 0.1  img/s: 695.3187605067593  loss: 2.6044 (2.6044)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.2047  data: 0.0206  max mem: 0\n",
      "Epoch: [20]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 681.2546627042035  loss: 2.6061 (2.6075)  acc1: 96.8750 (96.4264)  acc5: 100.0000 (99.9149)  time: 0.1981  data: 0.0017  max mem: 0\n",
      "Epoch: [20]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.1771965451213  loss: 2.6062 (2.6074)  acc1: 96.0938 (96.5096)  acc5: 100.0000 (99.9223)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [20]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.2685457750662  loss: 2.6070 (2.6075)  acc1: 96.0938 (96.5038)  acc5: 100.0000 (99.9118)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [20]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.9961278913166  loss: 2.6070 (2.6074)  acc1: 95.3125 (96.4366)  acc5: 100.0000 (99.9240)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [20]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.9486204551424  loss: 2.6063 (2.6073)  acc1: 97.6562 (96.5007)  acc5: 100.0000 (99.9251)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [20] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6422 (2.6422)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0604  data: 0.0035  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6275 (2.6305)  acc1: 94.5312 (93.8428)  acc5: 99.2188 (99.0099)  time: 0.0609  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.83091357029349, Acc@5 = 98.97793385437546, loss = 2.6313729937871297\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:44:20 max_test_acc1 93.914775407916 test_acc5_at_max_test_acc1 98.97793385397557 train_acc1 96.46596343980144 train_acc5 96.46596343980144\n",
      "Epoch: [21]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 661.8843112960394  loss: 2.6075 (2.6075)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2069  data: 0.0135  max mem: 0\n",
      "Epoch: [21]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 677.3225473955922  loss: 2.6070 (2.6069)  acc1: 96.0938 (96.4032)  acc5: 100.0000 (99.9613)  time: 0.1979  data: 0.0015  max mem: 0\n",
      "Epoch: [21]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 647.7580156705848  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.4591)  acc5: 100.0000 (99.9534)  time: 0.1984  data: 0.0015  max mem: 0\n",
      "Epoch: [21]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.3915679813621  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4441)  acc5: 100.0000 (99.9455)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [21]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.0689764967817  loss: 2.6063 (2.6070)  acc1: 96.8750 (96.4600)  acc5: 100.0000 (99.9416)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [21]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7529017854462  loss: 2.6066 (2.6071)  acc1: 96.8750 (96.4789)  acc5: 100.0000 (99.9361)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [21] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6343 (2.6343)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.0539  data: 0.0026  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6280 (2.6308)  acc1: 93.7500 (93.9821)  acc5: 99.2188 (98.9867)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6307190068562827\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:46:28 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44499770607305 train_acc5 96.44499770607305\n",
      "Epoch: [22]  [  0/597]  eta: 0:01:57  lr: 0.1  img/s: 715.6504013671276  loss: 2.6060 (2.6060)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1967  data: 0.0179  max mem: 0\n",
      "Epoch: [22]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 645.3721723618127  loss: 2.6063 (2.6072)  acc1: 96.8750 (96.4109)  acc5: 100.0000 (99.9149)  time: 0.1979  data: 0.0015  max mem: 0\n",
      "Epoch: [22]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.2233708717139  loss: 2.6068 (2.6072)  acc1: 96.0938 (96.3891)  acc5: 100.0000 (99.9262)  time: 0.1986  data: 0.0015  max mem: 0\n",
      "Epoch: [22]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.0876793711617  loss: 2.6059 (2.6070)  acc1: 96.8750 (96.4805)  acc5: 100.0000 (99.9351)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [22]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 646.690619647258  loss: 2.6064 (2.6071)  acc1: 96.0938 (96.3860)  acc5: 100.0000 (99.9279)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [22]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.376031609623  loss: 2.6063 (2.6071)  acc1: 96.8750 (96.4477)  acc5: 100.0000 (99.9329)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [22] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6243 (2.6243)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0623  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6331 (2.6310)  acc1: 93.7500 (93.8970)  acc5: 98.4375 (99.0022)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8413962999963, Acc@5 = 98.97269248912417, loss = 2.630928823153178\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:48:36 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4502391404049 train_acc5 96.4502391404049\n",
      "Epoch: [23]  [  0/597]  eta: 0:02:02  lr: 0.1  img/s: 677.6995995940399  loss: 2.6061 (2.6061)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2058  data: 0.0169  max mem: 0\n",
      "Epoch: [23]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 645.9801972097052  loss: 2.6064 (2.6071)  acc1: 96.0938 (96.5192)  acc5: 100.0000 (99.9613)  time: 0.1981  data: 0.0014  max mem: 0\n",
      "Epoch: [23]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.8712871287129  loss: 2.6057 (2.6069)  acc1: 96.8750 (96.5096)  acc5: 100.0000 (99.9572)  time: 0.1984  data: 0.0015  max mem: 0\n",
      "Epoch: [23]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.2422414228934  loss: 2.6067 (2.6070)  acc1: 96.0938 (96.4208)  acc5: 100.0000 (99.9533)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [23]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.1604480436844  loss: 2.6059 (2.6069)  acc1: 96.8750 (96.4990)  acc5: 100.0000 (99.9513)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [23]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.4015550975777  loss: 2.6062 (2.6070)  acc1: 96.0938 (96.4353)  acc5: 100.0000 (99.9407)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [23] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6383 (2.6383)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0504  data: 0.0067  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6322 (2.6310)  acc1: 93.7500 (93.5876)  acc5: 99.2188 (98.9944)  time: 0.0613  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.78898265148223, Acc@5 = 98.97269248912417, loss = 2.6315097252527875\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:50:44 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46072200746904 train_acc5 96.46072200746904\n",
      "Epoch: [24]  [  0/597]  eta: 0:02:02  lr: 0.1  img/s: 674.3423417991811  loss: 2.6059 (2.6059)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2052  data: 0.0154  max mem: 0\n",
      "Epoch: [24]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 645.4769225590117  loss: 2.6065 (2.6072)  acc1: 96.0938 (96.4960)  acc5: 100.0000 (99.9304)  time: 0.1972  data: 0.0020  max mem: 0\n",
      "Epoch: [24]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.6337503549013  loss: 2.6064 (2.6072)  acc1: 96.8750 (96.4863)  acc5: 100.0000 (99.9262)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [24]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.2286810013184  loss: 2.6063 (2.6071)  acc1: 96.8750 (96.4805)  acc5: 100.0000 (99.9403)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [24]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.505990424924  loss: 2.6061 (2.6070)  acc1: 96.8750 (96.5204)  acc5: 100.0000 (99.9396)  time: 0.2002  data: 0.0017  max mem: 0\n",
      "Epoch: [24]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6205213916585  loss: 2.6060 (2.6070)  acc1: 96.0938 (96.5101)  acc5: 100.0000 (99.9423)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [24] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6451 (2.6451)  acc1: 93.7500 (93.7500)  acc5: 97.6562 (97.6562)  time: 0.0525  data: 0.0035  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6259 (2.6300)  acc1: 93.7500 (93.9279)  acc5: 99.2188 (99.0718)  time: 0.0610  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8256722050422, Acc@5 = 99.01462340793543, loss = 2.6307187604904176\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:52:52 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45941164908602 train_acc5 96.45941164908602\n",
      "Epoch: [25]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 666.6148212806801  loss: 2.6070 (2.6070)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2083  data: 0.0163  max mem: 0\n",
      "Epoch: [25]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.8806888068881  loss: 2.6060 (2.6070)  acc1: 97.6562 (96.4573)  acc5: 100.0000 (99.9381)  time: 0.1975  data: 0.0017  max mem: 0\n",
      "Epoch: [25]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.5397244553433  loss: 2.6066 (2.6070)  acc1: 96.0938 (96.4863)  acc5: 100.0000 (99.9339)  time: 0.1984  data: 0.0016  max mem: 0\n",
      "Epoch: [25]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.0652713762317  loss: 2.6059 (2.6068)  acc1: 97.6562 (96.5142)  acc5: 100.0000 (99.9481)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [25]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.53075042859  loss: 2.6068 (2.6069)  acc1: 95.3125 (96.4892)  acc5: 100.0000 (99.9454)  time: 0.2002  data: 0.0017  max mem: 0\n",
      "Epoch: [25]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.4789113490374  loss: 2.6060 (2.6069)  acc1: 96.0938 (96.4649)  acc5: 100.0000 (99.9501)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [25] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:10  loss: 2.6200 (2.6200)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.0672  data: 0.0072  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6281 (2.6309)  acc1: 93.7500 (93.7809)  acc5: 99.2188 (98.9944)  time: 0.0610  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.83091357029349, Acc@5 = 98.97269248912417, loss = 2.630749739011129\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:55:00 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.43451483940879 train_acc5 96.43451483940879\n",
      "Epoch: [26]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 682.9584580000408  loss: 2.6150 (2.6150)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2029  data: 0.0155  max mem: 0\n",
      "Epoch: [26]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.6623198534091  loss: 2.6063 (2.6071)  acc1: 96.0938 (96.3103)  acc5: 100.0000 (99.9149)  time: 0.1966  data: 0.0017  max mem: 0\n",
      "Epoch: [26]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.2648551135883  loss: 2.6063 (2.6073)  acc1: 96.0938 (96.2453)  acc5: 100.0000 (99.9145)  time: 0.1985  data: 0.0018  max mem: 0\n",
      "Epoch: [26]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.6329055559825  loss: 2.6063 (2.6071)  acc1: 96.8750 (96.3403)  acc5: 100.0000 (99.9273)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [26]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.5493216798329  loss: 2.6062 (2.6070)  acc1: 96.0938 (96.3587)  acc5: 100.0000 (99.9299)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [26]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.5322979919853  loss: 2.6055 (2.6070)  acc1: 97.6562 (96.4306)  acc5: 100.0000 (99.9329)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [26] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6262 (2.6262)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.0633  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6297 (2.6311)  acc1: 94.5312 (93.9047)  acc5: 99.2188 (99.0176)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.89905131276196, Acc@5 = 99.01986477278683, loss = 2.6323311154047646\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:57:08 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44106663132389 train_acc5 96.44106663132389\n",
      "Epoch: [27]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 676.8136373549764  loss: 2.6073 (2.6073)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2081  data: 0.0190  max mem: 0\n",
      "Epoch: [27]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 643.7131298694759  loss: 2.6059 (2.6067)  acc1: 96.8750 (96.7280)  acc5: 100.0000 (99.9459)  time: 0.1965  data: 0.0015  max mem: 0\n",
      "Epoch: [27]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.0160292775721  loss: 2.6068 (2.6069)  acc1: 95.3125 (96.5135)  acc5: 100.0000 (99.9456)  time: 0.1984  data: 0.0015  max mem: 0\n",
      "Epoch: [27]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.2005157243119  loss: 2.6066 (2.6071)  acc1: 96.0938 (96.4883)  acc5: 100.0000 (99.9221)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [27]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.8210485605744  loss: 2.6059 (2.6070)  acc1: 96.0938 (96.5263)  acc5: 100.0000 (99.9279)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [27]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 646.3527213537905  loss: 2.6063 (2.6070)  acc1: 96.0938 (96.5273)  acc5: 100.0000 (99.9345)  time: 0.2000  data: 0.0019  max mem: 0\n",
      "Epoch: [27] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6090 (2.6090)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0641  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6280 (2.6310)  acc1: 93.7500 (93.8970)  acc5: 99.2188 (98.9712)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.82043084059067, Acc@5 = 98.97269248912417, loss = 2.6308226267496746\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 0:59:16 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.48299809998035 train_acc5 96.48299809998035\n",
      "Epoch: [28]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 672.986461822339  loss: 2.6071 (2.6071)  acc1: 92.9688 (92.9688)  acc5: 100.0000 (100.0000)  time: 0.2040  data: 0.0138  max mem: 0\n",
      "Epoch: [28]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.0189149570671  loss: 2.6058 (2.6068)  acc1: 96.0938 (96.3800)  acc5: 100.0000 (99.9459)  time: 0.1976  data: 0.0015  max mem: 0\n",
      "Epoch: [28]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 654.8555885298312  loss: 2.6064 (2.6068)  acc1: 96.0938 (96.4358)  acc5: 100.0000 (99.9417)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [28]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.4092898870632  loss: 2.6063 (2.6067)  acc1: 96.0938 (96.4156)  acc5: 100.0000 (99.9507)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [28]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.0852534340726  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4172)  acc5: 100.0000 (99.9396)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [28]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.1464930801316  loss: 2.6067 (2.6069)  acc1: 96.0938 (96.4025)  acc5: 100.0000 (99.9345)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [28] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6386 (2.6386)  acc1: 92.9688 (92.9688)  acc5: 97.6562 (97.6562)  time: 0.0629  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6288 (2.6310)  acc1: 94.5312 (93.7732)  acc5: 99.2188 (98.9558)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80994811088786, Acc@5 = 98.98317521882699, loss = 2.6311862389246623\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:01:24 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4279630474937 train_acc5 96.4279630474937\n",
      "Epoch: [29]  [  0/597]  eta: 0:01:58  lr: 0.1  img/s: 685.6072301065437  loss: 2.6053 (2.6053)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.1992  data: 0.0125  max mem: 0\n",
      "Epoch: [29]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.4920637588324  loss: 2.6053 (2.6071)  acc1: 96.8750 (96.6197)  acc5: 100.0000 (99.9072)  time: 0.1961  data: 0.0015  max mem: 0\n",
      "Epoch: [29]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.9952202158036  loss: 2.6062 (2.6071)  acc1: 96.8750 (96.5602)  acc5: 100.0000 (99.9145)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [29]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 643.3922136815437  loss: 2.6065 (2.6069)  acc1: 96.0938 (96.4935)  acc5: 100.0000 (99.9351)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [29]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.3520021540947  loss: 2.6063 (2.6070)  acc1: 95.3125 (96.4055)  acc5: 100.0000 (99.9299)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [29]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.2438059123882  loss: 2.6062 (2.6070)  acc1: 96.0938 (96.4353)  acc5: 100.0000 (99.9329)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [29] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6267 (2.6267)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0565  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6274 (2.6309)  acc1: 93.7500 (93.5721)  acc5: 99.2188 (98.9325)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.97793385397557, loss = 2.6307299375534057\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:03:32 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44368734808992 train_acc5 96.44368734808992\n",
      "Epoch: [30]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 669.4184409897306  loss: 2.6137 (2.6137)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.2076  data: 0.0164  max mem: 0\n",
      "Epoch: [30]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 647.0429079339062  loss: 2.6058 (2.6067)  acc1: 96.8750 (96.4186)  acc5: 100.0000 (99.9613)  time: 0.1972  data: 0.0015  max mem: 0\n",
      "Epoch: [30]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 647.9307838709716  loss: 2.6063 (2.6066)  acc1: 96.8750 (96.5446)  acc5: 100.0000 (99.9572)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [30]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 643.6598788381604  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4935)  acc5: 100.0000 (99.9455)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [30]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.5818239448288  loss: 2.6066 (2.6069)  acc1: 95.3125 (96.4600)  acc5: 100.0000 (99.9416)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [30]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.9370349224931  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.4399)  acc5: 100.0000 (99.9407)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [30] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6145 (2.6145)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0532  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6368 (2.6315)  acc1: 92.1875 (93.7191)  acc5: 99.2188 (98.9558)  time: 0.0610  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77849992137952, Acc@5 = 98.95172702971854, loss = 2.630977416038513\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:05:40 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45417021555396 train_acc5 96.45417021555396\n",
      "Epoch: [31]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 661.3795876532503  loss: 2.6048 (2.6048)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2123  data: 0.0188  max mem: 0\n",
      "Epoch: [31]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.7265762071115  loss: 2.6061 (2.6069)  acc1: 96.0938 (96.1634)  acc5: 100.0000 (99.9536)  time: 0.1973  data: 0.0021  max mem: 0\n",
      "Epoch: [31]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.6940980017351  loss: 2.6061 (2.6069)  acc1: 96.8750 (96.3619)  acc5: 100.0000 (99.9456)  time: 0.1984  data: 0.0017  max mem: 0\n",
      "Epoch: [31]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.001961334044  loss: 2.6063 (2.6067)  acc1: 96.0938 (96.4467)  acc5: 100.0000 (99.9585)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [31]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 646.4663527881802  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4873)  acc5: 100.0000 (99.9532)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [31]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.2255791901373  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4337)  acc5: 100.0000 (99.9501)  time: 0.1999  data: 0.0016  max mem: 0\n",
      "Epoch: [31] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6516 (2.6516)  acc1: 93.7500 (93.7500)  acc5: 96.8750 (96.8750)  time: 0.0611  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6306 (2.6304)  acc1: 93.7500 (93.9666)  acc5: 99.2188 (99.0408)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.87284448910475, Acc@5 = 98.9936579485298, loss = 2.630774909655253\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:07:48 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4646530826181 train_acc5 96.4646530826181\n",
      "Epoch: [32]  [  0/597]  eta: 0:02:05  lr: 0.1  img/s: 653.9406805054459  loss: 2.6067 (2.6067)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.2100  data: 0.0143  max mem: 0\n",
      "Epoch: [32]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.7637423543498  loss: 2.6061 (2.6067)  acc1: 96.0938 (96.5733)  acc5: 100.0000 (99.9459)  time: 0.1976  data: 0.0016  max mem: 0\n",
      "Epoch: [32]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.5044717705892  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.5368)  acc5: 100.0000 (99.9378)  time: 0.1984  data: 0.0015  max mem: 0\n",
      "Epoch: [32]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.9256199141334  loss: 2.6064 (2.6068)  acc1: 96.8750 (96.5220)  acc5: 100.0000 (99.9429)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [32]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.6282614385991  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.4873)  acc5: 100.0000 (99.9454)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [32]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.0034643001945  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4571)  acc5: 100.0000 (99.9439)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [32] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6366 (2.6366)  acc1: 94.5312 (94.5312)  acc5: 97.6562 (97.6562)  time: 0.0617  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6293 (2.6311)  acc1: 94.5312 (93.8583)  acc5: 99.2188 (99.0254)  time: 0.0611  data: 0.0017  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.82043084019078, Acc@5 = 99.02510613763825, loss = 2.6312568600972495\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:09:56 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47251523291621 train_acc5 96.47251523291621\n",
      "Epoch: [33]  [  0/597]  eta: 0:02:09  lr: 0.1  img/s: 668.5481570033871  loss: 2.6129 (2.6129)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2173  data: 0.0258  max mem: 0\n",
      "Epoch: [33]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 645.1999903857709  loss: 2.6058 (2.6072)  acc1: 96.8750 (96.3413)  acc5: 100.0000 (99.9149)  time: 0.1975  data: 0.0017  max mem: 0\n",
      "Epoch: [33]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 650.9838184955385  loss: 2.6061 (2.6070)  acc1: 96.8750 (96.5135)  acc5: 100.0000 (99.9300)  time: 0.1985  data: 0.0017  max mem: 0\n",
      "Epoch: [33]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.6150679470395  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.5713)  acc5: 100.0000 (99.9351)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [33]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 646.3387147648664  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.5438)  acc5: 100.0000 (99.9338)  time: 0.2003  data: 0.0017  max mem: 0\n",
      "Epoch: [33]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.9408967203893  loss: 2.6066 (2.6069)  acc1: 96.0938 (96.4820)  acc5: 100.0000 (99.9392)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [33] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6358 (2.6358)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0592  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6321 (2.6301)  acc1: 93.7500 (94.0285)  acc5: 99.2188 (98.9867)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.83091357029349, Acc@5 = 98.98841658367839, loss = 2.631317834854126\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:12:04 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46989451575028 train_acc5 96.46989451575028\n",
      "Epoch: [34]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 668.310140590495  loss: 2.6049 (2.6049)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2073  data: 0.0158  max mem: 0\n",
      "Epoch: [34]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.0135071428315  loss: 2.6063 (2.6065)  acc1: 96.8750 (96.4805)  acc5: 100.0000 (99.9691)  time: 0.1966  data: 0.0015  max mem: 0\n",
      "Epoch: [34]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.3032131933048  loss: 2.6059 (2.6066)  acc1: 96.0938 (96.5563)  acc5: 100.0000 (99.9534)  time: 0.1986  data: 0.0015  max mem: 0\n",
      "Epoch: [34]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.025095427402  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.5142)  acc5: 100.0000 (99.9507)  time: 0.2001  data: 0.0019  max mem: 0\n",
      "Epoch: [34]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 643.5858051012543  loss: 2.6065 (2.6068)  acc1: 96.0938 (96.4892)  acc5: 100.0000 (99.9493)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [34]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6437420901085  loss: 2.6061 (2.6068)  acc1: 96.0938 (96.4493)  acc5: 100.0000 (99.9454)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [34] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6226 (2.6226)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0563  data: 0.0039  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6354 (2.6304)  acc1: 93.7500 (93.7036)  acc5: 99.2188 (98.9944)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80470674563657, Acc@5 = 98.93600293516431, loss = 2.63105046749115\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:14:12 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45154949838803 train_acc5 96.45154949838803\n",
      "Epoch: [35]  [  0/597]  eta: 0:02:14  lr: 0.1  img/s: 640.6245407455226  loss: 2.6063 (2.6063)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2245  data: 0.0247  max mem: 0\n",
      "Epoch: [35]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.0475006268077  loss: 2.6066 (2.6069)  acc1: 96.0938 (96.5037)  acc5: 100.0000 (99.9381)  time: 0.1974  data: 0.0017  max mem: 0\n",
      "Epoch: [35]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 654.1661786656431  loss: 2.6061 (2.6070)  acc1: 96.0938 (96.4241)  acc5: 100.0000 (99.9378)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [35]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.1085076266074  loss: 2.6058 (2.6069)  acc1: 96.8750 (96.4260)  acc5: 100.0000 (99.9455)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [35]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.5075378694204  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4094)  acc5: 100.0000 (99.9454)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [35]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6592234851669  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4415)  acc5: 100.0000 (99.9501)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [35] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6280 (2.6280)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0566  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6305 (2.6308)  acc1: 94.5312 (93.9356)  acc5: 99.2188 (98.9790)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80994811048797, Acc@5 = 98.95696839456994, loss = 2.63106560866038\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:16:20 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46072200626938 train_acc5 96.46072200626938\n",
      "Epoch: [36]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 658.1623318033816  loss: 2.6064 (2.6064)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2093  data: 0.0148  max mem: 0\n",
      "Epoch: [36]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.699478592512  loss: 2.6066 (2.6067)  acc1: 96.8750 (96.3335)  acc5: 100.0000 (99.9536)  time: 0.1958  data: 0.0016  max mem: 0\n",
      "Epoch: [36]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 654.1853093383342  loss: 2.6059 (2.6067)  acc1: 96.0938 (96.3969)  acc5: 100.0000 (99.9534)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [36]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.7087689466264  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4182)  acc5: 100.0000 (99.9481)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [36]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.0542504517667  loss: 2.6059 (2.6068)  acc1: 96.8750 (96.5029)  acc5: 100.0000 (99.9435)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [36]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.1278631289106  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4976)  acc5: 100.0000 (99.9454)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [36] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6307 (2.6307)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0613  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6294 (2.6308)  acc1: 92.1875 (93.7732)  acc5: 99.2188 (98.9635)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8466376648477, Acc@5 = 98.95696839456994, loss = 2.6313349294662474\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:18:28 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46596344100111 train_acc5 96.46596344100111\n",
      "Epoch: [37]  [  0/597]  eta: 0:02:07  lr: 0.1  img/s: 641.1141493402818  loss: 2.6052 (2.6052)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2139  data: 0.0143  max mem: 0\n",
      "Epoch: [37]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 645.629841283585  loss: 2.6062 (2.6069)  acc1: 96.0938 (96.1711)  acc5: 100.0000 (99.9304)  time: 0.1970  data: 0.0015  max mem: 0\n",
      "Epoch: [37]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 653.2762465427049  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.4513)  acc5: 100.0000 (99.9339)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [37]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.7165111129258  loss: 2.6057 (2.6068)  acc1: 96.8750 (96.4338)  acc5: 100.0000 (99.9351)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [37]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.5609292553352  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.4698)  acc5: 100.0000 (99.9338)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [37]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.3636573129456  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4805)  acc5: 100.0000 (99.9376)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [37] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6311 (2.6311)  acc1: 96.0938 (96.0938)  acc5: 98.4375 (98.4375)  time: 0.0593  data: 0.0036  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6316 (2.6320)  acc1: 92.9688 (93.5721)  acc5: 99.2188 (98.9480)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.79422401593375, Acc@5 = 99.00414067823262, loss = 2.6310034561157227\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:20:36 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46072200706915 train_acc5 96.46072200706915\n",
      "Epoch: [38]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 644.4324953696535  loss: 2.6056 (2.6056)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.2125  data: 0.0139  max mem: 0\n",
      "Epoch: [38]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.5640246794113  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.2562)  acc5: 100.0000 (99.9459)  time: 0.1974  data: 0.0014  max mem: 0\n",
      "Epoch: [38]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 648.2985160416991  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.2725)  acc5: 100.0000 (99.9417)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [38]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.5856934804351  loss: 2.6066 (2.6069)  acc1: 96.0938 (96.3273)  acc5: 100.0000 (99.9533)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [38]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.0263503155021  loss: 2.6058 (2.6069)  acc1: 96.8750 (96.3938)  acc5: 100.0000 (99.9435)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [38]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6383237775043  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.4072)  acc5: 100.0000 (99.9470)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [38] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6323 (2.6323)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.0582  data: 0.0030  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6281 (2.6316)  acc1: 93.7500 (93.9202)  acc5: 99.2188 (98.9403)  time: 0.0612  data: 0.0017  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.88856858365897, Acc@5 = 98.96745112427276, loss = 2.6317216952641806\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:22:44 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44630806445606 train_acc5 96.44630806445606\n",
      "Epoch: [39]  [  0/597]  eta: 0:02:05  lr: 0.1  img/s: 669.4217797683767  loss: 2.6124 (2.6124)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2105  data: 0.0192  max mem: 0\n",
      "Epoch: [39]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 646.4048623260037  loss: 2.6056 (2.6069)  acc1: 96.8750 (96.5192)  acc5: 100.0000 (99.9536)  time: 0.1972  data: 0.0018  max mem: 0\n",
      "Epoch: [39]  [200/597]  eta: 0:01:18  lr: 0.1  img/s: 648.5773315437798  loss: 2.6064 (2.6069)  acc1: 96.0938 (96.5174)  acc5: 100.0000 (99.9456)  time: 0.1985  data: 0.0016  max mem: 0\n",
      "Epoch: [39]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.6104313401983  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4208)  acc5: 100.0000 (99.9533)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [39]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.0387500780961  loss: 2.6061 (2.6068)  acc1: 96.8750 (96.4386)  acc5: 100.0000 (99.9532)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [39]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.9007362862342  loss: 2.6067 (2.6068)  acc1: 96.0938 (96.4914)  acc5: 100.0000 (99.9517)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [39] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6627 (2.6627)  acc1: 89.8438 (89.8438)  acc5: 96.8750 (96.8750)  time: 0.0614  data: 0.0038  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6317 (2.6313)  acc1: 93.7500 (93.7577)  acc5: 99.2188 (99.0099)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.88332721840767, Acc@5 = 98.9988993133812, loss = 2.630854895909627\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:24:52 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47513594968224 train_acc5 96.47513594968224\n",
      "Epoch: [40]  [  0/597]  eta: 0:02:07  lr: 0.1  img/s: 645.9677612256365  loss: 2.6061 (2.6061)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2130  data: 0.0149  max mem: 0\n",
      "Epoch: [40]  [100/597]  eta: 0:01:38  lr: 0.1  img/s: 644.553964659865  loss: 2.6056 (2.6067)  acc1: 96.8750 (96.7590)  acc5: 100.0000 (99.9536)  time: 0.1974  data: 0.0015  max mem: 0\n",
      "Epoch: [40]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 654.9163006020092  loss: 2.6059 (2.6070)  acc1: 96.0938 (96.4863)  acc5: 100.0000 (99.9300)  time: 0.1986  data: 0.0015  max mem: 0\n",
      "Epoch: [40]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.3412301115327  loss: 2.6057 (2.6069)  acc1: 96.8750 (96.5454)  acc5: 100.0000 (99.9377)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [40]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.745548757092  loss: 2.6058 (2.6068)  acc1: 96.0938 (96.5457)  acc5: 100.0000 (99.9377)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [40]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.1883597820013  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4789)  acc5: 100.0000 (99.9376)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [40] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6297 (2.6297)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.0601  data: 0.0038  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6276 (2.6312)  acc1: 93.7500 (93.8660)  acc5: 99.2188 (98.9867)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.84663766444783, Acc@5 = 98.96745112427276, loss = 2.6309066661198934\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:27:00 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47906702403151 train_acc5 96.47906702403151\n",
      "Epoch: [41]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 660.7162212220898  loss: 2.6052 (2.6052)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2069  data: 0.0131  max mem: 0\n",
      "Epoch: [41]  [100/597]  eta: 0:01:29  lr: 0.1  img/s: 736.3837907234481  loss: 2.6063 (2.6069)  acc1: 97.6562 (96.4032)  acc5: 100.0000 (99.9459)  time: 0.1723  data: 0.0017  max mem: 0\n",
      "Epoch: [41]  [200/597]  eta: 0:01:12  lr: 0.1  img/s: 649.0022811206142  loss: 2.6061 (2.6067)  acc1: 96.8750 (96.4747)  acc5: 100.0000 (99.9534)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [41]  [300/597]  eta: 0:00:55  lr: 0.1  img/s: 644.411610360117  loss: 2.6060 (2.6067)  acc1: 96.0938 (96.4805)  acc5: 100.0000 (99.9533)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [41]  [400/597]  eta: 0:00:37  lr: 0.1  img/s: 646.4500060807402  loss: 2.6059 (2.6068)  acc1: 96.8750 (96.4717)  acc5: 100.0000 (99.9474)  time: 0.2001  data: 0.0018  max mem: 0\n",
      "Epoch: [41]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 738.7914923598573  loss: 2.6059 (2.6068)  acc1: 97.6562 (96.5023)  acc5: 100.0000 (99.9423)  time: 0.1753  data: 0.0017  max mem: 0\n",
      "Epoch: [41] Total time: 0:01:52\n",
      "Test:  [  0/150]  eta: 0:00:06  loss: 2.6548 (2.6548)  acc1: 91.4062 (91.4062)  acc5: 96.0938 (96.0938)  time: 0.0455  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:02  loss: 2.6305 (2.6327)  acc1: 93.7500 (93.6030)  acc5: 99.2188 (98.9325)  time: 0.0535  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:07\n",
      " * Acc@1 = 93.84663766444783, Acc@5 = 98.9936579485298, loss = 2.6311169783274333\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:29:01 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.48037738241453 train_acc5 96.48037738241453\n",
      "Epoch: [42]  [  0/597]  eta: 0:01:50  lr: 0.1  img/s: 751.3318172467214  loss: 2.6060 (2.6060)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1847  data: 0.0143  max mem: 0\n",
      "Epoch: [42]  [100/597]  eta: 0:01:26  lr: 0.1  img/s: 736.6283015606006  loss: 2.6063 (2.6070)  acc1: 96.8750 (96.1247)  acc5: 100.0000 (99.9459)  time: 0.1732  data: 0.0015  max mem: 0\n",
      "Epoch: [42]  [200/597]  eta: 0:01:07  lr: 0.1  img/s: 747.3938111492864  loss: 2.6059 (2.6067)  acc1: 96.8750 (96.3270)  acc5: 100.0000 (99.9534)  time: 0.1719  data: 0.0015  max mem: 0\n",
      "Epoch: [42]  [300/597]  eta: 0:00:50  lr: 0.1  img/s: 735.711718032697  loss: 2.6061 (2.6068)  acc1: 96.8750 (96.3767)  acc5: 100.0000 (99.9403)  time: 0.1754  data: 0.0016  max mem: 0\n",
      "Epoch: [42]  [400/597]  eta: 0:00:32  lr: 0.1  img/s: 859.2051673532359  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4191)  acc5: 100.0000 (99.9396)  time: 0.1507  data: 0.0016  max mem: 0\n",
      "Epoch: [42]  [500/597]  eta: 0:00:15  lr: 0.1  img/s: 952.0726515658001  loss: 2.6071 (2.6068)  acc1: 96.0938 (96.4228)  acc5: 100.0000 (99.9376)  time: 0.1327  data: 0.0015  max mem: 0\n",
      "Epoch: [42] Total time: 0:01:34\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6229 (2.6229)  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.0325  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6254 (2.6310)  acc1: 93.7500 (93.8815)  acc5: 99.2188 (99.0718)  time: 0.0384  data: 0.0028  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92001677276741, Acc@5 = 99.01462340793543, loss = 2.63106653213501\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:30:41 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45679093231999 train_acc5 96.45679093231999\n",
      "Epoch: [43]  [  0/597]  eta: 0:01:19  lr: 0.1  img/s: 1078.285720024182  loss: 2.6048 (2.6048)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1332  data: 0.0145  max mem: 0\n",
      "Epoch: [43]  [100/597]  eta: 0:01:01  lr: 0.1  img/s: 1031.9657850880649  loss: 2.6063 (2.6070)  acc1: 96.8750 (96.3567)  acc5: 100.0000 (99.9149)  time: 0.1237  data: 0.0019  max mem: 0\n",
      "Epoch: [43]  [200/597]  eta: 0:00:49  lr: 0.1  img/s: 1031.9479327246515  loss: 2.6060 (2.6071)  acc1: 96.8750 (96.3581)  acc5: 100.0000 (99.9184)  time: 0.1260  data: 0.0019  max mem: 0\n",
      "Epoch: [43]  [300/597]  eta: 0:00:37  lr: 0.1  img/s: 1030.9254290794713  loss: 2.6060 (2.6070)  acc1: 96.0938 (96.4260)  acc5: 100.0000 (99.9273)  time: 0.1259  data: 0.0016  max mem: 0\n",
      "Epoch: [43]  [400/597]  eta: 0:00:24  lr: 0.1  img/s: 1036.6484685001285  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.4678)  acc5: 100.0000 (99.9416)  time: 0.1260  data: 0.0017  max mem: 0\n",
      "Epoch: [43]  [500/597]  eta: 0:00:12  lr: 0.1  img/s: 1142.7210366567479  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4586)  acc5: 100.0000 (99.9407)  time: 0.1092  data: 0.0016  max mem: 0\n",
      "Epoch: [43] Total time: 0:01:15\n",
      "Test:  [  0/150]  eta: 0:00:06  loss: 2.6244 (2.6244)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0429  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:02  loss: 2.6303 (2.6312)  acc1: 94.5312 (93.8041)  acc5: 99.2188 (98.9867)  time: 0.0458  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 93.86236175900204, Acc@5 = 98.95696839456994, loss = 2.6310065587361655\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:32:03 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45154949758825 train_acc5 96.45154949758825\n",
      "Epoch: [44]  [  0/597]  eta: 0:01:39  lr: 0.1  img/s: 885.5894825396301  loss: 2.6067 (2.6067)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1670  data: 0.0224  max mem: 0\n",
      "Epoch: [44]  [100/597]  eta: 0:01:14  lr: 0.1  img/s: 859.8601982798662  loss: 2.6058 (2.6065)  acc1: 96.8750 (96.5347)  acc5: 100.0000 (99.9613)  time: 0.1487  data: 0.0015  max mem: 0\n",
      "Epoch: [44]  [200/597]  eta: 0:00:59  lr: 0.1  img/s: 860.1922230820873  loss: 2.6064 (2.6069)  acc1: 96.0938 (96.4008)  acc5: 100.0000 (99.9339)  time: 0.1506  data: 0.0016  max mem: 0\n",
      "Epoch: [44]  [300/597]  eta: 0:00:44  lr: 0.1  img/s: 856.6729036386237  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.4519)  acc5: 100.0000 (99.9429)  time: 0.1507  data: 0.0015  max mem: 0\n",
      "Epoch: [44]  [400/597]  eta: 0:00:29  lr: 0.1  img/s: 817.064332273583  loss: 2.6057 (2.6068)  acc1: 96.8750 (96.4737)  acc5: 100.0000 (99.9396)  time: 0.1549  data: 0.0015  max mem: 0\n",
      "Epoch: [44]  [500/597]  eta: 0:00:15  lr: 0.1  img/s: 726.1478965727587  loss: 2.6059 (2.6069)  acc1: 96.8750 (96.4586)  acc5: 100.0000 (99.9392)  time: 0.1907  data: 0.0015  max mem: 0\n",
      "Epoch: [44] Total time: 0:01:35\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6359 (2.6359)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0506  data: 0.0027  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6299 (2.6308)  acc1: 92.9688 (94.0130)  acc5: 99.2188 (98.9558)  time: 0.0611  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.86760312385346, Acc@5 = 98.97793385397557, loss = 2.6310019954045614\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:33:48 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47251523291621 train_acc5 96.47251523291621\n",
      "Epoch: [45]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 644.3249906988467  loss: 2.6077 (2.6077)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2124  data: 0.0137  max mem: 0\n",
      "Epoch: [45]  [100/597]  eta: 0:01:35  lr: 0.1  img/s: 734.6707172219759  loss: 2.6062 (2.6065)  acc1: 96.0938 (96.7590)  acc5: 100.0000 (99.9459)  time: 0.1753  data: 0.0015  max mem: 0\n",
      "Epoch: [45]  [200/597]  eta: 0:01:12  lr: 0.1  img/s: 735.9709159900366  loss: 2.6060 (2.6067)  acc1: 96.8750 (96.5913)  acc5: 100.0000 (99.9378)  time: 0.1754  data: 0.0015  max mem: 0\n",
      "Epoch: [45]  [300/597]  eta: 0:00:54  lr: 0.1  img/s: 646.2227946407185  loss: 2.6063 (2.6067)  acc1: 96.0938 (96.6258)  acc5: 100.0000 (99.9507)  time: 0.1976  data: 0.0015  max mem: 0\n",
      "Epoch: [45]  [400/597]  eta: 0:00:36  lr: 0.1  img/s: 716.9003656136247  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4873)  acc5: 100.0000 (99.9435)  time: 0.1973  data: 0.0015  max mem: 0\n",
      "Epoch: [45]  [500/597]  eta: 0:00:17  lr: 0.1  img/s: 734.4807559446367  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.4898)  acc5: 100.0000 (99.9423)  time: 0.1820  data: 0.0015  max mem: 0\n",
      "Epoch: [45] Total time: 0:01:51\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6188 (2.6188)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.0502  data: 0.0070  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6333 (2.6314)  acc1: 93.7500 (93.9511)  acc5: 99.2188 (98.9558)  time: 0.0612  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77325855652812, Acc@5 = 98.96745112427276, loss = 2.6309920358657837\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:35:48 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46465308181831 train_acc5 96.46465308181831\n",
      "Epoch: [46]  [  0/597]  eta: 0:02:09  lr: 0.1  img/s: 642.7128669252502  loss: 2.6074 (2.6074)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2170  data: 0.0179  max mem: 0\n",
      "Epoch: [46]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 646.7646306953368  loss: 2.6060 (2.6066)  acc1: 96.8750 (96.6352)  acc5: 100.0000 (99.9381)  time: 0.2001  data: 0.0018  max mem: 0\n",
      "Epoch: [46]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.9483309590729  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.5252)  acc5: 100.0000 (99.9300)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [46]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 648.999927468606  loss: 2.6060 (2.6068)  acc1: 95.3125 (96.4805)  acc5: 100.0000 (99.9325)  time: 0.1979  data: 0.0016  max mem: 0\n",
      "Epoch: [46]  [400/597]  eta: 0:00:38  lr: 0.1  img/s: 644.799363933237  loss: 2.6065 (2.6068)  acc1: 96.0938 (96.4483)  acc5: 100.0000 (99.9377)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [46]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 651.8960066929511  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.4540)  acc5: 100.0000 (99.9376)  time: 0.1980  data: 0.0016  max mem: 0\n",
      "Epoch: [46] Total time: 0:01:57\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6435 (2.6435)  acc1: 92.1875 (92.1875)  acc5: 97.6562 (97.6562)  time: 0.0497  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6289 (2.6316)  acc1: 92.9688 (93.6881)  acc5: 99.2188 (98.8861)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.79946538078515, Acc@5 = 98.95696839456994, loss = 2.630862998962402\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:37:55 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45417021515406 train_acc5 96.45417021515406\n",
      "Epoch: [47]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 684.1629948312248  loss: 2.6049 (2.6049)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2038  data: 0.0167  max mem: 0\n",
      "Epoch: [47]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.7874932488756  loss: 2.6056 (2.6066)  acc1: 96.8750 (96.5269)  acc5: 100.0000 (99.9613)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [47]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.5477740346867  loss: 2.6061 (2.6068)  acc1: 96.0938 (96.4358)  acc5: 100.0000 (99.9495)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [47]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.9512891489079  loss: 2.6056 (2.6068)  acc1: 96.0938 (96.4208)  acc5: 100.0000 (99.9481)  time: 0.1997  data: 0.0015  max mem: 0\n",
      "Epoch: [47]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.1077324598454  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.4308)  acc5: 100.0000 (99.9396)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [47]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 652.56715278605  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.4586)  acc5: 100.0000 (99.9407)  time: 0.1980  data: 0.0016  max mem: 0\n",
      "Epoch: [47] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6469 (2.6469)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0532  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6234 (2.6318)  acc1: 94.5312 (93.6726)  acc5: 99.2188 (98.9558)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.85187902929923, Acc@5 = 98.95172702971854, loss = 2.630980110168457\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:40:03 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45023913960512 train_acc5 96.45023913960512\n",
      "Epoch: [48]  [  0/597]  eta: 0:02:00  lr: 0.1  img/s: 687.8066401470749  loss: 2.6057 (2.6057)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2022  data: 0.0160  max mem: 0\n",
      "Epoch: [48]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.5686678712714  loss: 2.6059 (2.6066)  acc1: 96.8750 (96.3413)  acc5: 100.0000 (99.9613)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [48]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.4487402019038  loss: 2.6060 (2.6071)  acc1: 96.0938 (96.2259)  acc5: 100.0000 (99.9223)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [48]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 653.7065819850184  loss: 2.6059 (2.6070)  acc1: 96.0938 (96.3092)  acc5: 100.0000 (99.9247)  time: 0.1998  data: 0.0016  max mem: 0\n",
      "Epoch: [48]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 645.1162593966893  loss: 2.6061 (2.6070)  acc1: 96.8750 (96.3451)  acc5: 100.0000 (99.9260)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [48]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 657.4659456070225  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.4087)  acc5: 100.0000 (99.9329)  time: 0.1980  data: 0.0015  max mem: 0\n",
      "Epoch: [48] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6217 (2.6217)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0543  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6225 (2.6302)  acc1: 94.5312 (94.0207)  acc5: 99.2188 (99.0331)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.78374128703071, Acc@5 = 98.98841658367839, loss = 2.631959835688273\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:42:11 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45810129070301 train_acc5 96.45810129070301\n",
      "Epoch: [49]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 656.5092116815813  loss: 2.6053 (2.6053)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2119  data: 0.0169  max mem: 0\n",
      "Epoch: [49]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.438898186085  loss: 2.6064 (2.6068)  acc1: 96.0938 (96.5269)  acc5: 100.0000 (99.9459)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [49]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 642.553636208046  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4747)  acc5: 100.0000 (99.9417)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [49]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.0546053713597  loss: 2.6056 (2.6067)  acc1: 96.8750 (96.5843)  acc5: 100.0000 (99.9507)  time: 0.1997  data: 0.0016  max mem: 0\n",
      "Epoch: [49]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.9790805937156  loss: 2.6063 (2.6068)  acc1: 95.3125 (96.5087)  acc5: 100.0000 (99.9416)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [49]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 651.7424791835357  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.4618)  acc5: 100.0000 (99.9423)  time: 0.1982  data: 0.0016  max mem: 0\n",
      "Epoch: [49] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6334 (2.6334)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0618  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6287 (2.6314)  acc1: 93.7500 (93.6262)  acc5: 99.2188 (98.9480)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.85712039415064, Acc@5 = 98.97269248912417, loss = 2.6310049454371134\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:44:19 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45285985637116 train_acc5 96.45285985637116\n",
      "Epoch: [50]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 658.4739257671165  loss: 2.6063 (2.6063)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2090  data: 0.0146  max mem: 0\n",
      "Epoch: [50]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 646.0532682872824  loss: 2.6058 (2.6070)  acc1: 96.8750 (96.4650)  acc5: 100.0000 (99.9381)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [50]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.0992703251984  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.5524)  acc5: 100.0000 (99.9456)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [50]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 653.9359013086735  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4623)  acc5: 100.0000 (99.9507)  time: 0.1997  data: 0.0015  max mem: 0\n",
      "Epoch: [50]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.5841456606175  loss: 2.6064 (2.6069)  acc1: 96.8750 (96.4386)  acc5: 100.0000 (99.9474)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [50]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 658.0195492278974  loss: 2.6058 (2.6068)  acc1: 96.0938 (96.4727)  acc5: 100.0000 (99.9454)  time: 0.1983  data: 0.0016  max mem: 0\n",
      "Epoch: [50] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6142 (2.6142)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0554  data: 0.0026  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6325 (2.6318)  acc1: 93.7500 (93.9124)  acc5: 99.2188 (98.9248)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.87284448870486, Acc@5 = 98.97793385397557, loss = 2.6309534549713134\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:46:27 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46203236545217 train_acc5 96.46203236545217\n",
      "Epoch: [51]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 660.9431624562959  loss: 2.6051 (2.6051)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2111  data: 0.0175  max mem: 0\n",
      "Epoch: [51]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.4696276182622  loss: 2.6062 (2.6067)  acc1: 96.0938 (96.2330)  acc5: 100.0000 (99.9613)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [51]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.0482732476955  loss: 2.6056 (2.6069)  acc1: 96.8750 (96.4164)  acc5: 100.0000 (99.9378)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [51]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.3918323964057  loss: 2.6063 (2.6070)  acc1: 96.0938 (96.4312)  acc5: 100.0000 (99.9351)  time: 0.1998  data: 0.0016  max mem: 0\n",
      "Epoch: [51]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 644.2685457750662  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4756)  acc5: 100.0000 (99.9454)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [51]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 660.9911735845293  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4477)  acc5: 100.0000 (99.9454)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [51] Total time: 0:01:57\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6168 (2.6168)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.0545  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:02  loss: 2.6338 (2.6318)  acc1: 92.9688 (93.7500)  acc5: 99.2188 (99.0176)  time: 0.0533  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:07\n",
      " * Acc@1 = 93.84663766444783, Acc@5 = 98.97793385397557, loss = 2.63118190129598\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:48:33 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4567909319201 train_acc5 96.4567909319201\n",
      "Epoch: [52]  [  0/597]  eta: 0:01:49  lr: 0.1  img/s: 753.4681369143605  loss: 2.6052 (2.6052)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.1833  data: 0.0134  max mem: 0\n",
      "Epoch: [52]  [100/597]  eta: 0:01:29  lr: 0.1  img/s: 643.8551757055927  loss: 2.6067 (2.6066)  acc1: 95.3125 (96.4032)  acc5: 100.0000 (99.9613)  time: 0.1938  data: 0.0014  max mem: 0\n",
      "Epoch: [52]  [200/597]  eta: 0:01:15  lr: 0.1  img/s: 735.7127262312448  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.3036)  acc5: 100.0000 (99.9378)  time: 0.1854  data: 0.0015  max mem: 0\n",
      "Epoch: [52]  [300/597]  eta: 0:00:54  lr: 0.1  img/s: 690.3600405314351  loss: 2.6064 (2.6069)  acc1: 96.8750 (96.4130)  acc5: 100.0000 (99.9299)  time: 0.1771  data: 0.0019  max mem: 0\n",
      "Epoch: [52]  [400/597]  eta: 0:00:36  lr: 0.1  img/s: 646.9625960886106  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4503)  acc5: 100.0000 (99.9357)  time: 0.2001  data: 0.0018  max mem: 0\n",
      "Epoch: [52]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 644.7699371288229  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4353)  acc5: 100.0000 (99.9376)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [52] Total time: 0:01:53\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6263 (2.6263)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.0647  data: 0.0033  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6340 (2.6319)  acc1: 92.9688 (93.8660)  acc5: 98.4375 (98.9248)  time: 0.0613  data: 0.0017  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.87284448870486, Acc@5 = 98.96745112427276, loss = 2.6310889593760174\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:50:35 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44368734848982 train_acc5 96.44368734848982\n",
      "Epoch: [53]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 680.6940843984679  loss: 2.6061 (2.6061)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2067  data: 0.0187  max mem: 0\n",
      "Epoch: [53]  [100/597]  eta: 0:01:34  lr: 0.1  img/s: 650.4514418778214  loss: 2.6067 (2.6069)  acc1: 96.8750 (96.4882)  acc5: 100.0000 (99.9304)  time: 0.1910  data: 0.0018  max mem: 0\n",
      "Epoch: [53]  [200/597]  eta: 0:01:14  lr: 0.1  img/s: 736.5646322808125  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.3853)  acc5: 100.0000 (99.9417)  time: 0.1754  data: 0.0018  max mem: 0\n",
      "Epoch: [53]  [300/597]  eta: 0:00:54  lr: 0.1  img/s: 725.0818607616136  loss: 2.6066 (2.6067)  acc1: 96.0938 (96.4597)  acc5: 100.0000 (99.9481)  time: 0.1778  data: 0.0016  max mem: 0\n",
      "Epoch: [53]  [400/597]  eta: 0:00:36  lr: 0.1  img/s: 731.2952650527081  loss: 2.6060 (2.6067)  acc1: 96.8750 (96.4853)  acc5: 100.0000 (99.9493)  time: 0.1891  data: 0.0016  max mem: 0\n",
      "Epoch: [53]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 645.0162758594175  loss: 2.6060 (2.6067)  acc1: 96.8750 (96.5148)  acc5: 100.0000 (99.9485)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [53] Total time: 0:01:52\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6341 (2.6341)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0620  data: 0.0031  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6327 (2.6314)  acc1: 94.5312 (93.8892)  acc5: 99.2188 (99.0022)  time: 0.0612  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8256722050422, Acc@5 = 98.9988993133812, loss = 2.631070637702942\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:52:37 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47513594968224 train_acc5 96.47513594968224\n",
      "Epoch: [54]  [  0/597]  eta: 0:02:07  lr: 0.1  img/s: 651.5724171745784  loss: 2.6065 (2.6065)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2143  data: 0.0178  max mem: 0\n",
      "Epoch: [54]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.3225248875523  loss: 2.6061 (2.6068)  acc1: 97.6562 (96.6662)  acc5: 100.0000 (99.9381)  time: 0.2000  data: 0.0018  max mem: 0\n",
      "Epoch: [54]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.491667909066  loss: 2.6066 (2.6067)  acc1: 96.0938 (96.5718)  acc5: 100.0000 (99.9456)  time: 0.1999  data: 0.0016  max mem: 0\n",
      "Epoch: [54]  [300/597]  eta: 0:00:58  lr: 0.1  img/s: 730.4694115518112  loss: 2.6060 (2.6067)  acc1: 96.0938 (96.4312)  acc5: 100.0000 (99.9533)  time: 0.1773  data: 0.0016  max mem: 0\n",
      "Epoch: [54]  [400/597]  eta: 0:00:38  lr: 0.1  img/s: 655.2104341416205  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.4386)  acc5: 100.0000 (99.9513)  time: 0.1984  data: 0.0016  max mem: 0\n",
      "Epoch: [54]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.1209105481602  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.4602)  acc5: 100.0000 (99.9517)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [54] Total time: 0:01:57\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6293 (2.6293)  acc1: 90.6250 (90.6250)  acc5: 98.4375 (98.4375)  time: 0.0656  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6244 (2.6312)  acc1: 94.5312 (93.6804)  acc5: 99.2188 (98.9558)  time: 0.0613  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.85187902969912, Acc@5 = 99.00938204308402, loss = 2.6310573291778563\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:54:44 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45941164828625 train_acc5 96.45941164828625\n",
      "Epoch: [55]  [  0/597]  eta: 0:02:02  lr: 0.1  img/s: 670.5873759364874  loss: 2.6078 (2.6078)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2053  data: 0.0144  max mem: 0\n",
      "Epoch: [55]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.6857484419236  loss: 2.6062 (2.6069)  acc1: 96.0938 (96.5733)  acc5: 100.0000 (99.9536)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [55]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.6716091366047  loss: 2.6057 (2.6068)  acc1: 96.8750 (96.5913)  acc5: 100.0000 (99.9572)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [55]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 657.7929990075597  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.4623)  acc5: 100.0000 (99.9481)  time: 0.1998  data: 0.0015  max mem: 0\n",
      "Epoch: [55]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 656.4554279418903  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4425)  acc5: 100.0000 (99.9493)  time: 0.1970  data: 0.0016  max mem: 0\n",
      "Epoch: [55]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7134142240924  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4368)  acc5: 100.0000 (99.9485)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [55] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6326 (2.6326)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0583  data: 0.0033  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6265 (2.6311)  acc1: 93.7500 (93.8041)  acc5: 99.2188 (98.9635)  time: 0.0612  data: 0.0017  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.87284448870486, Acc@5 = 98.94124430001573, loss = 2.6310958751042683\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:56:52 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47644630726548 train_acc5 96.47644630726548\n",
      "Epoch: [56]  [  0/597]  eta: 0:02:00  lr: 0.1  img/s: 689.639954783681  loss: 2.6052 (2.6052)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.2019  data: 0.0162  max mem: 0\n",
      "Epoch: [56]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 705.9149542688539  loss: 2.6059 (2.6061)  acc1: 97.6562 (96.7976)  acc5: 100.0000 (99.9845)  time: 0.1990  data: 0.0019  max mem: 0\n",
      "Epoch: [56]  [200/597]  eta: 0:01:13  lr: 0.1  img/s: 859.1240460550003  loss: 2.6067 (2.6066)  acc1: 96.0938 (96.4902)  acc5: 100.0000 (99.9650)  time: 0.1507  data: 0.0016  max mem: 0\n",
      "Epoch: [56]  [300/597]  eta: 0:00:51  lr: 0.1  img/s: 884.0873958436255  loss: 2.6061 (2.6066)  acc1: 96.8750 (96.5246)  acc5: 100.0000 (99.9533)  time: 0.1510  data: 0.0017  max mem: 0\n",
      "Epoch: [56]  [400/597]  eta: 0:00:33  lr: 0.1  img/s: 719.5677159423242  loss: 2.6065 (2.6065)  acc1: 96.0938 (96.5224)  acc5: 100.0000 (99.9591)  time: 0.1778  data: 0.0016  max mem: 0\n",
      "Epoch: [56]  [500/597]  eta: 0:00:17  lr: 0.1  img/s: 646.6477788872334  loss: 2.6060 (2.6067)  acc1: 96.0938 (96.4836)  acc5: 100.0000 (99.9470)  time: 0.2001  data: 0.0018  max mem: 0\n",
      "Epoch: [56] Total time: 0:01:46\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6181 (2.6181)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0503  data: 0.0041  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:02  loss: 2.6319 (2.6312)  acc1: 93.7500 (93.8041)  acc5: 98.4375 (98.9248)  time: 0.0536  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:07\n",
      " * Acc@1 = 93.79946538078515, Acc@5 = 98.96745112427276, loss = 2.631004435221354\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 1:58:46 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47513594928235 train_acc5 96.47513594928235\n",
      "Epoch: [57]  [  0/597]  eta: 0:01:56  lr: 0.1  img/s: 741.9361201092304  loss: 2.6063 (2.6063)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.1947  data: 0.0221  max mem: 0\n",
      "Epoch: [57]  [100/597]  eta: 0:01:31  lr: 0.1  img/s: 644.9535113368524  loss: 2.6065 (2.6071)  acc1: 96.0938 (96.3877)  acc5: 100.0000 (99.9381)  time: 0.1992  data: 0.0015  max mem: 0\n",
      "Epoch: [57]  [200/597]  eta: 0:01:16  lr: 0.1  img/s: 644.6932851718515  loss: 2.6059 (2.6070)  acc1: 96.8750 (96.4164)  acc5: 100.0000 (99.9456)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [57]  [300/597]  eta: 0:00:56  lr: 0.1  img/s: 648.4112664693187  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.4415)  acc5: 100.0000 (99.9481)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [57]  [400/597]  eta: 0:00:37  lr: 0.1  img/s: 730.0512273792882  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4366)  acc5: 100.0000 (99.9435)  time: 0.1927  data: 0.0015  max mem: 0\n",
      "Epoch: [57]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 736.8557817284452  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4228)  acc5: 100.0000 (99.9501)  time: 0.1812  data: 0.0016  max mem: 0\n",
      "Epoch: [57] Total time: 0:01:51\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6249 (2.6249)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0515  data: 0.0038  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:02  loss: 2.6288 (2.6312)  acc1: 93.7500 (93.7809)  acc5: 99.2188 (99.0176)  time: 0.0457  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 93.85712039415064, Acc@5 = 98.94124430001573, loss = 2.6309215943018596\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:00:45 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4423769901068 train_acc5 96.4423769901068\n",
      "Epoch: [58]  [  0/597]  eta: 0:01:35  lr: 0.1  img/s: 899.8887222027599  loss: 2.6128 (2.6128)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.1604  data: 0.0182  max mem: 0\n",
      "Epoch: [58]  [100/597]  eta: 0:01:18  lr: 0.1  img/s: 707.7556930686543  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.4186)  acc5: 100.0000 (99.9304)  time: 0.1800  data: 0.0015  max mem: 0\n",
      "Epoch: [58]  [200/597]  eta: 0:01:09  lr: 0.1  img/s: 644.7699371288229  loss: 2.6060 (2.6067)  acc1: 96.8750 (96.4863)  acc5: 100.0000 (99.9417)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [58]  [300/597]  eta: 0:00:54  lr: 0.1  img/s: 655.6505287377097  loss: 2.6058 (2.6067)  acc1: 96.0938 (96.4026)  acc5: 100.0000 (99.9481)  time: 0.1986  data: 0.0016  max mem: 0\n",
      "Epoch: [58]  [400/597]  eta: 0:00:36  lr: 0.1  img/s: 644.1495026138122  loss: 2.6059 (2.6067)  acc1: 96.8750 (96.4892)  acc5: 100.0000 (99.9474)  time: 0.1979  data: 0.0016  max mem: 0\n",
      "Epoch: [58]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 644.524560249324  loss: 2.6054 (2.6068)  acc1: 97.6562 (96.4898)  acc5: 100.0000 (99.9392)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [58] Total time: 0:01:54\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6380 (2.6380)  acc1: 96.0938 (96.0938)  acc5: 98.4375 (98.4375)  time: 0.0571  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6276 (2.6314)  acc1: 93.7500 (93.8506)  acc5: 99.2188 (98.9790)  time: 0.0609  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.91477540751612, Acc@5 = 98.97793385397557, loss = 2.6308375279108684\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:02:48 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4646530822182 train_acc5 96.4646530822182\n",
      "Epoch: [59]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 660.3277735207623  loss: 2.6059 (2.6059)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2076  data: 0.0138  max mem: 0\n",
      "Epoch: [59]  [100/597]  eta: 0:01:30  lr: 0.1  img/s: 735.8680217935099  loss: 2.6061 (2.6070)  acc1: 96.0938 (96.4960)  acc5: 100.0000 (99.9304)  time: 0.1756  data: 0.0016  max mem: 0\n",
      "Epoch: [59]  [200/597]  eta: 0:01:13  lr: 0.1  img/s: 644.7172853397828  loss: 2.6060 (2.6070)  acc1: 96.0938 (96.5019)  acc5: 100.0000 (99.9300)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [59]  [300/597]  eta: 0:00:52  lr: 0.1  img/s: 865.2551375796363  loss: 2.6061 (2.6070)  acc1: 96.0938 (96.5038)  acc5: 100.0000 (99.9325)  time: 0.1492  data: 0.0015  max mem: 0\n",
      "Epoch: [59]  [400/597]  eta: 0:00:34  lr: 0.1  img/s: 644.7335445333384  loss: 2.6061 (2.6070)  acc1: 96.0938 (96.4386)  acc5: 100.0000 (99.9357)  time: 0.1869  data: 0.0015  max mem: 0\n",
      "Epoch: [59]  [500/597]  eta: 0:00:17  lr: 0.1  img/s: 645.142616808504  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4197)  acc5: 100.0000 (99.9423)  time: 0.1999  data: 0.0016  max mem: 0\n",
      "Epoch: [59] Total time: 0:01:49\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6310 (2.6310)  acc1: 91.4062 (91.4062)  acc5: 100.0000 (100.0000)  time: 0.0640  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6312 (2.6313)  acc1: 94.5312 (93.7268)  acc5: 99.2188 (98.9790)  time: 0.0613  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.84139629959641, Acc@5 = 98.9936579485298, loss = 2.630943086942037\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:04:47 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46596344060123 train_acc5 96.46596344060123\n",
      "Epoch: [60]  [  0/597]  eta: 0:02:02  lr: 0.1  img/s: 680.0052082937518  loss: 2.6062 (2.6062)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2053  data: 0.0171  max mem: 0\n",
      "Epoch: [60]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 647.308156597017  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.3103)  acc5: 100.0000 (99.9613)  time: 0.1992  data: 0.0016  max mem: 0\n",
      "Epoch: [60]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.4257071034336  loss: 2.6066 (2.6070)  acc1: 96.8750 (96.4125)  acc5: 100.0000 (99.9534)  time: 0.2001  data: 0.0019  max mem: 0\n",
      "Epoch: [60]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.2906876069424  loss: 2.6058 (2.6068)  acc1: 97.6562 (96.4338)  acc5: 100.0000 (99.9559)  time: 0.1988  data: 0.0015  max mem: 0\n",
      "Epoch: [60]  [400/597]  eta: 0:00:38  lr: 0.1  img/s: 654.3025091283131  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.5146)  acc5: 100.0000 (99.9532)  time: 0.1837  data: 0.0015  max mem: 0\n",
      "Epoch: [60]  [500/597]  eta: 0:00:18  lr: 0.1  img/s: 644.9349167869954  loss: 2.6063 (2.6068)  acc1: 97.6562 (96.5273)  acc5: 100.0000 (99.9532)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [60] Total time: 0:01:56\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6161 (2.6161)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0651  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6241 (2.6310)  acc1: 94.5312 (93.8506)  acc5: 99.2188 (99.0254)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77849992177941, Acc@5 = 98.9988993133812, loss = 2.6322587458292643\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:06:52 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.48823953351241 train_acc5 96.48823953351241\n",
      "Epoch: [61]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 660.1913564230422  loss: 2.6059 (2.6059)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2078  data: 0.0139  max mem: 0\n",
      "Epoch: [61]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 653.8785563956661  loss: 2.6070 (2.6068)  acc1: 96.0938 (96.2871)  acc5: 100.0000 (99.9459)  time: 0.1994  data: 0.0015  max mem: 0\n",
      "Epoch: [61]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.6878660263869  loss: 2.6058 (2.6069)  acc1: 96.0938 (96.3075)  acc5: 100.0000 (99.9339)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [61]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.3224452436871  loss: 2.6062 (2.6070)  acc1: 96.8750 (96.4364)  acc5: 100.0000 (99.9325)  time: 0.1989  data: 0.0015  max mem: 0\n",
      "Epoch: [61]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 647.9847439543091  loss: 2.6059 (2.6069)  acc1: 97.6562 (96.4347)  acc5: 100.0000 (99.9377)  time: 0.1977  data: 0.0016  max mem: 0\n",
      "Epoch: [61]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 646.3480524233646  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.4446)  acc5: 100.0000 (99.9407)  time: 0.2000  data: 0.0018  max mem: 0\n",
      "Epoch: [61] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:10  loss: 2.6569 (2.6569)  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.0670  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6255 (2.6312)  acc1: 93.7500 (93.9124)  acc5: 99.2188 (98.9867)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.89380994811049, Acc@5 = 98.9936579485298, loss = 2.63087958017985\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:09:00 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46334272383518 train_acc5 96.46334272383518\n",
      "Epoch: [62]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 687.4869218022891  loss: 2.6065 (2.6065)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2036  data: 0.0174  max mem: 0\n",
      "Epoch: [62]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 652.8623551987392  loss: 2.6066 (2.6068)  acc1: 95.3125 (96.2794)  acc5: 100.0000 (99.9613)  time: 0.1994  data: 0.0015  max mem: 0\n",
      "Epoch: [62]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.3041126567193  loss: 2.6058 (2.6067)  acc1: 96.8750 (96.4669)  acc5: 100.0000 (99.9572)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [62]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 647.8447791307622  loss: 2.6061 (2.6068)  acc1: 96.8750 (96.4415)  acc5: 100.0000 (99.9507)  time: 0.1991  data: 0.0015  max mem: 0\n",
      "Epoch: [62]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.2014568117964  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.4600)  acc5: 100.0000 (99.9454)  time: 0.1977  data: 0.0016  max mem: 0\n",
      "Epoch: [62]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.3861370903758  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4555)  acc5: 100.0000 (99.9454)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [62] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6293 (2.6293)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0631  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6312 (2.6312)  acc1: 92.9688 (93.8660)  acc5: 99.2188 (98.9867)  time: 0.0611  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8256722050422, Acc@5 = 98.97793385397557, loss = 2.6310568110148114\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:11:08 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46072200746904 train_acc5 96.46072200746904\n",
      "Epoch: [63]  [  0/597]  eta: 0:02:00  lr: 0.1  img/s: 691.9946637863143  loss: 2.6064 (2.6064)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2013  data: 0.0164  max mem: 0\n",
      "Epoch: [63]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 648.8195316257744  loss: 2.6061 (2.6070)  acc1: 96.8750 (96.3722)  acc5: 100.0000 (99.9304)  time: 0.1996  data: 0.0016  max mem: 0\n",
      "Epoch: [63]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.5087423139538  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.3775)  acc5: 100.0000 (99.9339)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [63]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 650.739211434431  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.3922)  acc5: 100.0000 (99.9455)  time: 0.1992  data: 0.0016  max mem: 0\n",
      "Epoch: [63]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 653.9534253716981  loss: 2.6064 (2.6069)  acc1: 96.8750 (96.5048)  acc5: 100.0000 (99.9318)  time: 0.1978  data: 0.0016  max mem: 0\n",
      "Epoch: [63]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7784551380902  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4883)  acc5: 100.0000 (99.9439)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [63] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6342 (2.6342)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0655  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6325 (2.6315)  acc1: 92.9688 (93.7268)  acc5: 99.2188 (98.9558)  time: 0.0613  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80994811048797, Acc@5 = 98.97793385397557, loss = 2.630889991124471\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:13:15 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46727379938413 train_acc5 96.46727379938413\n",
      "Epoch: [64]  [  0/597]  eta: 0:02:07  lr: 0.1  img/s: 646.1108039575078  loss: 2.6052 (2.6052)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.2132  data: 0.0151  max mem: 0\n",
      "Epoch: [64]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 649.8310420373531  loss: 2.6059 (2.6065)  acc1: 96.8750 (96.7203)  acc5: 100.0000 (99.9613)  time: 0.1996  data: 0.0015  max mem: 0\n",
      "Epoch: [64]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.8915336733542  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.5602)  acc5: 100.0000 (99.9456)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [64]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.6615451776303  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.5246)  acc5: 100.0000 (99.9455)  time: 0.1992  data: 0.0018  max mem: 0\n",
      "Epoch: [64]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 649.5110703540021  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.4931)  acc5: 100.0000 (99.9377)  time: 0.1967  data: 0.0019  max mem: 0\n",
      "Epoch: [64]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.647699462312  loss: 2.6065 (2.6069)  acc1: 96.0938 (96.4431)  acc5: 100.0000 (99.9439)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [64] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6203 (2.6203)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.0575  data: 0.0027  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6315 (2.6294)  acc1: 93.7500 (94.0130)  acc5: 99.2188 (99.1182)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.90953404266472, Acc@5 = 98.98317521882699, loss = 2.6308011277516683\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:15:23 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46989451615016 train_acc5 96.46989451615016\n",
      "Epoch: [65]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 673.5952563476839  loss: 2.6060 (2.6060)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2041  data: 0.0141  max mem: 0\n",
      "Epoch: [65]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 648.1662408908935  loss: 2.6065 (2.6071)  acc1: 96.0938 (96.4960)  acc5: 100.0000 (99.9072)  time: 0.1994  data: 0.0015  max mem: 0\n",
      "Epoch: [65]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.4100633762243  loss: 2.6066 (2.6071)  acc1: 96.0938 (96.3969)  acc5: 100.0000 (99.9184)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [65]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.6995847082748  loss: 2.6068 (2.6070)  acc1: 96.8750 (96.4208)  acc5: 100.0000 (99.9273)  time: 0.1992  data: 0.0015  max mem: 0\n",
      "Epoch: [65]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 653.7798192844443  loss: 2.6056 (2.6068)  acc1: 96.8750 (96.5107)  acc5: 100.0000 (99.9396)  time: 0.1961  data: 0.0015  max mem: 0\n",
      "Epoch: [65]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.7618598564308  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.4586)  acc5: 100.0000 (99.9361)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [65] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6296 (2.6296)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0611  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6263 (2.6308)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.0640)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80994811088786, Acc@5 = 98.98841658407828, loss = 2.6319323110580446\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:17:31 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47251523291621 train_acc5 96.47251523291621\n",
      "Epoch: [66]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 659.8229872710804  loss: 2.6059 (2.6059)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2066  data: 0.0126  max mem: 0\n",
      "Epoch: [66]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 648.051228877443  loss: 2.6060 (2.6066)  acc1: 96.8750 (96.3026)  acc5: 100.0000 (99.9613)  time: 0.1996  data: 0.0014  max mem: 0\n",
      "Epoch: [66]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.3829923603652  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.4202)  acc5: 100.0000 (99.9339)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [66]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.2227768137417  loss: 2.6064 (2.6068)  acc1: 96.0938 (96.4026)  acc5: 100.0000 (99.9481)  time: 0.1993  data: 0.0015  max mem: 0\n",
      "Epoch: [66]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 650.167863569977  loss: 2.6056 (2.6068)  acc1: 96.8750 (96.4133)  acc5: 100.0000 (99.9435)  time: 0.1979  data: 0.0019  max mem: 0\n",
      "Epoch: [66]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.4407934082398  loss: 2.6055 (2.6068)  acc1: 96.8750 (96.4540)  acc5: 100.0000 (99.9423)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [66] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6339 (2.6339)  acc1: 95.3125 (95.3125)  acc5: 98.4375 (98.4375)  time: 0.0552  data: 0.0030  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6305 (2.6328)  acc1: 93.7500 (93.7887)  acc5: 99.2188 (98.9712)  time: 0.0608  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.94622359662456, Acc@5 = 98.9936579485298, loss = 2.631254240671794\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:19:39 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.43582519699204 train_acc5 96.43582519699204\n",
      "Epoch: [67]  [  0/597]  eta: 0:02:09  lr: 0.1  img/s: 644.2824627828414  loss: 2.6059 (2.6059)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2177  data: 0.0191  max mem: 0\n",
      "Epoch: [67]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 649.0964412015403  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4650)  acc5: 100.0000 (99.9459)  time: 0.1995  data: 0.0014  max mem: 0\n",
      "Epoch: [67]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 646.8628188553438  loss: 2.6056 (2.6067)  acc1: 96.8750 (96.4863)  acc5: 100.0000 (99.9572)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [67]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 655.1288815347125  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.5324)  acc5: 100.0000 (99.9455)  time: 0.1993  data: 0.0015  max mem: 0\n",
      "Epoch: [67]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.2617240421653  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.5243)  acc5: 100.0000 (99.9493)  time: 0.1978  data: 0.0015  max mem: 0\n",
      "Epoch: [67]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.2496190068699  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.4446)  acc5: 100.0000 (99.9454)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [67] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6423 (2.6423)  acc1: 95.3125 (95.3125)  acc5: 97.6562 (97.6562)  time: 0.0584  data: 0.0038  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6304 (2.6309)  acc1: 94.5312 (94.0130)  acc5: 99.2188 (98.9867)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.88332721920744, Acc@5 = 98.9412443004156, loss = 2.6320001029968263\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:21:47 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4803773832143 train_acc5 96.4803773832143\n",
      "Epoch: [68]  [  0/597]  eta: 0:02:05  lr: 0.1  img/s: 650.6634994237153  loss: 2.6052 (2.6052)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2099  data: 0.0132  max mem: 0\n",
      "Epoch: [68]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 648.5052551219471  loss: 2.6059 (2.6070)  acc1: 96.0938 (96.3490)  acc5: 100.0000 (99.9226)  time: 0.1997  data: 0.0016  max mem: 0\n",
      "Epoch: [68]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.8311169190561  loss: 2.6074 (2.6071)  acc1: 95.3125 (96.3775)  acc5: 100.0000 (99.9300)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [68]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.1075561918811  loss: 2.6062 (2.6069)  acc1: 96.0938 (96.4182)  acc5: 100.0000 (99.9403)  time: 0.1995  data: 0.0015  max mem: 0\n",
      "Epoch: [68]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 649.0164033911706  loss: 2.6061 (2.6069)  acc1: 96.0938 (96.3996)  acc5: 100.0000 (99.9416)  time: 0.1978  data: 0.0015  max mem: 0\n",
      "Epoch: [68]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7970406668107  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4119)  acc5: 100.0000 (99.9439)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [68] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6305 (2.6305)  acc1: 96.0938 (96.0938)  acc5: 98.4375 (98.4375)  time: 0.0600  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6319 (2.6319)  acc1: 92.9688 (93.8583)  acc5: 98.4375 (98.8939)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.86236175900204, Acc@5 = 98.98841658367839, loss = 2.63111230691274\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:23:55 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4423769897069 train_acc5 96.4423769897069\n",
      "Epoch: [69]  [  0/597]  eta: 0:02:05  lr: 0.1  img/s: 652.506082405689  loss: 2.6067 (2.6067)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2106  data: 0.0145  max mem: 0\n",
      "Epoch: [69]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 647.4393009350933  loss: 2.6059 (2.6067)  acc1: 96.8750 (96.5811)  acc5: 100.0000 (99.9459)  time: 0.1998  data: 0.0014  max mem: 0\n",
      "Epoch: [69]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.2306636331347  loss: 2.6060 (2.6067)  acc1: 96.8750 (96.6107)  acc5: 100.0000 (99.9378)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [69]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.8811501355821  loss: 2.6056 (2.6067)  acc1: 96.8750 (96.5869)  acc5: 100.0000 (99.9403)  time: 0.1995  data: 0.0015  max mem: 0\n",
      "Epoch: [69]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 653.8411283359092  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.5457)  acc5: 100.0000 (99.9435)  time: 0.1962  data: 0.0015  max mem: 0\n",
      "Epoch: [69]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.3512834915194  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4680)  acc5: 100.0000 (99.9454)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [69] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6346 (2.6346)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.0614  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6268 (2.6296)  acc1: 92.9688 (93.9279)  acc5: 99.2188 (99.1182)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80994811048797, Acc@5 = 99.00938204308402, loss = 2.6308495791753135\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:26:03 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.48168774079755 train_acc5 96.48168774079755\n",
      "Epoch: [70]  [  0/597]  eta: 0:01:59  lr: 0.1  img/s: 682.0006504065041  loss: 2.6054 (2.6054)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2009  data: 0.0132  max mem: 0\n",
      "Epoch: [70]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 648.2781625045734  loss: 2.6063 (2.6067)  acc1: 96.0938 (96.4264)  acc5: 100.0000 (99.9613)  time: 0.1998  data: 0.0014  max mem: 0\n",
      "Epoch: [70]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.5663462669795  loss: 2.6061 (2.6069)  acc1: 96.8750 (96.4591)  acc5: 100.0000 (99.9378)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [70]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.8195316257744  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4831)  acc5: 100.0000 (99.9403)  time: 0.1995  data: 0.0016  max mem: 0\n",
      "Epoch: [70]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.4143989854766  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4639)  acc5: 100.0000 (99.9454)  time: 0.1979  data: 0.0015  max mem: 0\n",
      "Epoch: [70]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.9279441072207  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4820)  acc5: 100.0000 (99.9470)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [70] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6245 (2.6245)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0630  data: 0.0029  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6384 (2.6314)  acc1: 93.7500 (93.6959)  acc5: 97.6562 (98.9480)  time: 0.0609  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.9936579485298, loss = 2.63086928208669\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:28:11 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47120487413329 train_acc5 96.47120487413329\n",
      "Epoch: [71]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 653.1943799609693  loss: 2.6095 (2.6095)  acc1: 92.9688 (92.9688)  acc5: 100.0000 (100.0000)  time: 0.2117  data: 0.0157  max mem: 0\n",
      "Epoch: [71]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 649.2722798080981  loss: 2.6060 (2.6070)  acc1: 96.0938 (96.2794)  acc5: 100.0000 (99.9226)  time: 0.1998  data: 0.0016  max mem: 0\n",
      "Epoch: [71]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.8721680962568  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.3891)  acc5: 100.0000 (99.9417)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [71]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 649.2510799266665  loss: 2.6067 (2.6070)  acc1: 96.0938 (96.2884)  acc5: 100.0000 (99.9273)  time: 0.1995  data: 0.0016  max mem: 0\n",
      "Epoch: [71]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 654.1382817735431  loss: 2.6062 (2.6069)  acc1: 96.8750 (96.3178)  acc5: 100.0000 (99.9377)  time: 0.1966  data: 0.0016  max mem: 0\n",
      "Epoch: [71]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.0954066274998  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.3994)  acc5: 100.0000 (99.9392)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [71] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6282 (2.6282)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.0570  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6287 (2.6316)  acc1: 93.7500 (93.6649)  acc5: 99.2188 (98.9480)  time: 0.0608  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77849992137952, Acc@5 = 98.95172702971854, loss = 2.63142814318339\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:30:19 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44499770647295 train_acc5 96.44499770647295\n",
      "Epoch: [72]  [  0/597]  eta: 0:01:59  lr: 0.1  img/s: 688.1892834573098  loss: 2.6067 (2.6067)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1998  data: 0.0138  max mem: 0\n",
      "Epoch: [72]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 647.9487695668441  loss: 2.6065 (2.6069)  acc1: 96.8750 (96.5347)  acc5: 100.0000 (99.9304)  time: 0.1998  data: 0.0015  max mem: 0\n",
      "Epoch: [72]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.7792295137292  loss: 2.6059 (2.6068)  acc1: 96.8750 (96.6535)  acc5: 100.0000 (99.9417)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [72]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 649.4167899484333  loss: 2.6059 (2.6068)  acc1: 96.8750 (96.5739)  acc5: 100.0000 (99.9481)  time: 0.1996  data: 0.0016  max mem: 0\n",
      "Epoch: [72]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 649.0446497761648  loss: 2.6060 (2.6069)  acc1: 96.0938 (96.4834)  acc5: 100.0000 (99.9435)  time: 0.1965  data: 0.0016  max mem: 0\n",
      "Epoch: [72]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.1209105481602  loss: 2.6060 (2.6068)  acc1: 96.8750 (96.4197)  acc5: 100.0000 (99.9439)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [72] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:10  loss: 2.6440 (2.6440)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0669  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6238 (2.6318)  acc1: 93.7500 (93.7577)  acc5: 99.2188 (99.0408)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8256722050422, Acc@5 = 98.9988993133812, loss = 2.631199385325114\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:32:27 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45810128990323 train_acc5 96.45810128990323\n",
      "Epoch: [73]  [  0/597]  eta: 0:02:11  lr: 0.1  img/s: 654.5498028563277  loss: 2.6139 (2.6139)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.2211  data: 0.0255  max mem: 0\n",
      "Epoch: [73]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 650.0230190113884  loss: 2.6063 (2.6066)  acc1: 96.0938 (96.4960)  acc5: 100.0000 (99.9845)  time: 0.1997  data: 0.0014  max mem: 0\n",
      "Epoch: [73]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.0204600635299  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.5835)  acc5: 100.0000 (99.9495)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [73]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.09843319769  loss: 2.6058 (2.6067)  acc1: 96.0938 (96.5220)  acc5: 100.0000 (99.9533)  time: 0.1996  data: 0.0015  max mem: 0\n",
      "Epoch: [73]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 647.6861212248433  loss: 2.6071 (2.6069)  acc1: 96.0938 (96.4834)  acc5: 100.0000 (99.9377)  time: 0.1980  data: 0.0015  max mem: 0\n",
      "Epoch: [73]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.4404501136104  loss: 2.6067 (2.6068)  acc1: 96.0938 (96.4992)  acc5: 100.0000 (99.9392)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [73] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6195 (2.6195)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.0631  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6307 (2.6318)  acc1: 92.1875 (93.6881)  acc5: 98.4375 (98.9248)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.79946538158492, Acc@5 = 98.98841658407828, loss = 2.631885643005371\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:34:34 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46334272383518 train_acc5 96.46334272383518\n",
      "Epoch: [74]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 674.7907105356763  loss: 2.6124 (2.6124)  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.2030  data: 0.0133  max mem: 0\n",
      "Epoch: [74]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 656.0695674276623  loss: 2.6063 (2.6070)  acc1: 96.8750 (96.5656)  acc5: 100.0000 (99.9226)  time: 0.1997  data: 0.0015  max mem: 0\n",
      "Epoch: [74]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.4668340234396  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4125)  acc5: 100.0000 (99.9339)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [74]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 649.8381211410367  loss: 2.6059 (2.6070)  acc1: 96.0938 (96.4571)  acc5: 100.0000 (99.9325)  time: 0.1994  data: 0.0015  max mem: 0\n",
      "Epoch: [74]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.9756073974414  loss: 2.6060 (2.6069)  acc1: 96.0938 (96.4776)  acc5: 100.0000 (99.9396)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [74]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.0100763505518  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4914)  acc5: 100.0000 (99.9423)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [74] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6166 (2.6166)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0652  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6323 (2.6312)  acc1: 93.7500 (93.8738)  acc5: 98.4375 (98.9480)  time: 0.0609  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77325855632817, Acc@5 = 98.97793385477534, loss = 2.632820364634196\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:36:42 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46858415776715 train_acc5 96.46858415776715\n",
      "Epoch: [75]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 646.7272335222584  loss: 2.6060 (2.6060)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2121  data: 0.0142  max mem: 0\n",
      "Epoch: [75]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 651.8041980455741  loss: 2.6061 (2.6071)  acc1: 96.8750 (96.3335)  acc5: 100.0000 (99.9459)  time: 0.1998  data: 0.0015  max mem: 0\n",
      "Epoch: [75]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.8613238811008  loss: 2.6067 (2.6070)  acc1: 96.0938 (96.3697)  acc5: 100.0000 (99.9456)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [75]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.6541262267888  loss: 2.6064 (2.6070)  acc1: 96.8750 (96.4078)  acc5: 100.0000 (99.9455)  time: 0.1994  data: 0.0015  max mem: 0\n",
      "Epoch: [75]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 649.0266031910289  loss: 2.6062 (2.6069)  acc1: 96.8750 (96.3626)  acc5: 100.0000 (99.9454)  time: 0.1974  data: 0.0015  max mem: 0\n",
      "Epoch: [75]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.9801972097052  loss: 2.6057 (2.6068)  acc1: 96.8750 (96.4243)  acc5: 100.0000 (99.9485)  time: 0.1999  data: 0.0016  max mem: 0\n",
      "Epoch: [75] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6222 (2.6222)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.0591  data: 0.0036  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6286 (2.6301)  acc1: 93.7500 (94.0053)  acc5: 99.2188 (99.0254)  time: 0.0613  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.89380994851037, Acc@5 = 98.9988993133812, loss = 2.631493705113729\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:38:50 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44368734848982 train_acc5 96.44368734848982\n",
      "Epoch: [76]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 672.4217160520732  loss: 2.6059 (2.6059)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2029  data: 0.0125  max mem: 0\n",
      "Epoch: [76]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.4193453909937  loss: 2.6061 (2.6066)  acc1: 96.0938 (96.4573)  acc5: 100.0000 (99.9691)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [76]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.2747310376277  loss: 2.6061 (2.6067)  acc1: 96.0938 (96.5602)  acc5: 100.0000 (99.9495)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [76]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.2809794881732  loss: 2.6058 (2.6067)  acc1: 96.8750 (96.5661)  acc5: 100.0000 (99.9533)  time: 0.1996  data: 0.0015  max mem: 0\n",
      "Epoch: [76]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.0379308013944  loss: 2.6062 (2.6067)  acc1: 96.0938 (96.5711)  acc5: 100.0000 (99.9532)  time: 0.1966  data: 0.0017  max mem: 0\n",
      "Epoch: [76]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.7665203218784  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.5023)  acc5: 100.0000 (99.9439)  time: 0.1999  data: 0.0016  max mem: 0\n",
      "Epoch: [76] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6414 (2.6414)  acc1: 92.9688 (92.9688)  acc5: 97.6562 (97.6562)  time: 0.0517  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6304 (2.6308)  acc1: 93.7500 (93.8660)  acc5: 99.2188 (99.0022)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.82043084019078, Acc@5 = 98.9936579485298, loss = 2.630909070968628\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:40:58 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46072200666926 train_acc5 96.46072200666926\n",
      "Epoch: [77]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 678.3606663431991  loss: 2.6044 (2.6044)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.2063  data: 0.0176  max mem: 0\n",
      "Epoch: [77]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.331057503567  loss: 2.6061 (2.6066)  acc1: 96.0938 (96.6816)  acc5: 100.0000 (99.9613)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [77]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 646.086699929479  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.5174)  acc5: 100.0000 (99.9456)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [77]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 656.3310366411243  loss: 2.6067 (2.6068)  acc1: 96.0938 (96.5402)  acc5: 100.0000 (99.9455)  time: 0.1995  data: 0.0015  max mem: 0\n",
      "Epoch: [77]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 647.9698844839677  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4951)  acc5: 100.0000 (99.9435)  time: 0.1977  data: 0.0016  max mem: 0\n",
      "Epoch: [77]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.5811760587777  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.4649)  acc5: 100.0000 (99.9407)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [77] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6498 (2.6498)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0606  data: 0.0038  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6284 (2.6316)  acc1: 93.7500 (93.6262)  acc5: 99.2188 (99.0099)  time: 0.0609  data: 0.0016  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80470674563657, Acc@5 = 99.00938204308402, loss = 2.631083993911743\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:43:06 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45154949878791 train_acc5 96.45154949878791\n",
      "Epoch: [78]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 673.5622975377072  loss: 2.6069 (2.6069)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2091  data: 0.0190  max mem: 0\n",
      "Epoch: [78]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 647.0436877582922  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.3567)  acc5: 100.0000 (99.9536)  time: 0.2001  data: 0.0019  max mem: 0\n",
      "Epoch: [78]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.9491081472926  loss: 2.6066 (2.6069)  acc1: 95.3125 (96.4591)  acc5: 100.0000 (99.9378)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [78]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.7944410204353  loss: 2.6069 (2.6069)  acc1: 96.0938 (96.4909)  acc5: 100.0000 (99.9377)  time: 0.1997  data: 0.0015  max mem: 0\n",
      "Epoch: [78]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 649.2408730700998  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4795)  acc5: 100.0000 (99.9454)  time: 0.1967  data: 0.0016  max mem: 0\n",
      "Epoch: [78]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.5956805637394  loss: 2.6061 (2.6069)  acc1: 96.0938 (96.4415)  acc5: 100.0000 (99.9361)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [78] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6301 (2.6301)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0589  data: 0.0031  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6291 (2.6319)  acc1: 94.5312 (93.9279)  acc5: 99.2188 (98.9016)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77849992177941, Acc@5 = 98.97793385397557, loss = 2.6311562935511272\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:45:14 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4646530826181 train_acc5 96.4646530826181\n",
      "Epoch: [79]  [  0/597]  eta: 0:01:59  lr: 0.1  img/s: 685.0560770918056  loss: 2.6064 (2.6064)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2005  data: 0.0136  max mem: 0\n",
      "Epoch: [79]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.3373635104547  loss: 2.6063 (2.6071)  acc1: 96.0938 (96.1479)  acc5: 100.0000 (99.9381)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [79]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.1440926062793  loss: 2.6065 (2.6071)  acc1: 96.0938 (96.4241)  acc5: 100.0000 (99.9223)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [79]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 655.6993756534143  loss: 2.6059 (2.6070)  acc1: 97.6562 (96.4338)  acc5: 100.0000 (99.9351)  time: 0.1996  data: 0.0016  max mem: 0\n",
      "Epoch: [79]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.0637452122888  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4776)  acc5: 100.0000 (99.9435)  time: 0.1979  data: 0.0015  max mem: 0\n",
      "Epoch: [79]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.3791252580537  loss: 2.6065 (2.6069)  acc1: 96.8750 (96.4867)  acc5: 100.0000 (99.9407)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [79] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6323 (2.6323)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0591  data: 0.0037  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6279 (2.6300)  acc1: 93.7500 (93.9434)  acc5: 99.2188 (99.1337)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 99.02510613763825, loss = 2.6307766024271646\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:47:22 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.4646530826181 train_acc5 96.4646530826181\n",
      "Epoch: [80]  [  0/597]  eta: 0:01:57  lr: 0.1  img/s: 675.9189256222278  loss: 2.6071 (2.6071)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.1975  data: 0.0082  max mem: 0\n",
      "Epoch: [80]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.6764299098242  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4418)  acc5: 100.0000 (99.9381)  time: 0.2001  data: 0.0014  max mem: 0\n",
      "Epoch: [80]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 643.6498470214746  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.4824)  acc5: 100.0000 (99.9378)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [80]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.5702798824802  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.4467)  acc5: 100.0000 (99.9403)  time: 0.1997  data: 0.0016  max mem: 0\n",
      "Epoch: [80]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 655.4792216846082  loss: 2.6059 (2.6069)  acc1: 96.8750 (96.4561)  acc5: 100.0000 (99.9416)  time: 0.1981  data: 0.0016  max mem: 0\n",
      "Epoch: [80]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.2317828423224  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.4493)  acc5: 100.0000 (99.9407)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [80] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6269 (2.6269)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.0551  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6318 (2.6314)  acc1: 93.7500 (93.9588)  acc5: 99.2188 (99.0176)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.85712039415064, Acc@5 = 99.03034750248965, loss = 2.63093034585317\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:49:30 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46989451575028 train_acc5 96.46989451575028\n",
      "Epoch: [81]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 674.4600974119379  loss: 2.6056 (2.6056)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2033  data: 0.0135  max mem: 0\n",
      "Epoch: [81]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.3907267042351  loss: 2.6060 (2.6068)  acc1: 95.3125 (96.3722)  acc5: 100.0000 (99.9381)  time: 0.2000  data: 0.0014  max mem: 0\n",
      "Epoch: [81]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.2201510923308  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4008)  acc5: 100.0000 (99.9417)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [81]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.9010894973615  loss: 2.6065 (2.6067)  acc1: 96.0938 (96.4961)  acc5: 100.0000 (99.9481)  time: 0.1996  data: 0.0016  max mem: 0\n",
      "Epoch: [81]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.6313993751344  loss: 2.6062 (2.6068)  acc1: 95.3125 (96.4211)  acc5: 100.0000 (99.9454)  time: 0.1984  data: 0.0015  max mem: 0\n",
      "Epoch: [81]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.8589667862053  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4571)  acc5: 100.0000 (99.9407)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [81] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6198 (2.6198)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.0579  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6283 (2.6321)  acc1: 94.5312 (93.7345)  acc5: 99.2188 (98.9248)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.76801719167672, Acc@5 = 98.97269248912417, loss = 2.6310500462849933\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:51:38 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46334272423508 train_acc5 96.46334272423508\n",
      "Epoch: [82]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 665.708054648305  loss: 2.6061 (2.6061)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2061  data: 0.0138  max mem: 0\n",
      "Epoch: [82]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.8644221910723  loss: 2.6061 (2.6068)  acc1: 96.0938 (96.5733)  acc5: 100.0000 (99.9459)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [82]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.5661810328656  loss: 2.6066 (2.6071)  acc1: 96.8750 (96.4319)  acc5: 100.0000 (99.9378)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [82]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 654.3702968776472  loss: 2.6062 (2.6070)  acc1: 96.8750 (96.3948)  acc5: 100.0000 (99.9429)  time: 0.1998  data: 0.0015  max mem: 0\n",
      "Epoch: [82]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 653.6293821656284  loss: 2.6059 (2.6069)  acc1: 96.8750 (96.4055)  acc5: 100.0000 (99.9474)  time: 0.1985  data: 0.0015  max mem: 0\n",
      "Epoch: [82]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.1147255795427  loss: 2.6063 (2.6069)  acc1: 96.0938 (96.4524)  acc5: 100.0000 (99.9454)  time: 0.2002  data: 0.0015  max mem: 0\n",
      "Epoch: [82] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6368 (2.6368)  acc1: 90.6250 (90.6250)  acc5: 98.4375 (98.4375)  time: 0.0554  data: 0.0033  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6234 (2.6309)  acc1: 94.5312 (93.8196)  acc5: 99.2188 (98.9635)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8413962999963, Acc@5 = 98.97793385397557, loss = 2.6312266635894774\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:53:45 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47251523251632 train_acc5 96.47251523251632\n",
      "Epoch: [83]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 680.9798726502448  loss: 2.6059 (2.6059)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2029  data: 0.0149  max mem: 0\n",
      "Epoch: [83]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 643.9833795545491  loss: 2.6062 (2.6066)  acc1: 96.8750 (96.5888)  acc5: 100.0000 (99.9381)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [83]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.7629680159104  loss: 2.6059 (2.6067)  acc1: 96.0938 (96.5058)  acc5: 100.0000 (99.9534)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [83]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 648.2249362184066  loss: 2.6070 (2.6067)  acc1: 96.0938 (96.4727)  acc5: 100.0000 (99.9481)  time: 0.1997  data: 0.0015  max mem: 0\n",
      "Epoch: [83]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 652.021098014926  loss: 2.6063 (2.6067)  acc1: 96.8750 (96.4776)  acc5: 100.0000 (99.9532)  time: 0.1983  data: 0.0023  max mem: 0\n",
      "Epoch: [83]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.8442837084218  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4462)  acc5: 100.0000 (99.9501)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [83] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6272 (2.6272)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.0523  data: 0.0036  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6368 (2.6320)  acc1: 92.1875 (93.7113)  acc5: 99.2188 (98.8165)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.82043084019078, Acc@5 = 98.93600293516431, loss = 2.6313125769297283\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:55:53 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46989451575028 train_acc5 96.46989451575028\n",
      "Epoch: [84]  [  0/597]  eta: 0:02:01  lr: 0.1  img/s: 681.700155038366  loss: 2.6068 (2.6068)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2038  data: 0.0160  max mem: 0\n",
      "Epoch: [84]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.7439953620343  loss: 2.6062 (2.6064)  acc1: 96.0938 (96.4882)  acc5: 100.0000 (99.9923)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [84]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.2069689493096  loss: 2.6062 (2.6067)  acc1: 96.0938 (96.3969)  acc5: 100.0000 (99.9689)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [84]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 657.1713928283771  loss: 2.6060 (2.6067)  acc1: 96.0938 (96.4623)  acc5: 100.0000 (99.9559)  time: 0.1998  data: 0.0015  max mem: 0\n",
      "Epoch: [84]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 647.4650676745591  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4892)  acc5: 100.0000 (99.9513)  time: 0.1982  data: 0.0016  max mem: 0\n",
      "Epoch: [84]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.066044039757  loss: 2.6061 (2.6068)  acc1: 96.8750 (96.4742)  acc5: 100.0000 (99.9454)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [84] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6431 (2.6431)  acc1: 90.6250 (90.6250)  acc5: 99.2188 (99.2188)  time: 0.0575  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6317 (2.6324)  acc1: 93.7500 (93.6340)  acc5: 99.2188 (98.9016)  time: 0.0609  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.74705173227109, Acc@5 = 98.98841658367839, loss = 2.631217258771261\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 2:58:01 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45417021475417 train_acc5 96.45417021475417\n",
      "Epoch: [85]  [  0/597]  eta: 0:02:04  lr: 0.1  img/s: 690.606918020556  loss: 2.6059 (2.6059)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2091  data: 0.0237  max mem: 0\n",
      "Epoch: [85]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.5740850129906  loss: 2.6059 (2.6067)  acc1: 96.8750 (96.3567)  acc5: 100.0000 (99.9459)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [85]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.6282614385991  loss: 2.6066 (2.6069)  acc1: 96.0938 (96.3891)  acc5: 100.0000 (99.9456)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [85]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.241088544277  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.4182)  acc5: 100.0000 (99.9533)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [85]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 648.3360951604625  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.4113)  acc5: 100.0000 (99.9416)  time: 0.1971  data: 0.0016  max mem: 0\n",
      "Epoch: [85]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7683884240449  loss: 2.6053 (2.6068)  acc1: 97.6562 (96.4914)  acc5: 100.0000 (99.9454)  time: 0.2002  data: 0.0017  max mem: 0\n",
      "Epoch: [85] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6197 (2.6197)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0629  data: 0.0027  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6316 (2.6310)  acc1: 93.7500 (93.8815)  acc5: 99.2188 (99.0099)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.80994811048797, Acc@5 = 98.9988993133812, loss = 2.6309034554163615\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:00:09 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.49086024987857 train_acc5 96.49086024987857\n",
      "Epoch: [86]  [  0/597]  eta: 0:02:03  lr: 0.1  img/s: 680.8192491180193  loss: 2.6056 (2.6056)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2075  data: 0.0195  max mem: 0\n",
      "Epoch: [86]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.3860860756333  loss: 2.6068 (2.6067)  acc1: 96.8750 (96.5579)  acc5: 100.0000 (99.9459)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [86]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.9093510315626  loss: 2.6064 (2.6067)  acc1: 96.0938 (96.5213)  acc5: 100.0000 (99.9456)  time: 0.2002  data: 0.0016  max mem: 0\n",
      "Epoch: [86]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 650.3505856985379  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.5480)  acc5: 100.0000 (99.9455)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [86]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 653.4440179064802  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.5185)  acc5: 100.0000 (99.9474)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [86]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.4154778523441  loss: 2.6065 (2.6068)  acc1: 96.8750 (96.5117)  acc5: 100.0000 (99.9485)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [86] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6421 (2.6421)  acc1: 94.5312 (94.5312)  acc5: 96.8750 (96.8750)  time: 0.0548  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6323 (2.6322)  acc1: 93.7500 (93.7191)  acc5: 99.2188 (98.9403)  time: 0.0609  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.9936579485298, loss = 2.6311014064153038\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:02:17 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47251523251632 train_acc5 96.47251523251632\n",
      "Epoch: [87]  [  0/597]  eta: 0:02:09  lr: 0.1  img/s: 649.1089979433895  loss: 2.6055 (2.6055)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2163  data: 0.0191  max mem: 0\n",
      "Epoch: [87]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 643.6575637757854  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4882)  acc5: 100.0000 (99.9459)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [87]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.0472751914281  loss: 2.6064 (2.6069)  acc1: 96.8750 (96.4241)  acc5: 100.0000 (99.9339)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [87]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 651.7369408828364  loss: 2.6056 (2.6068)  acc1: 96.8750 (96.4831)  acc5: 100.0000 (99.9403)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [87]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 654.7453769593728  loss: 2.6061 (2.6068)  acc1: 96.0938 (96.4483)  acc5: 100.0000 (99.9435)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [87]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 645.3264033214053  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4649)  acc5: 100.0000 (99.9392)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [87] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:07  loss: 2.6176 (2.6176)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0518  data: 0.0034  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6320 (2.6311)  acc1: 94.5312 (93.9743)  acc5: 98.4375 (98.9480)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.83615493514489, Acc@5 = 98.9936579485298, loss = 2.631036183039347\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:04:25 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45023914000501 train_acc5 96.45023914000501\n",
      "Epoch: [88]  [  0/597]  eta: 0:02:11  lr: 0.1  img/s: 644.0142796821619  loss: 2.6070 (2.6070)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2199  data: 0.0212  max mem: 0\n",
      "Epoch: [88]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.5562861749653  loss: 2.6063 (2.6068)  acc1: 96.8750 (96.2330)  acc5: 100.0000 (99.9459)  time: 0.2000  data: 0.0014  max mem: 0\n",
      "Epoch: [88]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.1997427381112  loss: 2.6059 (2.6068)  acc1: 96.8750 (96.4086)  acc5: 100.0000 (99.9456)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [88]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 657.554524009573  loss: 2.6061 (2.6069)  acc1: 96.8750 (96.4156)  acc5: 100.0000 (99.9325)  time: 0.1998  data: 0.0015  max mem: 0\n",
      "Epoch: [88]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 650.1560531730279  loss: 2.6058 (2.6068)  acc1: 96.8750 (96.4269)  acc5: 100.0000 (99.9396)  time: 0.1984  data: 0.0018  max mem: 0\n",
      "Epoch: [88]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.5500955051931  loss: 2.6068 (2.6068)  acc1: 96.0938 (96.4633)  acc5: 100.0000 (99.9376)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [88] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6470 (2.6470)  acc1: 92.1875 (92.1875)  acc5: 97.6562 (97.6562)  time: 0.0632  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6302 (2.6321)  acc1: 92.9688 (93.7500)  acc5: 99.2188 (99.0099)  time: 0.0613  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.81518947533938, Acc@5 = 98.9988993133812, loss = 2.631120611826579\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:06:33 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45285985717094 train_acc5 96.45285985717094\n",
      "Epoch: [89]  [  0/597]  eta: 0:02:08  lr: 0.1  img/s: 639.556124716032  loss: 2.6061 (2.6061)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.2152  data: 0.0150  max mem: 0\n",
      "Epoch: [89]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.5864673931314  loss: 2.6060 (2.6072)  acc1: 96.0938 (96.3954)  acc5: 100.0000 (99.9072)  time: 0.2000  data: 0.0014  max mem: 0\n",
      "Epoch: [89]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 646.118579834087  loss: 2.6055 (2.6068)  acc1: 96.8750 (96.5330)  acc5: 100.0000 (99.9378)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [89]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.5545372233038  loss: 2.6064 (2.6069)  acc1: 96.0938 (96.4883)  acc5: 100.0000 (99.9377)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [89]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 649.7295918305601  loss: 2.6066 (2.6068)  acc1: 96.8750 (96.4912)  acc5: 100.0000 (99.9396)  time: 0.1981  data: 0.0016  max mem: 0\n",
      "Epoch: [89]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.4232129760666  loss: 2.6067 (2.6068)  acc1: 96.0938 (96.4867)  acc5: 100.0000 (99.9439)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [89] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:09  loss: 2.6244 (2.6244)  acc1: 91.4062 (91.4062)  acc5: 100.0000 (100.0000)  time: 0.0606  data: 0.0038  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6319 (2.6313)  acc1: 93.7500 (93.8815)  acc5: 99.2188 (99.0331)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.97793385397557, loss = 2.6309026924769086\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:08:41 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45810129070301 train_acc5 96.45810129070301\n",
      "Epoch: [90]  [  0/597]  eta: 0:02:05  lr: 0.1  img/s: 657.885696429775  loss: 2.6049 (2.6049)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.2102  data: 0.0156  max mem: 0\n",
      "Epoch: [90]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.3046846922647  loss: 2.6062 (2.6073)  acc1: 97.6562 (96.2020)  acc5: 100.0000 (99.9149)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [90]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.369069170868  loss: 2.6060 (2.6070)  acc1: 95.3125 (96.3814)  acc5: 100.0000 (99.9339)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [90]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.6781562952452  loss: 2.6064 (2.6069)  acc1: 96.0938 (96.3793)  acc5: 100.0000 (99.9403)  time: 0.2000  data: 0.0018  max mem: 0\n",
      "Epoch: [90]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 655.2800097644331  loss: 2.6060 (2.6068)  acc1: 95.3125 (96.4483)  acc5: 100.0000 (99.9493)  time: 0.1983  data: 0.0016  max mem: 0\n",
      "Epoch: [90]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7319960033817  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.4774)  acc5: 100.0000 (99.9439)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [90] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6210 (2.6210)  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.0600  data: 0.0046  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6339 (2.6306)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.0022)  time: 0.0611  data: 0.0015  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.85187902929923, Acc@5 = 98.96745112427276, loss = 2.6309365383783976\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:10:49 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46989451535039 train_acc5 96.46989451535039\n",
      "Epoch: [91]  [  0/597]  eta: 0:02:08  lr: 0.1  img/s: 646.1559066471369  loss: 2.6055 (2.6055)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.2153  data: 0.0172  max mem: 0\n",
      "Epoch: [91]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.8164017319345  loss: 2.6059 (2.6069)  acc1: 96.0938 (96.3103)  acc5: 100.0000 (99.9459)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [91]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.8473818546522  loss: 2.6058 (2.6067)  acc1: 96.0938 (96.4397)  acc5: 100.0000 (99.9534)  time: 0.2000  data: 0.0017  max mem: 0\n",
      "Epoch: [91]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.7722601999395  loss: 2.6058 (2.6069)  acc1: 96.8750 (96.4000)  acc5: 100.0000 (99.9377)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [91]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 656.7879043672829  loss: 2.6063 (2.6069)  acc1: 95.3125 (96.3704)  acc5: 100.0000 (99.9435)  time: 0.1984  data: 0.0019  max mem: 0\n",
      "Epoch: [91]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.7482559389348  loss: 2.6062 (2.6069)  acc1: 96.0938 (96.3994)  acc5: 100.0000 (99.9392)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [91] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6609 (2.6609)  acc1: 90.6250 (90.6250)  acc5: 95.3125 (95.3125)  time: 0.0569  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6297 (2.6306)  acc1: 93.7500 (94.0439)  acc5: 99.2188 (99.0022)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.77849992137952, Acc@5 = 98.9936579485298, loss = 2.631097572644552\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:12:57 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46727379938413 train_acc5 96.46727379938413\n",
      "Epoch: [92]  [  0/597]  eta: 0:02:02  lr: 0.1  img/s: 682.858560869792  loss: 2.6052 (2.6052)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.2050  data: 0.0175  max mem: 0\n",
      "Epoch: [92]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.1728529625601  loss: 2.6056 (2.6064)  acc1: 96.8750 (96.8441)  acc5: 100.0000 (99.9691)  time: 0.2000  data: 0.0014  max mem: 0\n",
      "Epoch: [92]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 644.7467073383092  loss: 2.6060 (2.6066)  acc1: 96.8750 (96.7001)  acc5: 100.0000 (99.9534)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [92]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 646.9056881140756  loss: 2.6058 (2.6066)  acc1: 96.8750 (96.6777)  acc5: 100.0000 (99.9533)  time: 0.1999  data: 0.0015  max mem: 0\n",
      "Epoch: [92]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 647.9206184845391  loss: 2.6065 (2.6068)  acc1: 95.3125 (96.5321)  acc5: 100.0000 (99.9454)  time: 0.1970  data: 0.0015  max mem: 0\n",
      "Epoch: [92]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 643.4006953274522  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.5304)  acc5: 100.0000 (99.9454)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [92] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6394 (2.6394)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0551  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6299 (2.6317)  acc1: 93.7500 (93.6572)  acc5: 99.2188 (98.9093)  time: 0.0610  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.9095340430646, Acc@5 = 98.9202788406101, loss = 2.631112289428711\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:15:05 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46465308181831 train_acc5 96.46465308181831\n",
      "Epoch: [93]  [  0/597]  eta: 0:02:07  lr: 0.1  img/s: 641.9942625156202  loss: 2.6066 (2.6066)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.2136  data: 0.0142  max mem: 0\n",
      "Epoch: [93]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 645.0573506158955  loss: 2.6061 (2.6068)  acc1: 96.0938 (96.3567)  acc5: 100.0000 (99.9381)  time: 0.2001  data: 0.0014  max mem: 0\n",
      "Epoch: [93]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 645.0728518835369  loss: 2.6057 (2.6067)  acc1: 96.8750 (96.4125)  acc5: 100.0000 (99.9456)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [93]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 645.6717707446373  loss: 2.6064 (2.6069)  acc1: 96.0938 (96.4234)  acc5: 100.0000 (99.9377)  time: 0.2001  data: 0.0018  max mem: 0\n",
      "Epoch: [93]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 653.5665215570554  loss: 2.6062 (2.6068)  acc1: 96.8750 (96.4464)  acc5: 100.0000 (99.9435)  time: 0.1982  data: 0.0015  max mem: 0\n",
      "Epoch: [93]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.5756327844919  loss: 2.6059 (2.6068)  acc1: 96.8750 (96.4914)  acc5: 100.0000 (99.9439)  time: 0.2001  data: 0.0015  max mem: 0\n",
      "Epoch: [93] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6292 (2.6292)  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.0560  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6271 (2.6321)  acc1: 93.7500 (93.6030)  acc5: 99.2188 (98.9403)  time: 0.0611  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.79422401593375, Acc@5 = 99.00414067823262, loss = 2.631027588844299\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:17:13 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47644630766537 train_acc5 96.47644630766537\n",
      "Epoch: [94]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 664.1770475984289  loss: 2.6078 (2.6078)  acc1: 92.9688 (92.9688)  acc5: 100.0000 (100.0000)  time: 0.2120  data: 0.0193  max mem: 0\n",
      "Epoch: [94]  [100/597]  eta: 0:01:39  lr: 0.1  img/s: 644.3938204937699  loss: 2.6060 (2.6072)  acc1: 96.0938 (96.3490)  acc5: 100.0000 (99.9226)  time: 0.2001  data: 0.0017  max mem: 0\n",
      "Epoch: [94]  [200/597]  eta: 0:01:19  lr: 0.1  img/s: 646.9267351023462  loss: 2.6061 (2.6069)  acc1: 96.0938 (96.3308)  acc5: 100.0000 (99.9495)  time: 0.2000  data: 0.0016  max mem: 0\n",
      "Epoch: [94]  [300/597]  eta: 0:00:59  lr: 0.1  img/s: 644.7304474808636  loss: 2.6067 (2.6069)  acc1: 96.0938 (96.3922)  acc5: 100.0000 (99.9507)  time: 0.2000  data: 0.0015  max mem: 0\n",
      "Epoch: [94]  [400/597]  eta: 0:00:39  lr: 0.1  img/s: 647.8854330713413  loss: 2.6065 (2.6069)  acc1: 96.8750 (96.4347)  acc5: 100.0000 (99.9493)  time: 0.1983  data: 0.0016  max mem: 0\n",
      "Epoch: [94]  [500/597]  eta: 0:00:19  lr: 0.1  img/s: 644.6963818673071  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.4197)  acc5: 100.0000 (99.9517)  time: 0.2001  data: 0.0016  max mem: 0\n",
      "Epoch: [94] Total time: 0:01:58\n",
      "Test:  [  0/150]  eta: 0:00:08  loss: 2.6461 (2.6461)  acc1: 90.6250 (90.6250)  acc5: 99.2188 (99.2188)  time: 0.0579  data: 0.0025  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:03  loss: 2.6341 (2.6313)  acc1: 94.5312 (93.8119)  acc5: 98.4375 (98.9558)  time: 0.0612  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:09\n",
      " * Acc@1 = 93.88856858365897, Acc@5 = 98.9988993133812, loss = 2.631044952074687\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:19:21 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45154949878791 train_acc5 96.45154949878791\n",
      "Epoch: [95]  [  0/597]  eta: 0:02:06  lr: 0.1  img/s: 647.0078177819288  loss: 2.6133 (2.6133)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.2120  data: 0.0142  max mem: 0\n",
      "Epoch: [95]  [100/597]  eta: 0:01:28  lr: 0.1  img/s: 738.1251677335621  loss: 2.6070 (2.6069)  acc1: 96.0938 (96.4960)  acc5: 100.0000 (99.9304)  time: 0.1751  data: 0.0014  max mem: 0\n",
      "Epoch: [95]  [200/597]  eta: 0:01:06  lr: 0.1  img/s: 858.356215545579  loss: 2.6065 (2.6070)  acc1: 96.8750 (96.4008)  acc5: 100.0000 (99.9300)  time: 0.1505  data: 0.0015  max mem: 0\n",
      "Epoch: [95]  [300/597]  eta: 0:00:49  lr: 0.1  img/s: 719.6120827390973  loss: 2.6060 (2.6069)  acc1: 96.8750 (96.4364)  acc5: 100.0000 (99.9403)  time: 0.1786  data: 0.0025  max mem: 0\n",
      "Epoch: [95]  [400/597]  eta: 0:00:34  lr: 0.1  img/s: 646.0408294896495  loss: 2.6065 (2.6068)  acc1: 96.0938 (96.4912)  acc5: 100.0000 (99.9474)  time: 0.1998  data: 0.0021  max mem: 0\n",
      "Epoch: [95]  [500/597]  eta: 0:00:16  lr: 0.1  img/s: 859.52430140855  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.4930)  acc5: 100.0000 (99.9439)  time: 0.1505  data: 0.0015  max mem: 0\n",
      "Epoch: [95] Total time: 0:01:39\n",
      "Test:  [  0/150]  eta: 0:00:06  loss: 2.6416 (2.6416)  acc1: 93.7500 (93.7500)  acc5: 96.8750 (96.8750)  time: 0.0426  data: 0.0026  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6245 (2.6310)  acc1: 93.7500 (93.9356)  acc5: 99.2188 (98.9635)  time: 0.0381  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.85712039415064, Acc@5 = 98.97793385397557, loss = 2.630983511606852\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:21:06 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.46072200706915 train_acc5 96.46072200706915\n",
      "Epoch: [96]  [  0/597]  eta: 0:01:23  lr: 0.1  img/s: 1022.5898352605946  loss: 2.6046 (2.6046)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1395  data: 0.0143  max mem: 0\n",
      "Epoch: [96]  [100/597]  eta: 0:01:02  lr: 0.1  img/s: 1028.3110421574825  loss: 2.6063 (2.6069)  acc1: 96.8750 (96.4728)  acc5: 100.0000 (99.9381)  time: 0.1259  data: 0.0014  max mem: 0\n",
      "Epoch: [96]  [200/597]  eta: 0:00:49  lr: 0.1  img/s: 1031.329432421114  loss: 2.6057 (2.6067)  acc1: 96.8750 (96.3697)  acc5: 100.0000 (99.9495)  time: 0.1259  data: 0.0014  max mem: 0\n",
      "Epoch: [96]  [300/597]  eta: 0:00:37  lr: 0.1  img/s: 1042.6722755336484  loss: 2.6069 (2.6067)  acc1: 96.0938 (96.4441)  acc5: 100.0000 (99.9481)  time: 0.1258  data: 0.0015  max mem: 0\n",
      "Epoch: [96]  [400/597]  eta: 0:00:24  lr: 0.1  img/s: 1027.057932725878  loss: 2.6059 (2.6067)  acc1: 96.0938 (96.4522)  acc5: 100.0000 (99.9513)  time: 0.1259  data: 0.0014  max mem: 0\n",
      "Epoch: [96]  [500/597]  eta: 0:00:12  lr: 0.1  img/s: 1029.0442576257672  loss: 2.6066 (2.6068)  acc1: 96.8750 (96.4524)  acc5: 100.0000 (99.9470)  time: 0.1259  data: 0.0015  max mem: 0\n",
      "Epoch: [96] Total time: 0:01:14\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6132 (2.6132)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6288 (2.6311)  acc1: 93.7500 (93.7423)  acc5: 99.2188 (99.0022)  time: 0.0382  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.80994811048797, Acc@5 = 99.01462340793543, loss = 2.630867214202881\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:22:27 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45154949798814 train_acc5 96.45154949798814\n",
      "Epoch: [97]  [  0/597]  eta: 0:01:19  lr: 0.1  img/s: 1067.2423182816647  loss: 2.6108 (2.6108)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1337  data: 0.0138  max mem: 0\n",
      "Epoch: [97]  [100/597]  eta: 0:01:02  lr: 0.1  img/s: 1025.7040027358682  loss: 2.6061 (2.6068)  acc1: 96.0938 (96.5888)  acc5: 100.0000 (99.9304)  time: 0.1259  data: 0.0013  max mem: 0\n",
      "Epoch: [97]  [200/597]  eta: 0:00:49  lr: 0.1  img/s: 1026.3942569279152  loss: 2.6057 (2.6070)  acc1: 96.8750 (96.4785)  acc5: 100.0000 (99.9300)  time: 0.1259  data: 0.0014  max mem: 0\n",
      "Epoch: [97]  [300/597]  eta: 0:00:37  lr: 0.1  img/s: 1038.7484656879058  loss: 2.6066 (2.6068)  acc1: 96.0938 (96.4987)  acc5: 100.0000 (99.9455)  time: 0.1257  data: 0.0014  max mem: 0\n",
      "Epoch: [97]  [400/597]  eta: 0:00:24  lr: 0.1  img/s: 1026.1039232587875  loss: 2.6060 (2.6068)  acc1: 96.0938 (96.4542)  acc5: 100.0000 (99.9435)  time: 0.1260  data: 0.0014  max mem: 0\n",
      "Epoch: [97]  [500/597]  eta: 0:00:12  lr: 0.1  img/s: 1028.4627241084033  loss: 2.6062 (2.6068)  acc1: 96.0938 (96.4181)  acc5: 100.0000 (99.9454)  time: 0.1260  data: 0.0015  max mem: 0\n",
      "Epoch: [97] Total time: 0:01:14\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6345 (2.6345)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0358  data: 0.0026  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6271 (2.6306)  acc1: 94.5312 (93.9821)  acc5: 99.2188 (99.0176)  time: 0.0384  data: 0.0013  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.86760312385346, Acc@5 = 99.01462340793543, loss = 2.630988620122274\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:23:47 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.45941164828625 train_acc5 96.45941164828625\n",
      "Epoch: [98]  [  0/597]  eta: 0:01:21  lr: 0.1  img/s: 1041.9498501715652  loss: 2.6065 (2.6065)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.1364  data: 0.0135  max mem: 0\n",
      "Epoch: [98]  [100/597]  eta: 0:01:02  lr: 0.1  img/s: 1026.6808281971012  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.4573)  acc5: 100.0000 (99.9459)  time: 0.1260  data: 0.0013  max mem: 0\n",
      "Epoch: [98]  [200/597]  eta: 0:00:49  lr: 0.1  img/s: 1027.6870562607317  loss: 2.6063 (2.6065)  acc1: 95.3125 (96.5058)  acc5: 100.0000 (99.9650)  time: 0.1260  data: 0.0014  max mem: 0\n",
      "Epoch: [98]  [300/597]  eta: 0:00:37  lr: 0.1  img/s: 1082.396667755372  loss: 2.6059 (2.6067)  acc1: 96.8750 (96.5272)  acc5: 100.0000 (99.9559)  time: 0.1256  data: 0.0015  max mem: 0\n",
      "Epoch: [98]  [400/597]  eta: 0:00:24  lr: 0.1  img/s: 1029.1310511928905  loss: 2.6060 (2.6067)  acc1: 96.0938 (96.4620)  acc5: 100.0000 (99.9532)  time: 0.1259  data: 0.0014  max mem: 0\n",
      "Epoch: [98]  [500/597]  eta: 0:00:12  lr: 0.1  img/s: 1029.4941647970238  loss: 2.6063 (2.6068)  acc1: 96.0938 (96.4072)  acc5: 100.0000 (99.9454)  time: 0.1258  data: 0.0015  max mem: 0\n",
      "Epoch: [98] Total time: 0:01:14\n",
      "Test:  [  0/150]  eta: 0:00:06  loss: 2.6485 (2.6485)  acc1: 91.4062 (91.4062)  acc5: 98.4375 (98.4375)  time: 0.0447  data: 0.0040  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6342 (2.6313)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (98.9171)  time: 0.0383  data: 0.0013  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.80470674603644, Acc@5 = 98.95172702971854, loss = 2.6309788672129315\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:25:08 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.44368734808992 train_acc5 96.44368734808992\n",
      "Epoch: [99]  [  0/597]  eta: 0:01:17  lr: 0.1  img/s: 1236.5026705206305  loss: 2.6076 (2.6076)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.1296  data: 0.0260  max mem: 0\n",
      "Epoch: [99]  [100/597]  eta: 0:01:02  lr: 0.1  img/s: 1030.0116494125411  loss: 2.6064 (2.6068)  acc1: 96.0938 (96.5501)  acc5: 100.0000 (99.9459)  time: 0.1258  data: 0.0016  max mem: 0\n",
      "Epoch: [99]  [200/597]  eta: 0:00:49  lr: 0.1  img/s: 1028.151528905282  loss: 2.6059 (2.6068)  acc1: 96.0938 (96.4436)  acc5: 100.0000 (99.9456)  time: 0.1259  data: 0.0016  max mem: 0\n",
      "Epoch: [99]  [300/597]  eta: 0:00:37  lr: 0.1  img/s: 1037.8388275980724  loss: 2.6055 (2.6068)  acc1: 96.8750 (96.4857)  acc5: 100.0000 (99.9481)  time: 0.1256  data: 0.0015  max mem: 0\n",
      "Epoch: [99]  [400/597]  eta: 0:00:24  lr: 0.1  img/s: 1028.313011766193  loss: 2.6059 (2.6069)  acc1: 96.8750 (96.4288)  acc5: 100.0000 (99.9435)  time: 0.1259  data: 0.0015  max mem: 0\n",
      "Epoch: [99]  [500/597]  eta: 0:00:12  lr: 0.1  img/s: 1029.5672131524798  loss: 2.6064 (2.6068)  acc1: 95.3125 (96.4477)  acc5: 100.0000 (99.9423)  time: 0.1259  data: 0.0014  max mem: 0\n",
      "Epoch: [99] Total time: 0:01:14\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6384 (2.6384)  acc1: 93.7500 (93.7500)  acc5: 97.6562 (97.6562)  time: 0.0366  data: 0.0030  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6319 (2.6316)  acc1: 92.9688 (93.6030)  acc5: 99.2188 (98.9403)  time: 0.0306  data: 0.0014  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78374128623093, Acc@5 = 98.95696839456994, loss = 2.6310567553838093\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.1, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.1_2025_3_12_7__45\n",
      "Training time 3:26:28 max_test_acc1 93.9671890560302 test_acc5_at_max_test_acc1 98.97269248912417 train_acc1 96.47382559129922 train_acc5 96.47382559129922\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    save_max = False\n",
    "\n",
    "    train_loss, train_acc1, train_acc5 = train_one_epoch(net, criterion,data_loader, device, epoch, args.print_freq,lr=args.lr)\n",
    "\n",
    "    if utils.is_main_process():\n",
    "        train_tb_writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc1', train_acc1, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc5', train_acc5, epoch)\n",
    "\n",
    "    test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "    if te_tb_writer is not None:\n",
    "        if utils.is_main_process():\n",
    "            te_tb_writer.add_scalar('test_loss', test_loss, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc1', test_acc1, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc5', test_acc5, epoch)\n",
    "\n",
    "\n",
    "    if max_test_acc1 < test_acc1:\n",
    "        max_test_acc1 = test_acc1\n",
    "        test_acc5_at_max_test_acc1 = test_acc5\n",
    "        save_max = True\n",
    "\n",
    "    if output_dir:\n",
    "\n",
    "        checkpoint = {\n",
    "            'model': net.state_dict(),\n",
    "            'pre-train_epoch': epoch,\n",
    "            'args': args,\n",
    "            'max_test_acc1': max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1': test_acc5_at_max_test_acc1,\n",
    "        }\n",
    "\n",
    "        utils.save_on_master(\n",
    "            checkpoint,\n",
    "            os.path.join(output_dir, 'checkpoint_latest.pth'))\n",
    "        save_flag = False\n",
    "\n",
    "        if epoch % 64 == 0 or epoch == args.epochs - 1:\n",
    "            save_flag = True\n",
    "\n",
    "\n",
    "        if save_flag:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir, f'checkpoint_{epoch}.pth'))\n",
    "\n",
    "        if save_max:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net,os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net.state_dict(),os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth'))\n",
    "    print(args)\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(output_dir)\n",
    "\n",
    "    print('Training time {}'.format(total_time_str), 'max_test_acc1', max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1', test_acc5_at_max_test_acc1,'train_acc1', train_acc1,\n",
    "            'train_acc5', train_acc1)\n",
    "\n",
    "    Train_logs= {\n",
    "        'Epoch:': epoch,\n",
    "        'max_test_acc1 ': max_test_acc1 ,\n",
    "        'test_acc5_at_max_test_acc1 ': test_acc5_at_max_test_acc1,\n",
    "        'train_acc1 ': train_acc1,\n",
    "        'train_acc5 ': train_acc1,\n",
    "        'args': args\n",
    "    }\n",
    "    with open(output_dir + '_logs/args.txt', 'a', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(str(Train_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [  0/150]  eta: 0:00:27  loss: 2.6494 (2.6494)  acc1: 89.8438 (89.8438)  acc5: 96.0938 (96.0938)  time: 0.1847  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6484 (2.6504)  acc1: 89.0625 (89.7045)  acc5: 96.0938 (96.2562)  time: 0.0300  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394649923, Acc@5 = 96.25766549649506, loss = 2.6505705372492474\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6341 (2.6341)  acc1: 89.8438 (89.8438)  acc5: 97.6562 (97.6562)  time: 0.0307  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6498 (2.6509)  acc1: 89.8438 (89.5808)  acc5: 96.0938 (96.1247)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394609935, Acc@5 = 96.25766549649506, loss = 2.650611735979716\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6331 (2.6331)  acc1: 89.0625 (89.0625)  acc5: 98.4375 (98.4375)  time: 0.0293  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6551 (2.6501)  acc1: 89.8438 (89.7896)  acc5: 95.3125 (96.2098)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394609935, Acc@5 = 96.25766549649506, loss = 2.650486235618591\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6502 (2.6502)  acc1: 86.7188 (86.7188)  acc5: 96.8750 (96.8750)  time: 0.0313  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6420 (2.6501)  acc1: 89.8438 (89.5575)  acc5: 96.0938 (96.2020)  time: 0.0310  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394609935, Acc@5 = 96.25766549609519, loss = 2.6505705642700197\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6650 (2.6650)  acc1: 89.8438 (89.8438)  acc5: 95.3125 (95.3125)  time: 0.0312  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6413 (2.6495)  acc1: 90.6250 (89.7664)  acc5: 96.8750 (96.2717)  time: 0.0311  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394569947, Acc@5 = 96.25766549609519, loss = 2.649670255978902\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6555 (2.6555)  acc1: 90.6250 (90.6250)  acc5: 95.3125 (95.3125)  time: 0.0309  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6412 (2.6475)  acc1: 89.0625 (89.8360)  acc5: 96.8750 (96.4650)  time: 0.0307  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394569947, Acc@5 = 96.25766549609519, loss = 2.6496290667851765\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6388 (2.6388)  acc1: 93.7500 (93.7500)  acc5: 96.8750 (96.8750)  time: 0.0329  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6480 (2.6505)  acc1: 89.0625 (89.3796)  acc5: 96.0938 (96.2330)  time: 0.0307  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394649923, Acc@5 = 96.25766549609519, loss = 2.6497114515304565\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6562 (2.6562)  acc1: 89.0625 (89.0625)  acc5: 95.3125 (95.3125)  time: 0.0328  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6437 (2.6503)  acc1: 89.8438 (89.6426)  acc5: 96.8750 (96.2252)  time: 0.0307  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394609935, Acc@5 = 96.25766549649506, loss = 2.6505294132232664\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6559 (2.6559)  acc1: 89.8438 (89.8438)  acc5: 96.8750 (96.8750)  time: 0.0371  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6438 (2.6492)  acc1: 89.8438 (89.6658)  acc5: 96.0938 (96.3258)  time: 0.0303  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394649923, Acc@5 = 96.25766549649506, loss = 2.6505274120966593\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6650 (2.6650)  acc1: 87.5000 (87.5000)  acc5: 95.3125 (95.3125)  time: 0.0369  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6544 (2.6502)  acc1: 90.6250 (89.6968)  acc5: 95.3125 (96.2175)  time: 0.0300  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 89.56968394569947, Acc@5 = 96.25766549609519, loss = 2.6496702575683595\n",
      "Test:  [  0/150]  eta: 0:00:25  loss: 2.6365 (2.6365)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.1677  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6343 (2.6377)  acc1: 92.9688 (93.1776)  acc5: 99.2188 (98.4298)  time: 0.0298  data: 0.0012  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427525706, Acc@5 = 98.39090099061795, loss = 2.63866935412089\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6458 (2.6458)  acc1: 96.0938 (96.0938)  acc5: 97.6562 (97.6562)  time: 0.0370  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6419 (2.6394)  acc1: 92.9688 (93.0538)  acc5: 98.4375 (98.3215)  time: 0.0308  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.6386438910166423\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6376 (2.6376)  acc1: 95.3125 (95.3125)  acc5: 98.4375 (98.4375)  time: 0.0369  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6355 (2.6402)  acc1: 92.9688 (92.8218)  acc5: 98.4375 (98.2519)  time: 0.0307  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.638628125190735\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6432 (2.6432)  acc1: 90.6250 (90.6250)  acc5: 98.4375 (98.4375)  time: 0.0370  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6430 (2.6404)  acc1: 92.1875 (92.6980)  acc5: 98.4375 (98.3292)  time: 0.0302  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.6386281363169353\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6399 (2.6399)  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.0305  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6320 (2.6380)  acc1: 93.7500 (93.0384)  acc5: 98.4375 (98.4530)  time: 0.0307  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427525706, Acc@5 = 98.39090099061795, loss = 2.638700564702352\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6230 (2.6230)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0290  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6430 (2.6380)  acc1: 92.9688 (93.0074)  acc5: 98.4375 (98.4607)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427525706, Acc@5 = 98.39090099101784, loss = 2.639528423945109\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6389 (2.6389)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0303  data: 0.0022  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6426 (2.6387)  acc1: 92.9688 (92.8991)  acc5: 97.6562 (98.3756)  time: 0.0307  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.638628145853678\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6354 (2.6354)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0354  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6399 (2.6388)  acc1: 92.1875 (92.9533)  acc5: 98.4375 (98.3292)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.638628158569336\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6302 (2.6302)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0368  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6303 (2.6376)  acc1: 92.9688 (93.0229)  acc5: 99.2188 (98.4994)  time: 0.0304  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.639051677385966\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6213 (2.6213)  acc1: 98.4375 (98.4375)  acc5: 98.4375 (98.4375)  time: 0.0355  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6349 (2.6396)  acc1: 93.7500 (92.8373)  acc5: 98.4375 (98.2983)  time: 0.0300  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 92.95036427485718, Acc@5 = 98.39090099061795, loss = 2.638628145853678\n",
      "Test:  [  0/150]  eta: 0:00:25  loss: 2.6327 (2.6327)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.1668  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6312 (2.6373)  acc1: 93.7500 (93.5876)  acc5: 98.4375 (98.5767)  time: 0.0300  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.4011216520782, Acc@5 = 98.64248650348551, loss = 2.6371370538075767\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6447 (2.6447)  acc1: 93.7500 (93.7500)  acc5: 97.6562 (97.6562)  time: 0.0352  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6367 (2.6365)  acc1: 92.9688 (93.3710)  acc5: 98.4375 (98.6696)  time: 0.0311  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.40112165247808, Acc@5 = 98.64248650348551, loss = 2.6371782143910725\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6312 (2.6312)  acc1: 95.3125 (95.3125)  acc5: 98.4375 (98.4375)  time: 0.0372  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6330 (2.6364)  acc1: 93.7500 (93.5566)  acc5: 99.2188 (98.6850)  time: 0.0310  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.4011216520782, Acc@5 = 98.64248650348551, loss = 2.637460592587789\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6273 (2.6273)  acc1: 91.4062 (91.4062)  acc5: 99.2188 (99.2188)  time: 0.0371  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6408 (2.6383)  acc1: 92.9688 (93.3787)  acc5: 99.2188 (98.6231)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.40112165247808, Acc@5 = 98.6424865038854, loss = 2.6380533329645792\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6553 (2.6553)  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.0349  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6329 (2.6366)  acc1: 92.9688 (93.4638)  acc5: 99.2188 (98.6928)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.40112165287798, Acc@5 = 98.6424865038854, loss = 2.6380785497029624\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6628 (2.6628)  acc1: 92.9688 (92.9688)  acc5: 97.6562 (97.6562)  time: 0.0338  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6289 (2.6368)  acc1: 93.7500 (93.3864)  acc5: 98.4375 (98.6231)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.4011216520782, Acc@5 = 98.64248650348551, loss = 2.6374473174413047\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6509 (2.6509)  acc1: 92.1875 (92.1875)  acc5: 96.8750 (96.8750)  time: 0.0337  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6360 (2.6381)  acc1: 93.7500 (93.2472)  acc5: 98.4375 (98.5767)  time: 0.0308  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.40112165247808, Acc@5 = 98.64248650348551, loss = 2.6374695269266764\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6353 (2.6353)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0330  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6371 (2.6383)  acc1: 92.9688 (93.4019)  acc5: 99.2188 (98.6154)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.40112165247808, Acc@5 = 98.64248650348551, loss = 2.637733966509501\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6278 (2.6278)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0355  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6355 (2.6380)  acc1: 93.7500 (93.2704)  acc5: 98.4375 (98.6077)  time: 0.0298  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.4011216520782, Acc@5 = 98.64248650348551, loss = 2.6371600087483724\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6316 (2.6316)  acc1: 95.3125 (95.3125)  acc5: 98.4375 (98.4375)  time: 0.0371  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6323 (2.6373)  acc1: 93.7500 (93.4793)  acc5: 98.4375 (98.6850)  time: 0.0301  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.4011216520782, Acc@5 = 98.64248650348551, loss = 2.6371467399597166\n",
      "Test:  [  0/150]  eta: 0:00:24  loss: 2.6150 (2.6150)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.1629  data: 0.0020  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6306 (2.6342)  acc1: 93.7500 (93.8583)  acc5: 99.2188 (98.8088)  time: 0.0300  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081345983, Acc@5 = 98.74731380051365, loss = 2.6347988160451252\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6539 (2.6539)  acc1: 92.1875 (92.1875)  acc5: 96.8750 (96.8750)  time: 0.0374  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6358 (2.6357)  acc1: 92.9688 (93.5489)  acc5: 98.4375 (98.8165)  time: 0.0310  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081385971, Acc@5 = 98.74731380051365, loss = 2.635254519780477\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6286 (2.6286)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6371 (2.6351)  acc1: 92.1875 (93.5876)  acc5: 98.4375 (98.7314)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081345983, Acc@5 = 98.74731380051365, loss = 2.6348126061757404\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6248 (2.6248)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6318 (2.6339)  acc1: 94.5312 (93.8274)  acc5: 99.2188 (98.8707)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081345983, Acc@5 = 98.74731380051365, loss = 2.6347988128662108\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6272 (2.6272)  acc1: 92.1875 (92.1875)  acc5: 99.2188 (99.2188)  time: 0.0317  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6324 (2.6343)  acc1: 93.7500 (93.7887)  acc5: 98.4375 (98.7624)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081385971, Acc@5 = 98.74731380051365, loss = 2.6348469400405885\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6255 (2.6255)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 0.0295  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6356 (2.6345)  acc1: 92.1875 (93.7191)  acc5: 99.2188 (98.7933)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081385971, Acc@5 = 98.74731380091353, loss = 2.6357060289382934\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6242 (2.6242)  acc1: 92.1875 (92.1875)  acc5: 99.2188 (99.2188)  time: 0.0297  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6350 (2.6358)  acc1: 93.7500 (93.5025)  acc5: 98.4375 (98.6618)  time: 0.0301  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081385971, Acc@5 = 98.74731380051365, loss = 2.634846960703532\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6403 (2.6403)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0332  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6343 (2.6352)  acc1: 93.7500 (93.6262)  acc5: 98.4375 (98.6928)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081345983, Acc@5 = 98.74731380051365, loss = 2.634832746187846\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6392 (2.6392)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0352  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6308 (2.6357)  acc1: 93.7500 (93.6262)  acc5: 98.4375 (98.6618)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081345983, Acc@5 = 98.74731380051365, loss = 2.635031992594401\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6633 (2.6633)  acc1: 92.1875 (92.1875)  acc5: 96.8750 (96.8750)  time: 0.0351  data: 0.0024  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6318 (2.6342)  acc1: 92.9688 (93.7191)  acc5: 99.2188 (98.7701)  time: 0.0297  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.70512081385971, Acc@5 = 98.74731380051365, loss = 2.6356903521219888\n",
      "Test:  [  0/150]  eta: 0:00:24  loss: 2.6462 (2.6462)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.1616  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6322 (2.6343)  acc1: 93.7500 (93.7964)  acc5: 99.2188 (98.8165)  time: 0.0302  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.80496881387913, loss = 2.634237360954285\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6424 (2.6424)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0332  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6391 (2.6359)  acc1: 92.9688 (93.7345)  acc5: 98.4375 (98.6850)  time: 0.0310  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265148223, Acc@5 = 98.80496881387913, loss = 2.6346504418055217\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6346 (2.6346)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0351  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6402 (2.6359)  acc1: 92.9688 (93.6726)  acc5: 98.4375 (98.7701)  time: 0.0311  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265148223, Acc@5 = 98.80496881387913, loss = 2.634283946355184\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6300 (2.6300)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 0.0370  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6338 (2.6352)  acc1: 93.7500 (93.7268)  acc5: 99.2188 (98.7392)  time: 0.0310  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265148223, Acc@5 = 98.80496881387913, loss = 2.634639612833659\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6427 (2.6427)  acc1: 89.0625 (89.0625)  acc5: 97.6562 (97.6562)  time: 0.0332  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6288 (2.6342)  acc1: 94.5312 (93.7345)  acc5: 99.2188 (98.8552)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.80496881387913, loss = 2.6344228092829387\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6293 (2.6293)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0308  data: 0.0020  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6339 (2.6344)  acc1: 94.5312 (93.8892)  acc5: 99.2188 (98.8629)  time: 0.0310  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265148223, Acc@5 = 98.80496881427902, loss = 2.635131009419759\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6243 (2.6243)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0331  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6389 (2.6352)  acc1: 93.7500 (93.6340)  acc5: 99.2188 (98.7469)  time: 0.0313  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.80496881387913, loss = 2.6342373736699423\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6215 (2.6215)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.0332  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6330 (2.6348)  acc1: 93.7500 (93.6494)  acc5: 98.4375 (98.8320)  time: 0.0308  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.80496881387913, loss = 2.634237380027771\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6379 (2.6379)  acc1: 89.0625 (89.0625)  acc5: 98.4375 (98.4375)  time: 0.0320  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6326 (2.6342)  acc1: 93.7500 (93.6572)  acc5: 98.4375 (98.8088)  time: 0.0307  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.80496881387913, loss = 2.6342373657226563\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6341 (2.6341)  acc1: 93.7500 (93.7500)  acc5: 97.6562 (97.6562)  time: 0.0310  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6371 (2.6344)  acc1: 92.1875 (93.8274)  acc5: 98.4375 (98.7933)  time: 0.0302  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.78898265108234, Acc@5 = 98.80496881387913, loss = 2.634994641939799\n",
      "Test:  [  0/150]  eta: 0:00:24  loss: 2.6391 (2.6391)  acc1: 96.0938 (96.0938)  acc5: 97.6562 (97.6562)  time: 0.1622  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6302 (2.6333)  acc1: 93.7500 (93.8970)  acc5: 99.2188 (98.8397)  time: 0.0304  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.83091357069337, Acc@5 = 98.8573824623932, loss = 2.633617951075236\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6474 (2.6474)  acc1: 90.6250 (90.6250)  acc5: 98.4375 (98.4375)  time: 0.0357  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6302 (2.6340)  acc1: 93.7500 (93.7268)  acc5: 99.2188 (98.7933)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.8573824623932, loss = 2.632966955502828\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6198 (2.6198)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.0310  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6292 (2.6320)  acc1: 94.5312 (93.9821)  acc5: 99.2188 (98.8784)  time: 0.0314  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.8573824623932, loss = 2.633161268234253\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6200 (2.6200)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0287  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6317 (2.6321)  acc1: 92.9688 (93.9511)  acc5: 98.4375 (98.8861)  time: 0.0313  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.83091357069337, Acc@5 = 98.8573824623932, loss = 2.633330880800883\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6407 (2.6407)  acc1: 92.9688 (92.9688)  acc5: 97.6562 (97.6562)  time: 0.0313  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6355 (2.6338)  acc1: 93.7500 (93.8815)  acc5: 99.2188 (98.7701)  time: 0.0314  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.83091357029349, Acc@5 = 98.8573824623932, loss = 2.633012534777323\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6368 (2.6368)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.0332  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6356 (2.6339)  acc1: 92.9688 (93.6804)  acc5: 98.4375 (98.7546)  time: 0.0314  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.83091357069337, Acc@5 = 98.8573824623932, loss = 2.633049268722534\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6491 (2.6491)  acc1: 92.1875 (92.1875)  acc5: 96.8750 (96.8750)  time: 0.0354  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6333 (2.6323)  acc1: 93.7500 (93.9356)  acc5: 99.2188 (98.9093)  time: 0.0314  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.8573824623932, loss = 2.6329898405075074\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6443 (2.6443)  acc1: 91.4062 (91.4062)  acc5: 98.4375 (98.4375)  time: 0.0355  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6336 (2.6333)  acc1: 93.7500 (93.8660)  acc5: 99.2188 (98.7856)  time: 0.0316  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.83091357029349, Acc@5 = 98.8573824623932, loss = 2.6330081192652384\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6368 (2.6368)  acc1: 92.1875 (92.1875)  acc5: 99.2188 (99.2188)  time: 0.0360  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6291 (2.6325)  acc1: 94.5312 (93.8815)  acc5: 98.4375 (98.9171)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.8573824623932, loss = 2.6329669427871703\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6324 (2.6324)  acc1: 96.0938 (96.0938)  acc5: 97.6562 (97.6562)  time: 0.0314  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6366 (2.6324)  acc1: 93.7500 (93.8970)  acc5: 98.4375 (98.9016)  time: 0.0297  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8309135698936, Acc@5 = 98.8573824623932, loss = 2.632989896138509\n",
      "Test:  [  0/150]  eta: 0:00:24  loss: 2.6334 (2.6334)  acc1: 92.1875 (92.1875)  acc5: 100.0000 (100.0000)  time: 0.1631  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6320 (2.6328)  acc1: 93.7500 (93.8041)  acc5: 99.2188 (98.8552)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.6325178384780883\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6331 (2.6331)  acc1: 95.3125 (95.3125)  acc5: 98.4375 (98.4375)  time: 0.0354  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6291 (2.6324)  acc1: 93.7500 (93.9821)  acc5: 99.2188 (98.9325)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.89905131336178, Acc@5 = 98.89931338120446, loss = 2.632562754948934\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6348 (2.6348)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0334  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6310 (2.6323)  acc1: 94.5312 (93.9898)  acc5: 99.2188 (98.8939)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.89905131336178, Acc@5 = 98.89931338120446, loss = 2.6325552654266358\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6358 (2.6358)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0358  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6339 (2.6327)  acc1: 92.9688 (93.8738)  acc5: 99.2188 (98.8629)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.632514108022054\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6087 (2.6087)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0336  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6347 (2.6325)  acc1: 92.9688 (93.8660)  acc5: 98.4375 (98.9171)  time: 0.0305  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.632773674329122\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6424 (2.6424)  acc1: 95.3125 (95.3125)  acc5: 97.6562 (97.6562)  time: 0.0331  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6304 (2.6332)  acc1: 93.7500 (93.9511)  acc5: 99.2188 (98.8475)  time: 0.0304  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.632514101664225\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6535 (2.6535)  acc1: 93.7500 (93.7500)  acc5: 96.8750 (96.8750)  time: 0.0335  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6326 (2.6336)  acc1: 93.7500 (93.8815)  acc5: 99.2188 (98.8552)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.632514093716939\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6454 (2.6454)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0300  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6311 (2.6334)  acc1: 94.5312 (93.9588)  acc5: 99.2188 (98.8629)  time: 0.0304  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.632514100074768\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6399 (2.6399)  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.0280  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6322 (2.6326)  acc1: 92.9688 (93.9434)  acc5: 98.4375 (98.8939)  time: 0.0304  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.89905131336178, Acc@5 = 98.89931338120446, loss = 2.63257510026296\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6483 (2.6483)  acc1: 91.4062 (91.4062)  acc5: 99.2188 (99.2188)  time: 0.0316  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6329 (2.6340)  acc1: 92.9688 (93.8970)  acc5: 98.4375 (98.7778)  time: 0.0305  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.8990513129619, Acc@5 = 98.89931338120446, loss = 2.63251406510671\n",
      "Test:  [  0/150]  eta: 0:00:24  loss: 2.6431 (2.6431)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.1665  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6275 (2.6319)  acc1: 94.5312 (93.9356)  acc5: 99.2188 (98.9635)  time: 0.0301  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.632253532409668\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6388 (2.6388)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.0326  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6297 (2.6322)  acc1: 93.7500 (93.8119)  acc5: 99.2188 (98.9016)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.6318122243881223\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6209 (2.6209)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0313  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6282 (2.6320)  acc1: 93.7500 (94.0981)  acc5: 99.2188 (98.9171)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.6319267670313518\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6263 (2.6263)  acc1: 96.8750 (96.8750)  acc5: 99.2188 (99.2188)  time: 0.0280  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6297 (2.6323)  acc1: 93.7500 (93.8583)  acc5: 99.2188 (98.8475)  time: 0.0304  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.6318534008661905\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6339 (2.6339)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 0.0345  data: 0.0016  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6239 (2.6302)  acc1: 94.5312 (94.1522)  acc5: 99.2188 (99.0408)  time: 0.0291  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.6318122053146364\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6582 (2.6582)  acc1: 92.1875 (92.1875)  acc5: 96.0938 (96.0938)  time: 0.0375  data: 0.0023  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6323 (2.6326)  acc1: 93.7500 (93.7964)  acc5: 99.2188 (98.9093)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.631812245051066\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6414 (2.6414)  acc1: 93.7500 (93.7500)  acc5: 96.8750 (96.8750)  time: 0.0376  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6341 (2.6336)  acc1: 93.7500 (93.8970)  acc5: 98.4375 (98.8552)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.6318534088134764\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6325 (2.6325)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 0.0363  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6354 (2.6328)  acc1: 93.7500 (94.0285)  acc5: 99.2188 (98.8784)  time: 0.0306  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813761881, Acc@5 = 98.9150374757587, loss = 2.6320184246699014\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6339 (2.6339)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0372  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6342 (2.6328)  acc1: 93.7500 (93.7113)  acc5: 98.4375 (98.8939)  time: 0.0306  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.92525813721893, Acc@5 = 98.9150374757587, loss = 2.6321354293823243\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6225 (2.6225)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.0351  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6283 (2.6306)  acc1: 93.7500 (94.0130)  acc5: 99.2188 (98.9944)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9252581380187, Acc@5 = 98.9150374757587, loss = 2.6319135856628417\n",
      "Test:  [  0/150]  eta: 0:00:24  loss: 2.6379 (2.6379)  acc1: 91.4062 (91.4062)  acc5: 97.6562 (97.6562)  time: 0.1639  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6311 (2.6321)  acc1: 93.7500 (93.7732)  acc5: 98.4375 (98.8552)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248912417, loss = 2.6312756745020547\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6480 (2.6480)  acc1: 92.9688 (92.9688)  acc5: 96.8750 (96.8750)  time: 0.0361  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6307 (2.6311)  acc1: 93.7500 (93.9666)  acc5: 99.2188 (99.0176)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.631240267753601\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6349 (2.6349)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0355  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6347 (2.6309)  acc1: 93.7500 (93.8738)  acc5: 98.4375 (99.0563)  time: 0.0293  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6313773806889853\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6259 (2.6259)  acc1: 92.1875 (92.1875)  acc5: 100.0000 (100.0000)  time: 0.0311  data: 0.0029  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6314 (2.6320)  acc1: 93.7500 (93.9124)  acc5: 99.2188 (98.9248)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6312344678243003\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6243 (2.6243)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.0291  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6366 (2.6318)  acc1: 92.9688 (93.9898)  acc5: 98.4375 (98.9171)  time: 0.0305  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6312402470906577\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6148 (2.6148)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.0301  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6300 (2.6310)  acc1: 95.3125 (94.0053)  acc5: 99.2188 (98.9635)  time: 0.0301  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248952405, loss = 2.6322337214152016\n",
      "Test:  [  0/150]  eta: 0:00:03  loss: 2.6208 (2.6208)  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.0265  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6361 (2.6314)  acc1: 93.7500 (93.8119)  acc5: 98.4375 (98.9403)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.631234499613444\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6375 (2.6375)  acc1: 91.4062 (91.4062)  acc5: 97.6562 (97.6562)  time: 0.0343  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6293 (2.6312)  acc1: 94.5312 (94.0130)  acc5: 99.2188 (98.9635)  time: 0.0309  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248912417, loss = 2.631696662902832\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6186 (2.6186)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.0314  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6338 (2.6316)  acc1: 93.7500 (93.8815)  acc5: 98.4375 (98.8861)  time: 0.0323  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.631237368583679\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6098 (2.6098)  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6272 (2.6314)  acc1: 94.5312 (93.7887)  acc5: 99.2188 (98.9712)  time: 0.0308  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248912417, loss = 2.6312756745020547\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6520 (2.6520)  acc1: 92.1875 (92.1875)  acc5: 97.6562 (97.6562)  time: 0.0352  data: 0.0018  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6333 (2.6323)  acc1: 94.5312 (93.8274)  acc5: 98.4375 (98.8784)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6307576004664104\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6395 (2.6395)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.0354  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6268 (2.6314)  acc1: 94.5312 (93.8428)  acc5: 99.2188 (98.9171)  time: 0.0306  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6307987435658773\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6265 (2.6265)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 0.0328  data: 0.0020  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6276 (2.6303)  acc1: 95.3125 (94.0517)  acc5: 99.2188 (98.9867)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.630757597287496\n",
      "Test:  [  0/150]  eta: 0:00:04  loss: 2.6288 (2.6288)  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.0314  data: 0.0020  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6316 (2.6313)  acc1: 93.7500 (93.9279)  acc5: 98.4375 (98.9403)  time: 0.0301  data: 0.0009  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248912417, loss = 2.6307735045750937\n",
      "Test:  [  0/150]  eta: 0:00:03  loss: 2.6360 (2.6360)  acc1: 92.1875 (92.1875)  acc5: 99.2188 (99.2188)  time: 0.0244  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6318 (2.6311)  acc1: 93.7500 (93.7423)  acc5: 99.2188 (98.9635)  time: 0.0321  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.6307164525985716\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6213 (2.6213)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.0365  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6262 (2.6313)  acc1: 93.7500 (93.8815)  acc5: 98.4375 (98.9712)  time: 0.0307  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248912417, loss = 2.6307576179504393\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6483 (2.6483)  acc1: 91.4062 (91.4062)  acc5: 97.6562 (97.6562)  time: 0.0351  data: 0.0019  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6211 (2.6309)  acc1: 94.5312 (93.8815)  acc5: 99.2188 (98.9558)  time: 0.0306  data: 0.0011  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248912417, loss = 2.630757582982381\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6206 (2.6206)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.0359  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6222 (2.6291)  acc1: 94.5312 (94.2141)  acc5: 99.2188 (99.1182)  time: 0.0294  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.96718905643007, Acc@5 = 98.97269248952405, loss = 2.631681450208028\n",
      "Test:  [  0/150]  eta: 0:00:05  loss: 2.6417 (2.6417)  acc1: 94.5312 (94.5312)  acc5: 97.6562 (97.6562)  time: 0.0337  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6302 (2.6314)  acc1: 92.9688 (93.8428)  acc5: 99.2188 (98.9248)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.630716420809428\n",
      "Test:  [  0/150]  eta: 0:00:03  loss: 2.6340 (2.6340)  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.0237  data: 0.0017  max mem: 0\n",
      "Test:  [100/150]  eta: 0:00:01  loss: 2.6327 (2.6315)  acc1: 93.7500 (94.1677)  acc5: 98.4375 (98.9093)  time: 0.0305  data: 0.0010  max mem: 0\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 93.9671890560302, Acc@5 = 98.97269248912417, loss = 2.630716431935628\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for time in range(1,11):\n",
    "    acc = 0\n",
    "    for i in range(10):\n",
    "        net = NetworkA().to(device)\n",
    "        functional.reset_net(net)\n",
    "        functional.set_step_mode(net,step_mode='m')\n",
    "        functional.set_backend(net, backend='cupy')\n",
    "        weights = torch.load(model_dir)\n",
    "        net.load_state_dict(weights)\n",
    "        net.set_T(time)\n",
    "        # print(net.T)\n",
    "        test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "        acc += test_acc1\n",
    "    acc_list.append(acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'a') as file:\n",
    "    line = ' '.join(map(str, acc_list))\n",
    "    file.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
