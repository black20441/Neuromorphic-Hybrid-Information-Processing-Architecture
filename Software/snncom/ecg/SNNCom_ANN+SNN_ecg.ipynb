{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import math\n",
    "import argparse\n",
    "import requests\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.cuda import amp\n",
    "import torch.distributed.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from spikingjelly.activation_based import layer,functional,neuron,surrogate\n",
    "\n",
    "from scipy.io import loadmat,savemat\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torchaudio\n",
    "from torchaudio import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "train_tb_writer = None\n",
    "te_tb_writer = None\n",
    "device = torch.device('cuda:0')\n",
    "deviceIds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "\n",
    "    parser.add_argument('--device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--data-path', default='./data/', help='dataset')\n",
    "    parser.add_argument('--epochs', default=320, type=int, metavar='N',\n",
    "                        help='number of total epochs to pre-train')\n",
    "    parser.add_argument('-j', '--workers', default=16, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', default=0.0025, type=float, help='initial learning rate')\n",
    "\n",
    "    parser.add_argument('--print-freq', default=10, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='./logs', help='path where to save')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--tb', action='store_true',\n",
    "                        help='Use TensorBoard to record logs')\n",
    "    parser.add_argument(\n",
    "        \"--cache-dataset\",\n",
    "        dest=\"cache_dataset\",\n",
    "        help=\"Cache the datasets for quicker initialization. It also serializes the transforms\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(args=['--data-path','../data','--lr','0.01','-b','128','--epochs','100','--print-freq','100','--tb','--cache-dataset'])\n",
    "    return args\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkA, self).__init__()\n",
    "        self.T = 10\n",
    "        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, padding=1) \n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.sn1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.sn2 = nn.ReLU()\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(96, 128, kernel_size=3, padding=1) \n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.sn3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.sn4 = nn.ReLU()\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.sn5 = nn.ReLU()\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1) \n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.sn8 = nn.ReLU()\n",
    "\n",
    "        self.conv10 = nn.Conv2d(256, 512, kernel_size=3, padding=1) \n",
    "        self.bn10 = nn.BatchNorm2d(512)\n",
    "        self.sn10 = nn.ReLU()\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 256, kernel_size=3, padding=1) \n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "        self.sn11 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.conv13 = layer.SeqToANNContainer(nn.Conv2d(256, 128, kernel_size=3, padding=1)) \n",
    "        self.bn13 = layer.SeqToANNContainer(nn.BatchNorm2d(128))\n",
    "        self.sn13 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.pool5 = layer.SeqToANNContainer(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.linear1 = layer.SeqToANNContainer(nn.Linear(2048, 256),nn.BatchNorm1d(256)) \n",
    "        # self.bn14 = layer.SeqToANNContainer(nn.BatchNorm1d(256))\n",
    "        self.sn14 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.linear3 = layer.SeqToANNContainer(nn.Linear(256, 8),nn.BatchNorm1d(8))\n",
    "        # self.bn15 = layer.SeqToANNContainer(nn.BatchNorm1d(8))\n",
    "        self.sn15 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        T = self.T\n",
    "        \n",
    "        x = self.sn1(self.bn1(self.conv1(x)))\n",
    "        x = self.sn2(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.sn3(self.bn3(self.conv3(x)))\n",
    "        x = self.sn4(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.sn5(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.sn8(self.bn8(self.conv8(x)))\n",
    "        x = self.sn10(self.bn10(self.conv10(x)))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "\n",
    "        x = self.bn11(self.conv11(x))\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.repeat(T, 1, 1, 1, 1)\n",
    "        x = self.sn11(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "        x = self.sn13(self.bn13(self.conv13(x)))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = torch.flatten(x,2)\n",
    "\n",
    "        x = self.sn14(self.linear1(x))\n",
    "\n",
    "        x = self.sn15(self.linear3(x))\n",
    "\n",
    "        return x.mean(0)\n",
    "    \n",
    "    def set_T(self, T):\n",
    "        self.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,random_split,Dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "args = parse_args()\n",
    "max_test_acc1 = 0.\n",
    "test_acc5_at_max_test_acc1 = 0.\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "print(args)\n",
    "output_dir = os.path.join(args.output_dir, f'b_{args.batch_size}_lr{args.lr}')\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "output_dir += f'_{time_now.year}_{time_now.month}_{time_now.day}_{time_now.hour}__{time_now.minute}'\n",
    "\n",
    "\n",
    "if output_dir:\n",
    "    utils.mkdir(output_dir)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.jpg_list = os.listdir(self.data_path)\n",
    "        self.label_list = []\n",
    "        self.data_set = []\n",
    "        \n",
    "        label_0 = 0\n",
    "        for i in range(len(self.jpg_list)):\n",
    "            if 'c' in self.jpg_list[i]:\n",
    "                label = int(self.jpg_list[i].split('c')[1].split('.')[0])\n",
    "                if label in [0, 1, 2, 4, 5, 7, 11, 25]:\n",
    "                    if label == 0 and label_0 < 6000:\n",
    "                        label = 0\n",
    "                        label_0 += 1\n",
    "                    elif label == 1:\n",
    "                        label = 1\n",
    "                    elif label == 2:\n",
    "                        label = 2\n",
    "                    elif label == 4:\n",
    "                        label = 3\n",
    "                    elif label == 5:\n",
    "                        label = 4\n",
    "                    elif label == 7:\n",
    "                        label = 5\n",
    "                    elif label == 11:\n",
    "                        label = 6\n",
    "                    elif label == 25:\n",
    "                        label = 7\n",
    "                    \n",
    "                    self.label_list.append(label)\n",
    "                    self.data_set.append(self.jpg_list[i])\n",
    "        \n",
    "        self.label_list = np.array(self.label_list)\n",
    "        self.data_set = [Image.open(os.path.join(self.data_path, i)) for i in self.data_set]\n",
    "        self.data_set = [self.transform(i) for i in self.data_set]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_set[idx], self.label_list[idx]\n",
    "\n",
    "# Parameters\n",
    "data_path = './ecg/data/mitbih_database/JPEG/'\n",
    "pickle_file = './ecg/data/mitbih_database/dataset.pkl'\n",
    "\n",
    "# Check if the dataset is already saved\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "else:\n",
    "    # Create the dataset\n",
    "    dataset = MyDataset(data_path=data_path, transform=transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "    \n",
    "    # Save the dataset to a pickle file\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "traindata, testdata = random_split(dataset, [round(len(dataset) * .8), round(len(dataset) * .2)])\n",
    "\n",
    "# Create data loaders\n",
    "data_loader = DataLoader(traindata, batch_size=args.batch_size, shuffle=True)\n",
    "data_loader_test = DataLoader(testdata, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Creating model\")\n",
    "\n",
    "net = NetworkA().to(device)\n",
    "functional.set_step_mode(net,step_mode='m')\n",
    "functional.set_backend(net, backend='cupy')\n",
    "net.to(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    args.start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc1 = checkpoint['max_test_acc1']\n",
    "    test_acc5_at_max_test_acc1 = checkpoint['test_acc5_at_max_test_acc1']\n",
    "\n",
    "\n",
    "if args.tb and utils.is_main_process():\n",
    "    purge_step_train = args.start_epoch\n",
    "    purge_step_te = args.start_epoch\n",
    "    train_tb_writer = SummaryWriter(output_dir + '_logs/train', purge_step=purge_step_train)\n",
    "    te_tb_writer = SummaryWriter(output_dir + '_logs/te', purge_step=purge_step_te)\n",
    "    with open(output_dir + '_logs/args.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "\n",
    "    with open(output_dir + '_logs/resluts.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('Results\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(net, criterion, data_loader, device, epoch, print_freq, scaler=None,lr = 1e-2):\n",
    "    net.train()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        functional.reset_net(net)\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        loss_s = loss.item()\n",
    "        if math.isnan(loss_s):\n",
    "            raise ValueError('loss is Nan')\n",
    "        acc1_s = acc1.item()\n",
    "        acc5_s = acc5.item()\n",
    "\n",
    "        metric_logger.update(loss=loss_s, lr=lr)\n",
    "\n",
    "        metric_logger.meters['acc1'].update(acc1_s, n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5_s, n=batch_size)\n",
    "        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n",
    "        \n",
    "    scheduler.step()\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    return metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg\n",
    "def evaluate(net, criterion, data_loader, device, print_freq=100, header='Test:'):\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    with torch.no_grad():\n",
    "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = net(image)\n",
    "            loss = criterion(output, target)\n",
    "            functional.reset_net(net)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    loss, acc1, acc5 = metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg\n",
    "    print(f' * Acc@1 = {acc1}, Acc@5 = {acc5}, loss = {loss}')\n",
    "    return loss, acc1, acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "cuda:0\n",
      "Epoch: [0]  [  0/560]  eta: 0:22:19  lr: 0.01  img/s: 53.83538075629321  loss: 2.1208 (2.1208)  acc1: 8.5938 (8.5938)  acc5: 74.2188 (74.2188)  time: 2.3918  data: 0.0142  max mem: 8056\n",
      "Epoch: [0]  [100/560]  eta: 0:01:02  lr: 0.01  img/s: 1150.4467077955612  loss: 1.3328 (1.5054)  acc1: 93.7500 (77.1040)  acc5: 100.0000 (99.1801)  time: 0.1128  data: 0.0015  max mem: 8056\n",
      "Epoch: [0]  [200/560]  eta: 0:00:44  lr: 0.01  img/s: 1148.6007278359823  loss: 1.3057 (1.4152)  acc1: 96.8750 (85.9103)  acc5: 100.0000 (99.5841)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [0]  [300/560]  eta: 0:00:31  lr: 0.01  img/s: 1148.9719086936236  loss: 1.3013 (1.3788)  acc1: 96.8750 (89.4830)  acc5: 100.0000 (99.7223)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [0]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.6706739932074  loss: 1.2990 (1.3593)  acc1: 97.6562 (91.4199)  acc5: 100.0000 (99.7915)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [0]  [500/560]  eta: 0:00:07  lr: 0.01  img/s: 1149.038304065406  loss: 1.2914 (1.3471)  acc1: 97.6562 (92.5945)  acc5: 100.0000 (99.8331)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [0] Total time: 0:01:06\n",
      "Test:  [  0/140]  eta: 0:11:24  loss: 1.2944 (1.2944)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 4.8889  data: 0.0053  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:03  loss: 1.2941 (1.2980)  acc1: 97.6562 (97.0838)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:12\n",
      " * Acc@1 = 97.16949527633142, Acc@5 = 100.0, loss = 1.2978153364998954\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:01:19 max_test_acc1 97.16949527633142 test_acc5_at_max_test_acc1 100.0 train_acc1 93.08434171676237 train_acc5 93.08434171676237\n",
      "Epoch: [1]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1119.1455593425262  loss: 1.2856 (1.2856)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0041  max mem: 8056\n",
      "Epoch: [1]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3999246394683  loss: 1.2940 (1.2932)  acc1: 97.6562 (97.7645)  acc5: 100.0000 (99.9923)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [1]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.8701255308986  loss: 1.2889 (1.2932)  acc1: 98.4375 (97.7262)  acc5: 100.0000 (99.9961)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [1]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.7149905773513  loss: 1.2900 (1.2925)  acc1: 98.4375 (97.8120)  acc5: 100.0000 (99.9974)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [1]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9719086936236  loss: 1.2876 (1.2923)  acc1: 97.6562 (97.8374)  acc5: 100.0000 (99.9981)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [1]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3753173852167  loss: 1.2892 (1.2920)  acc1: 97.6562 (97.8870)  acc5: 100.0000 (99.9984)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [1] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2966 (1.2966)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0409  data: 0.0052  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2905 (1.2888)  acc1: 98.4375 (98.2673)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.17999105040332, Acc@5 = 100.0, loss = 1.2894706061908177\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:02:27 max_test_acc1 98.17999105040332 test_acc5_at_max_test_acc1 100.0 train_acc1 97.9190218913936 train_acc5 97.9190218913936\n",
      "Epoch: [2]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.225235947504  loss: 1.2924 (1.2924)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1154  data: 0.0040  max mem: 8056\n",
      "Epoch: [2]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.6411315017451  loss: 1.2835 (1.2890)  acc1: 98.4375 (98.1358)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [2]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.5500517100725  loss: 1.2863 (1.2886)  acc1: 98.4375 (98.2587)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [2]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.51559284945  loss: 1.2859 (1.2880)  acc1: 98.4375 (98.3389)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [2]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.9809618465808  loss: 1.2861 (1.2878)  acc1: 98.4375 (98.3868)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [2]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0751936989  loss: 1.2852 (1.2875)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [2] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2949 (1.2949)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0409  data: 0.0053  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2927 (1.2912)  acc1: 97.6562 (98.1745)  acc5: 100.0000 (99.9923)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.1855738828522, Acc@5 = 99.99441715051363, loss = 1.290758580820901\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:03:36 max_test_acc1 98.1855738828522 test_acc5_at_max_test_acc1 99.99441715051363 train_acc1 98.42286702999559 train_acc5 98.42286702999559\n",
      "Epoch: [3]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1148.475416288741  loss: 1.2815 (1.2815)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1158  data: 0.0043  max mem: 8056\n",
      "Epoch: [3]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4466813254573  loss: 1.2842 (1.2861)  acc1: 99.2188 (98.6928)  acc5: 100.0000 (99.9923)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [3]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2941209211122  loss: 1.2846 (1.2855)  acc1: 99.2188 (98.6901)  acc5: 100.0000 (99.9961)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [3]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.478674934055  loss: 1.2832 (1.2856)  acc1: 99.2188 (98.6685)  acc5: 100.0000 (99.9974)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [3]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3679354143965  loss: 1.2850 (1.2857)  acc1: 98.4375 (98.6615)  acc5: 100.0000 (99.9981)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [3]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2473766456171  loss: 1.2849 (1.2856)  acc1: 98.4375 (98.6808)  acc5: 100.0000 (99.9984)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [3] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2932 (1.2932)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0454  data: 0.0098  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.3062 (1.3034)  acc1: 97.6562 (98.1049)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.0348369637575, Acc@5 = 100.0, loss = 1.3041203115667617\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:04:45 max_test_acc1 98.1855738828522 test_acc5_at_max_test_acc1 99.99441715051363 train_acc1 98.66711328370677 train_acc5 98.66711328370677\n",
      "Epoch: [4]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.9425334790167  loss: 1.2767 (1.2767)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1171  data: 0.0056  max mem: 8056\n",
      "Epoch: [4]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.454064307828  loss: 1.2861 (1.2840)  acc1: 98.4375 (98.8861)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [4]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.966990823175  loss: 1.2820 (1.2840)  acc1: 99.2188 (98.8689)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [4]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.98666255757  loss: 1.2806 (1.2838)  acc1: 99.2188 (98.8917)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [4]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2227759225962  loss: 1.2851 (1.2838)  acc1: 99.2188 (98.9070)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [4]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.5254380273939  loss: 1.2828 (1.2841)  acc1: 99.2188 (98.8788)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [4] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2784 (1.2784)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2821 (1.2859)  acc1: 98.4375 (98.7546)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.78852164441851, Acc@5 = 100.0, loss = 1.2856988983494895\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:05:53 max_test_acc1 98.78852164441851 test_acc5_at_max_test_acc1 100.0 train_acc1 98.89461121941616 train_acc5 98.89461121941616\n",
      "Epoch: [5]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.0653562317004  loss: 1.3058 (1.3058)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.1160  data: 0.0046  max mem: 8056\n",
      "Epoch: [5]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.9694497531368  loss: 1.2805 (1.2812)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [5]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.107166630637  loss: 1.2806 (1.2814)  acc1: 99.2188 (99.1838)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [5]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1489800723475  loss: 1.2781 (1.2814)  acc1: 99.2188 (99.1772)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [5]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.949778608131  loss: 1.2784 (1.2813)  acc1: 99.2188 (99.2012)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [5]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3261060374466  loss: 1.2786 (1.2813)  acc1: 99.2188 (99.1969)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [5] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2800 (1.2800)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2797 (1.2831)  acc1: 99.2188 (99.0176)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.02300132284637, Acc@5 = 100.0, loss = 1.2829444135938373\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:07:02 max_test_acc1 99.02300132284637 test_acc5_at_max_test_acc1 100.0 train_acc1 99.20585074225953 train_acc5 99.20585074225953\n",
      "Epoch: [6]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1148.7457302173514  loss: 1.2856 (1.2856)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1159  data: 0.0045  max mem: 8056\n",
      "Epoch: [6]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4762138240087  loss: 1.2785 (1.2805)  acc1: 99.2188 (99.3348)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [6]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.4417593899  loss: 1.2811 (1.2801)  acc1: 99.2188 (99.3587)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [6]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3777780632288  loss: 1.2785 (1.2799)  acc1: 99.2188 (99.3823)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [6]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9768266061722  loss: 1.2811 (1.2802)  acc1: 99.2188 (99.3473)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [6]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.6288225784  loss: 1.2805 (1.2803)  acc1: 99.2188 (99.3419)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [6] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2783 (1.2783)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0411  data: 0.0054  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2820 (1.2845)  acc1: 98.4375 (98.9325)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.98392135940422, Acc@5 = 100.0, loss = 1.2840866931847164\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:08:10 max_test_acc1 99.02300132284637 test_acc5_at_max_test_acc1 100.0 train_acc1 99.34123294477172 train_acc5 99.34123294477172\n",
      "Epoch: [7]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.8110472499259  loss: 1.2832 (1.2832)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1191  data: 0.0073  max mem: 8056\n",
      "Epoch: [7]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4983641938302  loss: 1.2766 (1.2794)  acc1: 100.0000 (99.4972)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [7]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1489800723475  loss: 1.2761 (1.2796)  acc1: 100.0000 (99.4403)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [7]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0751936989  loss: 1.2778 (1.2795)  acc1: 99.2188 (99.4394)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [7]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8588083234183  loss: 1.2758 (1.2795)  acc1: 100.0000 (99.4506)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [7]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0727343163085  loss: 1.2759 (1.2796)  acc1: 99.2188 (99.4371)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [7] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2881 (1.2881)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2822 (1.2823)  acc1: 99.2188 (99.1027)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.10674408217955, Acc@5 = 100.0, loss = 1.2824055348123824\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:09:19 max_test_acc1 99.10674408217955 test_acc5_at_max_test_acc1 100.0 train_acc1 99.4333486756263 train_acc5 99.4333486756263\n",
      "Epoch: [8]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.401716385665  loss: 1.2759 (1.2759)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1162  data: 0.0047  max mem: 8056\n",
      "Epoch: [8]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4294547354177  loss: 1.2791 (1.2789)  acc1: 99.2188 (99.5282)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [8]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.5057478401438  loss: 1.2780 (1.2789)  acc1: 99.2188 (99.5297)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [8]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0309264229365  loss: 1.2760 (1.2791)  acc1: 100.0000 (99.5120)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [8]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2473766456171  loss: 1.2761 (1.2790)  acc1: 100.0000 (99.5149)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [8]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0825719098407  loss: 1.2771 (1.2791)  acc1: 100.0000 (99.5057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [8] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2887 (1.2887)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2812 (1.2825)  acc1: 99.2188 (99.0408)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.039749854268, Acc@5 = 100.0, loss = 1.2824065574577876\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:10:28 max_test_acc1 99.10674408217955 test_acc5_at_max_test_acc1 100.0 train_acc1 99.50313332819933 train_acc5 99.50313332819933\n",
      "Epoch: [9]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1147.1380080297602  loss: 1.2755 (1.2755)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1180  data: 0.0064  max mem: 8056\n",
      "Epoch: [9]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3482506224457  loss: 1.2757 (1.2783)  acc1: 100.0000 (99.6597)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [9]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1637384841947  loss: 1.2753 (1.2782)  acc1: 100.0000 (99.6385)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [9]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2104759560327  loss: 1.2778 (1.2785)  acc1: 99.2188 (99.6055)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [9]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.8479608315165  loss: 1.2758 (1.2785)  acc1: 100.0000 (99.5948)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [9]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3088830612792  loss: 1.2766 (1.2786)  acc1: 100.0000 (99.5868)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [9] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2774 (1.2774)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2844 (1.2825)  acc1: 98.4375 (99.0950)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.10674406514204, Acc@5 = 99.99441715051363, loss = 1.2823275778974805\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:11:36 max_test_acc1 99.10674408217955 test_acc5_at_max_test_acc1 100.0 train_acc1 99.57710504911871 train_acc5 99.57710504911871\n",
      "Epoch: [10]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1144.9704347455188  loss: 1.2828 (1.2828)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1194  data: 0.0076  max mem: 8056\n",
      "Epoch: [10]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.372856717741  loss: 1.2760 (1.2775)  acc1: 100.0000 (99.6751)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [10]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.6509788302005  loss: 1.2760 (1.2774)  acc1: 99.2188 (99.6852)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [10]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1146.586774988574  loss: 1.2758 (1.2774)  acc1: 100.0000 (99.6859)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [10]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1147.5254130054227  loss: 1.2754 (1.2776)  acc1: 100.0000 (99.6844)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [10]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0727343163085  loss: 1.2752 (1.2776)  acc1: 100.0000 (99.6756)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [10] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2776 (1.2776)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2794 (1.2820)  acc1: 99.2188 (99.1182)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.12349263063868, Acc@5 = 100.0, loss = 1.2817893428461893\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:12:45 max_test_acc1 99.12349263063868 test_acc5_at_max_test_acc1 100.0 train_acc1 99.67480354589665 train_acc5 99.67480354589665\n",
      "Epoch: [11]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.6007278359823  loss: 1.2755 (1.2755)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1169  data: 0.0055  max mem: 8056\n",
      "Epoch: [11]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4983641938302  loss: 1.2747 (1.2769)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [11]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.5943589952228  loss: 1.2752 (1.2771)  acc1: 100.0000 (99.7318)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [11]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3384084793188  loss: 1.2748 (1.2772)  acc1: 100.0000 (99.7145)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [11]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.6928318582175  loss: 1.2752 (1.2774)  acc1: 99.2188 (99.6961)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [11]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.8194742833666  loss: 1.2744 (1.2773)  acc1: 100.0000 (99.7053)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [11] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2792 (1.2792)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2817 (1.2813)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.281780274425234\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:13:54 max_test_acc1 99.1681554094922 test_acc5_at_max_test_acc1 100.0 train_acc1 99.70550878951484 train_acc5 99.70550878951484\n",
      "Epoch: [12]  [  0/560]  eta: 0:01:09  lr: 0.01  img/s: 1147.471454860614  loss: 1.2753 (1.2753)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1235  data: 0.0119  max mem: 8056\n",
      "Epoch: [12]  [100/560]  eta: 0:00:52  lr: 0.01  img/s: 1149.1514397813305  loss: 1.2749 (1.2770)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [12]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3876208806382  loss: 1.2751 (1.2769)  acc1: 100.0000 (99.7629)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [12]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0678155827088  loss: 1.2749 (1.2768)  acc1: 100.0000 (99.7716)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [12]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.7814718599884  loss: 1.2750 (1.2770)  acc1: 100.0000 (99.7584)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [12]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.424532947388  loss: 1.2750 (1.2771)  acc1: 100.0000 (99.7521)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [12] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2844 (1.2844)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0409  data: 0.0052  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2807 (1.2822)  acc1: 99.2188 (99.1491)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19606967396159, Acc@5 = 100.0, loss = 1.2817639461585453\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:15:02 max_test_acc1 99.19606967396159 test_acc5_at_max_test_acc1 100.0 train_acc1 99.74458819048346 train_acc5 99.74458819048346\n",
      "Epoch: [13]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.22031590822  loss: 1.2749 (1.2749)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1156  data: 0.0042  max mem: 8056\n",
      "Epoch: [13]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.6646226788507  loss: 1.2748 (1.2769)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [13]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.016171422212  loss: 1.2748 (1.2770)  acc1: 100.0000 (99.7629)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [13]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2818194273189  loss: 1.2747 (1.2770)  acc1: 100.0000 (99.7560)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [13]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.631284341983  loss: 1.2748 (1.2771)  acc1: 100.0000 (99.7389)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [13]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.24491652592  loss: 1.2751 (1.2770)  acc1: 100.0000 (99.7474)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [13] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2780 (1.2780)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0410  data: 0.0053  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2813 (1.2815)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.15140684399556, Acc@5 = 100.0, loss = 1.2819660595485143\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:16:11 max_test_acc1 99.19606967396159 test_acc5_at_max_test_acc1 100.0 train_acc1 99.74458819378442 train_acc5 99.74458819378442\n",
      "Epoch: [14]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.1733067856892  loss: 1.2752 (1.2752)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1173  data: 0.0059  max mem: 8056\n",
      "Epoch: [14]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2080159943146  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1131  data: 0.0017  max mem: 8056\n",
      "Epoch: [14]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3384084793188  loss: 1.2743 (1.2766)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [14]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.424532947388  loss: 1.2753 (1.2766)  acc1: 100.0000 (99.7846)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [14]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2350761524547  loss: 1.2743 (1.2766)  acc1: 100.0000 (99.7818)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [14]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2178559043757  loss: 1.2754 (1.2767)  acc1: 100.0000 (99.7661)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [14] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2806 (1.2806)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2812 (1.2818)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2184010378321, Acc@5 = 100.0, loss = 1.2818476668425969\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:17:20 max_test_acc1 99.2184010378321 test_acc5_at_max_test_acc1 100.0 train_acc1 99.7613365131705 train_acc5 99.7613365131705\n",
      "Epoch: [15]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.5032866141664  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1157  data: 0.0044  max mem: 8056\n",
      "Epoch: [15]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2080159943146  loss: 1.2749 (1.2767)  acc1: 100.0000 (99.7834)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [15]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.8932278180332  loss: 1.2748 (1.2767)  acc1: 100.0000 (99.7785)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [15]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.748188200354  loss: 1.2750 (1.2766)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [15]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3999246394683  loss: 1.2743 (1.2765)  acc1: 100.0000 (99.7993)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [15]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0506003467244  loss: 1.2748 (1.2766)  acc1: 100.0000 (99.7864)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [15] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2790 (1.2790)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2750 (1.2818)  acc1: 99.2188 (99.1801)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281820538321, Acc@5 = 100.0, loss = 1.281616073846817\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:18:28 max_test_acc1 99.2184010378321 test_acc5_at_max_test_acc1 100.0 train_acc1 99.78645897723554 train_acc5 99.78645897723554\n",
      "Epoch: [16]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.2641685381243  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1169  data: 0.0054  max mem: 8056\n",
      "Epoch: [16]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.173577636029  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [16]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.313803858941  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.8173)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [16]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3703960608007  loss: 1.2747 (1.2766)  acc1: 100.0000 (99.7924)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [16]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2621375849844  loss: 1.2753 (1.2766)  acc1: 100.0000 (99.7896)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [16]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.5845126366933  loss: 1.2741 (1.2766)  acc1: 100.0000 (99.7926)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [16] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2922 (1.2922)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0462  data: 0.0105  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2184010719071, Acc@5 = 100.0, loss = 1.2815180242061615\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:19:37 max_test_acc1 99.2184010719071 test_acc5_at_max_test_acc1 100.0 train_acc1 99.79204174880248 train_acc5 99.79204174880248\n",
      "Epoch: [17]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.4606755513723  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1170  data: 0.0055  max mem: 8056\n",
      "Epoch: [17]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0874907697741  loss: 1.2745 (1.2765)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [17]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.6179295943998  loss: 1.2746 (1.2764)  acc1: 100.0000 (99.8095)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [17]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.696572766136  loss: 1.2745 (1.2767)  acc1: 100.0000 (99.7768)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [17]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0604375612659  loss: 1.2744 (1.2766)  acc1: 100.0000 (99.7857)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [17]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2104759560327  loss: 1.2754 (1.2765)  acc1: 100.0000 (99.7942)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [17] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0411  data: 0.0054  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2825 (1.2821)  acc1: 99.2188 (99.0950)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.14582401154668, Acc@5 = 100.0, loss = 1.2815611447606767\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:20:45 max_test_acc1 99.2184010719071 test_acc5_at_max_test_acc1 100.0 train_acc1 99.79622882747769 train_acc5 99.79622882747769\n",
      "Epoch: [18]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.2572172297312  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1158  data: 0.0045  max mem: 8056\n",
      "Epoch: [18]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2375362300227  loss: 1.2743 (1.2760)  acc1: 100.0000 (99.8376)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [18]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2621375849844  loss: 1.2744 (1.2765)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [18]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3630141531953  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [18]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8637252678116  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [18]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3630141531953  loss: 1.2751 (1.2764)  acc1: 100.0000 (99.7957)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [18] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2764 (1.2764)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2805 (1.2819)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0016  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398392139348, Acc@5 = 100.0, loss = 1.2816899393286023\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:21:54 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.79622883312128 train_acc5 99.79622883312128\n",
      "Epoch: [19]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.2006361723488  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1156  data: 0.0042  max mem: 8056\n",
      "Epoch: [19]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.331026982591  loss: 1.2747 (1.2766)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [19]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.8184092281729  loss: 1.2755 (1.2765)  acc1: 100.0000 (99.7785)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [19]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1440606859705  loss: 1.2744 (1.2764)  acc1: 100.0000 (99.7950)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [19]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3015019437928  loss: 1.2745 (1.2764)  acc1: 100.0000 (99.7993)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [19]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.3771518532462  loss: 1.2742 (1.2765)  acc1: 100.0000 (99.7879)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [19] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2866 (1.2866)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2817)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19048682447522, Acc@5 = 100.0, loss = 1.2816249234335764\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:23:03 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.79622882747769 train_acc5 99.79622882747769\n",
      "Epoch: [20]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.7851578436964  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1182  data: 0.0066  max mem: 8056\n",
      "Epoch: [20]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.407307021206  loss: 1.2744 (1.2767)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [20]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.289200291994  loss: 1.2742 (1.2766)  acc1: 100.0000 (99.7707)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [20]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.625301934305  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7898)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [20]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3630141531953  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [20]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1219239684847  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8004)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [20] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2821 (1.2821)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0463  data: 0.0106  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2803 (1.2819)  acc1: 99.2188 (99.1646)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2815444452422007\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:24:11 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.79902021326116 train_acc5 99.79902021326116\n",
      "Epoch: [21]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.2346982860026  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1161  data: 0.0046  max mem: 8056\n",
      "Epoch: [21]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0260080472563  loss: 1.2742 (1.2769)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [21]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.431915645239  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [21]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.7039461156126  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [21]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1637384841947  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7993)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [21]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3408689992978  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.7988)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [21] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2871 (1.2871)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0471  data: 0.0114  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2820 (1.2822)  acc1: 99.2188 (99.1491)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398392139348, Acc@5 = 100.0, loss = 1.2816249889986855\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:25:19 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80041590615289 train_acc5 99.80041590615289\n",
      "Epoch: [22]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.797733783726  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1173  data: 0.0057  max mem: 8056\n",
      "Epoch: [22]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0456818026162  loss: 1.2747 (1.2760)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [22]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2990415923653  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [22]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.313803858941  loss: 1.2747 (1.2765)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [22]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3950031043269  loss: 1.2746 (1.2765)  acc1: 100.0000 (99.7896)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [22]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.762936319266  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.8020)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [22] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2758 (1.2758)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2821 (1.2816)  acc1: 99.2188 (99.1801)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18490394091383, Acc@5 = 100.0, loss = 1.2816208464758736\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:26:28 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80041591413911 train_acc5 99.80041591413911\n",
      "Epoch: [23]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.7312692903295  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1181  data: 0.0065  max mem: 8056\n",
      "Epoch: [23]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0776530920189  loss: 1.2741 (1.2757)  acc1: 100.0000 (99.8530)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [23]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1194643858546  loss: 1.2745 (1.2761)  acc1: 100.0000 (99.8251)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [23]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0087940639532  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [23]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3088830612792  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7954)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [23]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.028467229833  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.7973)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [23] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2813 (1.2813)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2824)  acc1: 99.2188 (99.0873)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281822242072, Acc@5 = 100.0, loss = 1.2816071493285044\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:27:36 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80181159904463 train_acc5 99.80181159904463\n",
      "Epoch: [24]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1148.3329383430084  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1156  data: 0.0041  max mem: 8056\n",
      "Epoch: [24]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4122286617153  loss: 1.2744 (1.2764)  acc1: 100.0000 (99.7834)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [24]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.303962305754  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [24]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.454064307828  loss: 1.2748 (1.2761)  acc1: 100.0000 (99.8157)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [24]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2793591601608  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8110)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [24]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.5761547891311  loss: 1.2748 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [24] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2808 (1.2812)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2816558284418924\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:28:45 max_test_acc1 99.22398392139348 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80041590615289 train_acc5 99.80041590615289\n",
      "Epoch: [25]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.7043269128083  loss: 1.2778 (1.2778)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1183  data: 0.0066  max mem: 8056\n",
      "Epoch: [25]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1834169563506  loss: 1.2741 (1.2766)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [25]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.6228444771546  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8095)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [25]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.5614114656985  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [25]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1932564451636  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8032)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [25]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2744386574445  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [25] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2812)  acc1: 99.2188 (99.2961)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.26306386779812, Acc@5 = 100.0, loss = 1.2814575374126433\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:29:54 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879007148953 train_acc5 99.80879007148953\n",
      "Epoch: [26]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.9818074904044  loss: 1.2746 (1.2746)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1177  data: 0.0062  max mem: 8056\n",
      "Epoch: [26]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.966990823175  loss: 1.2756 (1.2768)  acc1: 99.2188 (99.7525)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [26]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0628968912195  loss: 1.2744 (1.2765)  acc1: 100.0000 (99.7823)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [26]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3064226782496  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [26]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3999246394683  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.7974)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [26]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2744386574445  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8004)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [26] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2821 (1.2821)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2810 (1.2818)  acc1: 99.2188 (99.1491)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.17932112550245, Acc@5 = 100.0, loss = 1.2816001457827433\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:31:02 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80181160703084 train_acc5 99.80181160703084\n",
      "Epoch: [27]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.7337186601562  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1180  data: 0.0064  max mem: 8056\n",
      "Epoch: [27]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1243835616438  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [27]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.5574360204187  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [27]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.5057478401438  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.7924)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [27]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1883366796953  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [27]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3211851344408  loss: 1.2752 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [27] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2814 (1.2814)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2833 (1.2815)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631530230148, Acc@5 = 100.0, loss = 1.2815163331372397\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:32:11 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80320729193636 train_acc5 99.80320729193636\n",
      "Epoch: [28]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1146.5402506764506  loss: 1.2749 (1.2749)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1178  data: 0.0062  max mem: 8056\n",
      "Epoch: [28]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1686580390513  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [28]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.6916572524049  loss: 1.2745 (1.2760)  acc1: 100.0000 (99.8329)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [28]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2793591601608  loss: 1.2743 (1.2760)  acc1: 100.0000 (99.8287)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [28]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.662165053446  loss: 1.2746 (1.2763)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [28]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.6154721687951  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.7988)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [28] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2785 (1.2785)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2823 (1.2814)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398390435598, Acc@5 = 100.0, loss = 1.2814516169684274\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:33:19 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80320729193636 train_acc5 99.80320729193636\n",
      "Epoch: [29]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.5108688456323  loss: 1.2747 (1.2747)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1181  data: 0.0064  max mem: 8056\n",
      "Epoch: [29]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.5598974782827  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [29]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.728524630853  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [29]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.7653943759015  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [29]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1317624042963  loss: 1.2818 (1.2763)  acc1: 99.2188 (99.7896)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [29]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7432722448673  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8020)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [29] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2757 (1.2757)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2785 (1.2810)  acc1: 100.0000 (99.3038)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631530230148, Acc@5 = 100.0, loss = 1.281511540072305\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:34:28 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80320729193636 train_acc5 99.80320729193636\n",
      "Epoch: [30]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.0583480321377  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1195  data: 0.0077  max mem: 8056\n",
      "Epoch: [30]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3457900708613  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [30]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2793591601608  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [30]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3334874709653  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.7975)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [30]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.5475902943722  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.7954)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [30]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.24491652592  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8004)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [30] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2783 (1.2783)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2796 (1.2815)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2815022213118417\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:35:36 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460299281432 train_acc5 99.80460299281432\n",
      "Epoch: [31]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1146.6871824226334  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1172  data: 0.0055  max mem: 8056\n",
      "Epoch: [31]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.9620729948251  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [31]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0751936989  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [31]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1686580390513  loss: 1.2746 (1.2763)  acc1: 100.0000 (99.7975)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [31]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.311343454843  loss: 1.2745 (1.2764)  acc1: 100.0000 (99.7857)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [31]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2301560289154  loss: 1.2740 (1.2763)  acc1: 100.0000 (99.7988)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [31] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2782 (1.2782)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0112  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2827 (1.2820)  acc1: 99.2188 (99.1337)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18490397498883, Acc@5 = 100.0, loss = 1.2815156323569161\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:36:45 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460299281432 train_acc5 99.80460299281432\n",
      "Epoch: [32]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.6716744059  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1188  data: 0.0071  max mem: 8056\n",
      "Epoch: [32]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2104759560327  loss: 1.2743 (1.2766)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [32]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9301081366807  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7823)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [32]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2965812514717  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8001)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [32]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8883106211053  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [32]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.038304065406  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [32] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2777 (1.2777)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0464  data: 0.0107  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2813)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281820538321, Acc@5 = 100.0, loss = 1.2816097744873591\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:37:53 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [33]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.1511600376264  loss: 1.2747 (1.2747)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1183  data: 0.0066  max mem: 8056\n",
      "Epoch: [33]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4097678361923  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [33]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3777780632288  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [33]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.5992822377395  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7820)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [33]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.792433693175  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8052)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [33]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.215395911063  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [33] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2770 (1.2770)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2827 (1.2811)  acc1: 99.2188 (99.2652)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398390435598, Acc@5 = 100.0, loss = 1.281572323186057\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:39:02 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [34]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.1070113384117  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1162  data: 0.0047  max mem: 8056\n",
      "Epoch: [34]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.7322257272144  loss: 1.2747 (1.2769)  acc1: 100.0000 (99.7447)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [34]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.190796557164  loss: 1.2742 (1.2765)  acc1: 100.0000 (99.7746)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [34]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1147.8983534281665  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7794)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [34]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2670579823694  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7915)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [34]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1834169563506  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [34] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2784 (1.2815)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956675384235, Acc@5 = 100.0, loss = 1.2815346785954067\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:40:10 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [35]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1142.7867115376837  loss: 1.2746 (1.2746)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1200  data: 0.0080  max mem: 8056\n",
      "Epoch: [35]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.198176252756  loss: 1.2818 (1.2767)  acc1: 99.2188 (99.7602)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [35]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3703960608007  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [35]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2645977784105  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7950)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [35]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.762936319266  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7954)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [35]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.313803858941  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [35] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2852 (1.2852)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2789 (1.2817)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2815148617540086\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:41:19 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [36]  [  0/560]  eta: 0:01:11  lr: 0.01  img/s: 1145.91376473024  loss: 1.2820 (1.2820)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1275  data: 0.0158  max mem: 8056\n",
      "Epoch: [36]  [100/560]  eta: 0:00:52  lr: 0.01  img/s: 1148.7506461938754  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [36]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0087940639532  loss: 1.2748 (1.2763)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [36]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.114545252181  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [36]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.5672819151214  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8266)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [36]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.9940396316342  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [36] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2808 (1.2813)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514962036623, Acc@5 = 100.0, loss = 1.2816002939428601\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:42:27 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80739437061158 train_acc5 99.80739437061158\n",
      "Epoch: [37]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.378669240411  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1180  data: 0.0063  max mem: 8056\n",
      "Epoch: [37]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.927649375107  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [37]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2916606012861  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [37]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2178559043757  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.7975)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [37]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3187246987397  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7876)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [37]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.089950215533  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [37] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2753 (1.2753)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0111  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2813 (1.2821)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.281596302986145\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:43:36 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018576438126 train_acc5 99.81018576438126\n",
      "Epoch: [38]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.569564353092  loss: 1.2820 (1.2820)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1163  data: 0.0048  max mem: 8056\n",
      "Epoch: [38]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.9792855782339  loss: 1.2746 (1.2764)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [38]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.4466813254573  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7707)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [38]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.107166630637  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.7898)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [38]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.311343454843  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [38]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.9006036923458  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [38] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2762 (1.2762)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0414  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2822 (1.2816)  acc1: 99.2188 (99.1723)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0015  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.16257256000581, Acc@5 = 100.0, loss = 1.2815830775669643\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:44:44 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [39]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.234263778401  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0068  max mem: 8056\n",
      "Epoch: [39]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.866183755791  loss: 1.2743 (1.2760)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [39]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.8096411941933  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8095)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [39]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.040763300616  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [39]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3211851344408  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8110)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [39]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.8637252678116  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [39] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2829 (1.2829)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2832 (1.2815)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514962036623, Acc@5 = 100.0, loss = 1.2816198136125292\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:45:53 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [40]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.5543340957972  loss: 1.2814 (1.2814)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1194  data: 0.0076  max mem: 8056\n",
      "Epoch: [40]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0850313345434  loss: 1.2743 (1.2769)  acc1: 100.0000 (99.7447)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [40]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.2617126260022  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [40]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.09240967182  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8001)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [40]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9915805964208  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [40]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0530596345689  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [40] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2836 (1.2836)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2794 (1.2812)  acc1: 99.2188 (99.2884)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281820538321, Acc@5 = 100.0, loss = 1.2816291102341244\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:47:01 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [41]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1145.6838987373108  loss: 1.2743 (1.2743)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1198  data: 0.0081  max mem: 8056\n",
      "Epoch: [41]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1612787225617  loss: 1.2741 (1.2759)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [41]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.4712916355322  loss: 1.2741 (1.2758)  acc1: 100.0000 (99.8484)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [41]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1563592308862  loss: 1.2743 (1.2758)  acc1: 100.0000 (99.8495)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [41]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0235488752057  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8208)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [41]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2818194273189  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8176)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [41] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2830 (1.2830)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2827 (1.2813)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19048680743771, Acc@5 = 100.0, loss = 1.281667059659958\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:48:10 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [42]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1147.3954315415128  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1179  data: 0.0063  max mem: 8056\n",
      "Epoch: [42]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2424564167552  loss: 1.2744 (1.2761)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [42]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1416010085768  loss: 1.2740 (1.2760)  acc1: 100.0000 (99.8368)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [42]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3285665047515  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [42]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3211851344408  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [42]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.8833934662678  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8035)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [42] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2868 (1.2868)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2827 (1.2817)  acc1: 99.2188 (99.1801)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19048680743771, Acc@5 = 100.0, loss = 1.2816796720027923\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:49:18 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [43]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.2494332229721  loss: 1.2814 (1.2814)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1170  data: 0.0055  max mem: 8056\n",
      "Epoch: [43]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.7014883219363  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [43]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.5598974782827  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [43]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3384084793188  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.7950)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [43]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9178144340488  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7915)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [43]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.5614114656985  loss: 1.2744 (1.2764)  acc1: 100.0000 (99.7910)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [43] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2918 (1.2918)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2798 (1.2821)  acc1: 99.2188 (99.1414)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0015  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398392139348, Acc@5 = 100.0, loss = 1.2814872707639422\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:50:27 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [44]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1145.217114553514  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1197  data: 0.0079  max mem: 8056\n",
      "Epoch: [44]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.673135936031  loss: 1.2742 (1.2766)  acc1: 100.0000 (99.7602)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [44]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.7850592076827  loss: 1.2743 (1.2765)  acc1: 100.0000 (99.7629)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [44]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0702749442448  loss: 1.2743 (1.2765)  acc1: 100.0000 (99.7716)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [44]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.303962305754  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8032)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [44]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7555622124746  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8098)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [44] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2798 (1.2814)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25748101831175, Acc@5 = 100.0, loss = 1.2815470014299666\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:51:35 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460298482811 train_acc5 99.80460298482811\n",
      "Epoch: [45]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.2146861776398  loss: 1.2813 (1.2813)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1183  data: 0.0066  max mem: 8056\n",
      "Epoch: [45]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.7776848168683  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [45]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9227318835308  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8095)  acc5: 100.0000 (100.0000)  time: 0.1135  data: 0.0021  max mem: 8056\n",
      "Epoch: [45]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.966990823175  loss: 1.2746 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [45]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9006036923458  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [45]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.508209076661  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [45] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2785 (1.2785)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2813 (1.2814)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18490397498883, Acc@5 = 100.0, loss = 1.2815634080341884\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:52:44 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81297714217853 train_acc5 99.81297714217853\n",
      "Epoch: [46]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.9719887356227  loss: 1.2793 (1.2793)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1173  data: 0.0058  max mem: 8056\n",
      "Epoch: [46]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.3722390728676  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [46]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.944860927124  loss: 1.2748 (1.2765)  acc1: 100.0000 (99.7785)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [46]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1784972751286  loss: 1.2744 (1.2764)  acc1: 100.0000 (99.7924)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [46]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9227318835308  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8032)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [46]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1144.0944818797495  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7988)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [46] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2891 (1.2891)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0414  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2773 (1.2814)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956677087986, Acc@5 = 100.0, loss = 1.281512702362878\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:53:52 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460298482811 train_acc5 99.80460298482811\n",
      "Epoch: [47]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.8072046208003  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0068  max mem: 8056\n",
      "Epoch: [47]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.4287385851464  loss: 1.2741 (1.2760)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [47]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.232616085419  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [47]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.627759401971  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [47]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1146.1265952495826  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8130)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [47]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1612787225617  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.8035)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [47] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0415  data: 0.0058  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2820 (1.2820)  acc1: 99.2188 (99.1414)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19606967396159, Acc@5 = 100.0, loss = 1.2816717335156032\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:55:01 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [48]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1149.1563592308862  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1158  data: 0.0044  max mem: 8056\n",
      "Epoch: [48]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0260080472563  loss: 1.2746 (1.2772)  acc1: 100.0000 (99.7138)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [48]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9350256913992  loss: 1.2741 (1.2766)  acc1: 100.0000 (99.7668)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [48]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.7408142829022  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [48]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.5466685207568  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [48]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.028467229833  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8020)  acc5: 100.0000 (100.0000)  time: 0.1134  data: 0.0020  max mem: 8056\n",
      "Epoch: [48] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2864 (1.2864)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0414  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2811)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165250641047, Acc@5 = 100.0, loss = 1.2815783739089965\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:56:09 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599868570606 train_acc5 99.80599868570606\n",
      "Epoch: [49]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.1315643151042  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1171  data: 0.0056  max mem: 8056\n",
      "Epoch: [49]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4835971857644  loss: 1.2750 (1.2763)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [49]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.407307021206  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8290)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [49]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0579782418397  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8391)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [49]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.716235241759  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8208)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [49]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3064226782496  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [49] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2793 (1.2793)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2791 (1.2814)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.17932112550245, Acc@5 = 100.0, loss = 1.2815854728221894\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:57:18 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [50]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1148.4508486033449  loss: 1.2835 (1.2835)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1159  data: 0.0044  max mem: 8056\n",
      "Epoch: [50]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.215395911063  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [50]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2793591601608  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [50]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.6214373509094  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [50]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.198176252756  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [50]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0456818026162  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8113)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [50] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2797 (1.2797)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0414  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2795 (1.2816)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2815548649856023\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:58:26 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [51]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.1755329823527  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1186  data: 0.0069  max mem: 8056\n",
      "Epoch: [51]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1858768127574  loss: 1.2744 (1.2760)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [51]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3408689992978  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [51]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0628968912195  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [51]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9546963312353  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8227)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [51]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.6891995113153  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [51] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2767 (1.2767)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2832 (1.2817)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2407324357776, Acc@5 = 100.0, loss = 1.2815505044800894\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 0:59:35 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [52]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.77291000047  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0069  max mem: 8056\n",
      "Epoch: [52]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0874907697741  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [52]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0210897136815  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8290)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [52]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3408689992978  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8053)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [52]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9694497531368  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8149)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [52]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1293027795496  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [52] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2799 (1.2818)  acc1: 99.2188 (99.1801)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2184010719071, Acc@5 = 100.0, loss = 1.281564212696893\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:00:44 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [53]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.6137190983616  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1176  data: 0.0061  max mem: 8056\n",
      "Epoch: [53]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1957163436944  loss: 1.2741 (1.2767)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [53]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.7998082733475  loss: 1.2744 (1.2764)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [53]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.09240967182  loss: 1.2748 (1.2765)  acc1: 100.0000 (99.7846)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [53]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2670579823694  loss: 1.2747 (1.2764)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [53]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7236088436612  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [53] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2776 (1.2776)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2801 (1.2809)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19606965692408, Acc@5 = 100.0, loss = 1.2816133626869746\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:01:52 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81297714217853 train_acc5 99.81297714217853\n",
      "Epoch: [54]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.4175017899315  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1165  data: 0.0049  max mem: 8056\n",
      "Epoch: [54]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.508209076661  loss: 1.2749 (1.2771)  acc1: 100.0000 (99.7215)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [54]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3187246987397  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7785)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [54]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0997881038504  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8001)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [54]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.016171422212  loss: 1.2746 (1.2763)  acc1: 100.0000 (99.8032)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [54]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.5106703237175  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.7973)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [54] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2876 (1.2876)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0468  data: 0.0111  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2777 (1.2815)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281822242072, Acc@5 = 100.0, loss = 1.2815118380955288\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:03:01 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [55]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.5500449547142  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1180  data: 0.0064  max mem: 8056\n",
      "Epoch: [55]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1661982563578  loss: 1.2743 (1.2757)  acc1: 100.0000 (99.8685)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [55]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.7727686089231  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8368)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [55]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.9055209945022  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8365)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [55]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9891215717328  loss: 1.2748 (1.2761)  acc1: 100.0000 (99.8227)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [55]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2350761524547  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8207)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [55] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2951 (1.2951)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2806 (1.2812)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281822242072, Acc@5 = 100.0, loss = 1.281589833327702\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:04:09 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [56]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1145.0266000102374  loss: 1.2752 (1.2752)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1198  data: 0.0080  max mem: 8056\n",
      "Epoch: [56]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.5845126366933  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [56]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2129359282821  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [56]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.5303606796065  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8209)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [56]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0506003467244  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8149)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [56]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.907979661365  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [56] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2813)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631530230148, Acc@5 = 100.0, loss = 1.2815140000411442\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:05:18 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [57]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.2489474178644  loss: 1.2747 (1.2747)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1186  data: 0.0069  max mem: 8056\n",
      "Epoch: [57]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1170048137533  loss: 1.2742 (1.2766)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [57]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0997881038504  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [57]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1147.7265744416582  loss: 1.2740 (1.2762)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [57]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8219325819616  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8110)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [57]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2793591601608  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [57] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2918 (1.2918)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2769 (1.2814)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398390435598, Acc@5 = 100.0, loss = 1.2814232579299383\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:06:26 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [58]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.4739073934752  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1174  data: 0.0058  max mem: 8056\n",
      "Epoch: [58]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.728524630853  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [58]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.09240967182  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [58]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2424564167552  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8157)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [58]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0432225463526  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8110)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [58]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1120857011376  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8051)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [58] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2789 (1.2789)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2822 (1.2818)  acc1: 99.2188 (99.1105)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.17932112550245, Acc@5 = 100.0, loss = 1.2815737281526838\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:07:35 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81297714217853 train_acc5 99.81297714217853\n",
      "Epoch: [59]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.5378021330303  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1187  data: 0.0071  max mem: 8056\n",
      "Epoch: [59]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1142.667529371701  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [59]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.126843165332  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7862)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [59]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8022664877785  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [59]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8047247127297  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7974)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [59]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.78014293662  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7988)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [59] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2743 (1.2743)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2817)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18490397498883, Acc@5 = 100.0, loss = 1.2816380969115666\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:08:43 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80739437061158 train_acc5 99.80739437061158\n",
      "Epoch: [60]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.7067761675405  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1184  data: 0.0068  max mem: 8056\n",
      "Epoch: [60]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.8342242327494  loss: 1.2742 (1.2767)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [60]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3974638666293  loss: 1.2741 (1.2765)  acc1: 100.0000 (99.7823)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [60]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1760374503135  loss: 1.2748 (1.2764)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [60]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9055209945022  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [60]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0751936989  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [60] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2799 (1.2817)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956677087986, Acc@5 = 100.0, loss = 1.2816959576947349\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:09:52 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [61]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.3123956011136  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1194  data: 0.0077  max mem: 8056\n",
      "Epoch: [61]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2227759225962  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [61]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1489800723475  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [61]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.232616085419  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [61]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9989577336378  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8227)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [61]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.6189756294982  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [61] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2906 (1.2906)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2791 (1.2811)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2816201320716314\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:11:00 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [62]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.8219029431493  loss: 1.2743 (1.2743)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0069  max mem: 8056\n",
      "Epoch: [62]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0137122922663  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [62]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.53528337398  loss: 1.2747 (1.2761)  acc1: 100.0000 (99.8251)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [62]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.83176588155  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [62]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.436837496494  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [62]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.508209076661  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8098)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [62] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2743 (1.2743)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0109  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2804 (1.2812)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2184010548696, Acc@5 = 100.0, loss = 1.2816660872527532\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:12:09 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80320729992259 train_acc5 99.80320729992259\n",
      "Epoch: [63]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.6602421166842  loss: 1.2837 (1.2837)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1184  data: 0.0068  max mem: 8056\n",
      "Epoch: [63]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.98666255757  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [63]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.4023854228442  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [63]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8489745608929  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [63]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8170159952924  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8032)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [63]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.3605535383983  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.7973)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [63] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2883 (1.2883)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0469  data: 0.0112  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2772 (1.2814)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398392139348, Acc@5 = 100.0, loss = 1.2814202887671335\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:13:17 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80739437061158 train_acc5 99.80739437061158\n",
      "Epoch: [64]  [  0/560]  eta: 0:01:04  lr: 0.01  img/s: 1147.7069458310264  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1159  data: 0.0044  max mem: 8056\n",
      "Epoch: [64]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.8194742833666  loss: 1.2742 (1.2757)  acc1: 100.0000 (99.8530)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [64]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.792433693175  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [64]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2227759225962  loss: 1.2748 (1.2763)  acc1: 100.0000 (99.7924)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [64]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2842797050102  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [64]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.198176252756  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8051)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [64] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.3038 (1.3038)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2813 (1.2815)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.281606434924262\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:14:26 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018576438126 train_acc5 99.81018576438126\n",
      "Epoch: [65]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.2568008332746  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1171  data: 0.0057  max mem: 8056\n",
      "Epoch: [65]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.001416800428  loss: 1.2741 (1.2760)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [65]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1711178322748  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [65]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.6867417807428  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8001)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [65]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9891215717328  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7915)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [65]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.5549745730957  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7926)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [65] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2805 (1.2805)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2780 (1.2811)  acc1: 99.2188 (99.2652)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.281652148280825\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:15:34 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80320729193636 train_acc5 99.80320729193636\n",
      "Epoch: [66]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.3059206515904  loss: 1.2811 (1.2811)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1175  data: 0.0061  max mem: 8056\n",
      "Epoch: [66]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2473766456171  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [66]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.6818263511489  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [66]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.5426674945934  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [66]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9350256913992  loss: 1.2751 (1.2764)  acc1: 99.2188 (99.7954)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [66]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.98666255757  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [66] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2796 (1.2796)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2780 (1.2808)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398388731847, Acc@5 = 100.0, loss = 1.2815222229276384\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:16:43 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80739437061158 train_acc5 99.80739437061158\n",
      "Epoch: [67]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.5842822239845  loss: 1.2815 (1.2815)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1174  data: 0.0059  max mem: 8056\n",
      "Epoch: [67]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3950031043269  loss: 1.2744 (1.2761)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [67]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1391413417125  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [67]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.358092934137  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8157)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [67]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0210897136815  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8169)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [67]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.426993836134  loss: 1.2746 (1.2762)  acc1: 100.0000 (99.8113)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [67] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2788 (1.2788)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2810)  acc1: 99.2188 (99.3116)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398388731847, Acc@5 = 100.0, loss = 1.2815978808062418\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:17:51 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [68]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.116832403071  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1174  data: 0.0059  max mem: 8056\n",
      "Epoch: [68]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0776530920189  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [68]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1858768127574  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8212)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [68]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8809349046328  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [68]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2498367758467  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8013)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [68]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7334404601174  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8035)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [68] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2758 (1.2758)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2781 (1.2815)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21281820538321, Acc@5 = 100.0, loss = 1.2816164578710283\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:19:00 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [69]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1140.3569134564734  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1186  data: 0.0064  max mem: 8056\n",
      "Epoch: [69]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.87601781293  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [69]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.316264273573  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [69]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.9596140964375  loss: 1.2746 (1.2765)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [69]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.426993836134  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7954)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [69]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.514726771748  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8035)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [69] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2888 (1.2888)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2796 (1.2819)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723533885933, Acc@5 = 100.0, loss = 1.281665951013565\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:20:08 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158145727301 train_acc5 99.81158145727301\n",
      "Epoch: [70]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.040723546481  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1172  data: 0.0057  max mem: 8056\n",
      "Epoch: [70]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.8784763535202  loss: 1.2747 (1.2764)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [70]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3408689992978  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [70]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0997881038504  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [70]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.920273153528  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [70]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.5426674945934  loss: 1.2749 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [70] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2814 (1.2814)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2814885667392186\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:21:17 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [71]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.8905000961313  loss: 1.2752 (1.2752)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1183  data: 0.0067  max mem: 8056\n",
      "Epoch: [71]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0235488752057  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [71]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.920273153528  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8173)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [71]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8538914211124  loss: 1.2747 (1.2761)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [71]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.927649375107  loss: 1.2750 (1.2762)  acc1: 100.0000 (99.8052)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [71]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7899755208243  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8098)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [71] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2822 (1.2822)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2809 (1.2812)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2816136487892695\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:22:25 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [72]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.040723546481  loss: 1.2895 (1.2895)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1176  data: 0.0061  max mem: 8056\n",
      "Epoch: [72]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.8932278180332  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [72]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.3088830612792  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [72]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8956864322813  loss: 1.2748 (1.2765)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [72]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8170159952924  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8032)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [72]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.920273153528  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8160)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [72] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2838 (1.2838)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0108  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2823 (1.2816)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514958629123, Acc@5 = 100.0, loss = 1.2815166984285626\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:23:34 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879007148953 train_acc5 99.80879007148953\n",
      "Epoch: [73]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1147.7879181774647  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1172  data: 0.0057  max mem: 8056\n",
      "Epoch: [73]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.925190624057  loss: 1.2741 (1.2758)  acc1: 100.0000 (99.8530)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [73]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1391413417125  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8290)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [73]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.4122286617153  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [73]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0628968912195  loss: 1.2746 (1.2762)  acc1: 100.0000 (99.8169)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [73]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1711178322748  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8191)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [73] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2918 (1.2918)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2823 (1.2815)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2817081085273199\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:24:42 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [74]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.6063653022259  loss: 1.2814 (1.2814)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0068  max mem: 8056\n",
      "Epoch: [74]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.4048462167566  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [74]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.8415993494752  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [74]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.6165139186296  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.8001)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [74]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0333856265663  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8130)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [74]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.4835971857644  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8160)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [74] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.3033 (1.3033)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2816 (1.2815)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2184010548696, Acc@5 = 100.0, loss = 1.2814423833574569\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:25:51 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [75]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.42273238793  loss: 1.2747 (1.2747)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1184  data: 0.0068  max mem: 8056\n",
      "Epoch: [75]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1317624042963  loss: 1.2746 (1.2764)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [75]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2990415923653  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [75]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0948691386352  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7898)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [75]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9473197623654  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.7974)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [75]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.9350256913992  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [75] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2846 (1.2846)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2821 (1.2811)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2814717965466635\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:26:59 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599868570606 train_acc5 99.80599868570606\n",
      "Epoch: [76]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1147.4763599368202  loss: 1.2747 (1.2747)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1182  data: 0.0066  max mem: 8056\n",
      "Epoch: [76]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3064226782496  loss: 1.2747 (1.2761)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [76]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9350256913992  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [76]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.468830557102  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.7950)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [76]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.4097678361923  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [76]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2498367758467  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8020)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [76] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2785 (1.2811)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2814949486936842\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:28:08 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80739437061158 train_acc5 99.80739437061158\n",
      "Epoch: [77]  [  0/560]  eta: 0:01:11  lr: 0.01  img/s: 1146.613711842434  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1276  data: 0.0159  max mem: 8056\n",
      "Epoch: [77]  [100/560]  eta: 0:00:52  lr: 0.01  img/s: 1148.9817445608207  loss: 1.2742 (1.2769)  acc1: 100.0000 (99.7447)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [77]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.4466813254573  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [77]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.7776848168683  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [77]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2104759560327  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7876)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [77]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.225235947504  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7988)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [77] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2791 (1.2816)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.1904867904002, Acc@5 = 100.0, loss = 1.2815597432000296\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:29:16 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [78]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1145.1731440321494  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1198  data: 0.0080  max mem: 8056\n",
      "Epoch: [78]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.6228444771546  loss: 1.2743 (1.2769)  acc1: 100.0000 (99.7370)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [78]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.225235947504  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [78]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8047247127297  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7924)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [78]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.3187246987397  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7896)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [78]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.431915645239  loss: 1.2745 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [78] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2874 (1.2874)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2782 (1.2812)  acc1: 99.2188 (99.2652)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514958629123, Acc@5 = 100.0, loss = 1.2815746477672032\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:30:25 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460299281432 train_acc5 99.80460299281432\n",
      "Epoch: [79]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.586774988574  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1194  data: 0.0078  max mem: 8056\n",
      "Epoch: [79]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.422072069179  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [79]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.8612667903542  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8251)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [79]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.5992822377395  loss: 1.2742 (1.2760)  acc1: 100.0000 (99.8339)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [79]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.5820510734154  loss: 1.2747 (1.2761)  acc1: 100.0000 (99.8227)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [79]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2424564167552  loss: 1.2745 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [79] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0109  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2812 (1.2814)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19048680743771, Acc@5 = 100.0, loss = 1.2815367826393673\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:31:33 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879007148953 train_acc5 99.80879007148953\n",
      "Epoch: [80]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.0266000102374  loss: 1.2755 (1.2755)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1195  data: 0.0077  max mem: 8056\n",
      "Epoch: [80]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.9227318835308  loss: 1.2744 (1.2760)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [80]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1416010085768  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [80]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.320657416577  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8001)  acc5: 100.0000 (100.0000)  time: 0.1135  data: 0.0020  max mem: 8056\n",
      "Epoch: [80]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.5795895206793  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8169)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [80]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7899755208243  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8129)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [80] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2852 (1.2852)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2797 (1.2817)  acc1: 99.2188 (99.1646)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165250641047, Acc@5 = 100.0, loss = 1.281515921013696\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:32:42 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [81]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.070322022863  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1195  data: 0.0078  max mem: 8056\n",
      "Epoch: [81]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0628968912195  loss: 1.2741 (1.2759)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [81]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1243835616438  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [81]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8243908910772  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [81]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1145.745024307586  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8130)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [81]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1440606859705  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [81] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2798 (1.2798)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2813 (1.2820)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956677087986, Acc@5 = 100.0, loss = 1.281568808215005\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:33:51 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80739437061158 train_acc5 99.80739437061158\n",
      "Epoch: [82]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.5518897615955  loss: 1.2755 (1.2755)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1195  data: 0.0077  max mem: 8056\n",
      "Epoch: [82]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2080159943146  loss: 1.2742 (1.2759)  acc1: 100.0000 (99.8376)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [82]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0260080472563  loss: 1.2746 (1.2762)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [82]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.468830557102  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7898)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [82]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.343329529812  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [82]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.65479224033  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.7942)  acc5: 100.0000 (100.0000)  time: 0.1131  data: 0.0016  max mem: 8056\n",
      "Epoch: [82] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2922 (1.2922)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2813)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398390435598, Acc@5 = 100.0, loss = 1.2814670409475053\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:34:59 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [83]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1146.0116080252908  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1197  data: 0.0080  max mem: 8056\n",
      "Epoch: [83]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1563592308862  loss: 1.2752 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [83]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.748188200354  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8095)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [83]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0604375612659  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [83]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.8489745608929  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8208)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [83]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2473766456171  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [83] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0463  data: 0.0107  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2799 (1.2816)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631530230148, Acc@5 = 100.0, loss = 1.2815547823905944\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:36:08 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018576438126 train_acc5 99.81018576438126\n",
      "Epoch: [84]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.9871456351298  loss: 1.2750 (1.2750)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1184  data: 0.0067  max mem: 8056\n",
      "Epoch: [84]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2645977784105  loss: 1.2743 (1.2766)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [84]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.7039461156126  loss: 1.2746 (1.2765)  acc1: 100.0000 (99.7862)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [84]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1883366796953  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [84]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.7555622124746  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [84]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.180957110474  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8113)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [84] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0109  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2814 (1.2816)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22398392139348, Acc@5 = 100.0, loss = 1.28152152129582\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:37:16 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [85]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.3444002451247  loss: 1.2746 (1.2746)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0068  max mem: 8056\n",
      "Epoch: [85]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.0432225463526  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [85]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.966990823175  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8329)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [85]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.355632340411  loss: 1.2742 (1.2761)  acc1: 100.0000 (99.8261)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [85]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0358448407228  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8247)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [85]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.7076042427345  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8082)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [85] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2842 (1.2842)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2811 (1.2822)  acc1: 99.2188 (99.0718)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18490395795133, Acc@5 = 100.0, loss = 1.2815967968532018\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:38:25 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [86]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.0605359388107  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0068  max mem: 8056\n",
      "Epoch: [86]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1760374503135  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [86]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.0604375612659  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8251)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [86]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.6302168801521  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8131)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [86]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9055209945022  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8130)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [86]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.925190624057  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [86] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2790 (1.2790)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2804 (1.2814)  acc1: 99.2188 (99.2806)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189816882536, Acc@5 = 100.0, loss = 1.2816958725452423\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:39:33 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158145727301 train_acc5 99.81158145727301\n",
      "Epoch: [87]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.3246122666667  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1186  data: 0.0068  max mem: 8056\n",
      "Epoch: [87]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.232616085419  loss: 1.2747 (1.2759)  acc1: 100.0000 (99.8530)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [87]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1760374503135  loss: 1.2751 (1.2762)  acc1: 100.0000 (99.8212)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [87]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.767852443056  loss: 1.2743 (1.2760)  acc1: 100.0000 (99.8313)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [87]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1366816853777  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8071)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [87]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.040763300616  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8113)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [87] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2767 (1.2767)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2791 (1.2815)  acc1: 99.2188 (99.2806)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631530230148, Acc@5 = 100.0, loss = 1.2815225081784385\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:40:42 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158145727301 train_acc5 99.81158145727301\n",
      "Epoch: [88]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.1853210304057  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1186  data: 0.0069  max mem: 8056\n",
      "Epoch: [88]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1834169563506  loss: 1.2746 (1.2760)  acc1: 100.0000 (99.8376)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [88]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.2916606012861  loss: 1.2746 (1.2762)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [88]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.7604782731498  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [88]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.9350256913992  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8149)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [88]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0973286159785  loss: 1.2744 (1.2763)  acc1: 100.0000 (99.8051)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [88] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0109  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2817 (1.2810)  acc1: 99.2188 (99.3038)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631531933899, Acc@5 = 100.0, loss = 1.2815887706620352\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:41:50 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [89]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.755763459464  loss: 1.2825 (1.2825)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1181  data: 0.0065  max mem: 8056\n",
      "Epoch: [89]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2178559043757  loss: 1.2745 (1.2768)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [89]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.1489800723475  loss: 1.2743 (1.2764)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [89]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.431915645239  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7898)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [89]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.6583644372492  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8052)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [89]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.564820425634  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [89] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2861 (1.2861)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2788 (1.2820)  acc1: 99.2188 (99.1105)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.16257257704332, Acc@5 = 100.0, loss = 1.2817069930689675\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:42:59 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n",
      "Epoch: [90]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1147.1698732467798  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1183  data: 0.0067  max mem: 8056\n",
      "Epoch: [90]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.1514397813305  loss: 1.2742 (1.2756)  acc1: 100.0000 (99.8762)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [90]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.6597074385577  loss: 1.2744 (1.2759)  acc1: 100.0000 (99.8445)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [90]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.1957163436944  loss: 1.2743 (1.2761)  acc1: 100.0000 (99.8261)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [90]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.4983641938302  loss: 1.2769 (1.2762)  acc1: 99.2188 (99.8169)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [90]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7531041979155  loss: 1.2753 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [90] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2819 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2762 (1.2814)  acc1: 100.0000 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956677087986, Acc@5 = 100.0, loss = 1.281485060283116\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:44:07 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006914691 train_acc5 99.80879006914691\n",
      "Epoch: [91]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1146.0850014623036  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1199  data: 0.0082  max mem: 8056\n",
      "Epoch: [91]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.730982540226  loss: 1.2749 (1.2759)  acc1: 100.0000 (99.8376)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [91]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.7064039198067  loss: 1.2742 (1.2757)  acc1: 100.0000 (99.8562)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [91]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.0678155827088  loss: 1.2742 (1.2758)  acc1: 100.0000 (99.8443)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [91]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2990415923653  loss: 1.2745 (1.2761)  acc1: 100.0000 (99.8208)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [91]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2104759560327  loss: 1.2743 (1.2762)  acc1: 100.0000 (99.8160)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [91] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2837 (1.2837)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0413  data: 0.0056  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2805 (1.2818)  acc1: 99.2188 (99.1723)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.2815833466393607\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:45:16 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879007148953 train_acc5 99.80879007148953\n",
      "Epoch: [92]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.2928494783077  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1196  data: 0.0079  max mem: 8056\n",
      "Epoch: [92]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.8194742833666  loss: 1.2741 (1.2760)  acc1: 100.0000 (99.8376)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [92]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1145.8844149995411  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8173)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [92]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.5746664468318  loss: 1.2741 (1.2761)  acc1: 100.0000 (99.8261)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [92]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1391413417125  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8130)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [92]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.0776530920189  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [92] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2846 (1.2846)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2784 (1.2819)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956677087986, Acc@5 = 100.0, loss = 1.2815678477287293\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:46:24 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [93]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1146.5280080639307  loss: 1.2744 (1.2744)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1185  data: 0.0068  max mem: 8056\n",
      "Epoch: [93]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.337850787132  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [93]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9817445608207  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [93]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.3015019437928  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [93]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1661982563578  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7876)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [93]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7014883219363  loss: 1.2740 (1.2763)  acc1: 100.0000 (99.7957)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [93] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2767 (1.2767)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0412  data: 0.0055  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2824)  acc1: 99.2188 (99.1569)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2815809684140342\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:47:33 max_test_acc1 99.26306386779812 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460298482811 train_acc5 99.80460298482811\n",
      "Epoch: [94]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.075094038625  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1166  data: 0.0051  max mem: 8056\n",
      "Epoch: [94]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.5024419567314  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [94]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9694497531368  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (100.0000)  time: 0.1129  data: 0.0014  max mem: 8056\n",
      "Epoch: [94]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.522976717098  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8053)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [94]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1148.7383563314554  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [94]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2670579823694  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [94] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2753 (1.2753)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2781 (1.2817)  acc1: 99.2188 (99.2884)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.2816572972706386\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:48:41 max_test_acc1 99.27981241625726 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80879006350331 train_acc5 99.80879006350331\n",
      "Epoch: [95]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.1315643151042  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1166  data: 0.0051  max mem: 8056\n",
      "Epoch: [95]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.2867399932354  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [95]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.8637252678116  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [95]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.126843165332  loss: 1.2747 (1.2763)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [95]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.303962305754  loss: 1.2741 (1.2763)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [95]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.6091288492794  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8113)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [95] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2892 (1.2892)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0109  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2792 (1.2814)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19606965692408, Acc@5 = 100.0, loss = 1.28148261819567\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:49:50 max_test_acc1 99.27981241625726 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [96]  [  0/560]  eta: 0:01:06  lr: 0.01  img/s: 1145.6130012461804  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1196  data: 0.0079  max mem: 8056\n",
      "Epoch: [96]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3900816113314  loss: 1.2741 (1.2764)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [96]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.9694497531368  loss: 1.2745 (1.2765)  acc1: 100.0000 (99.7823)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [96]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.2399963181228  loss: 1.2745 (1.2764)  acc1: 100.0000 (99.7924)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [96]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.2818194273189  loss: 1.2747 (1.2762)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [96]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.1932564451636  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8098)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [96] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2923 (1.2923)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2817)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24631530230148, Acc@5 = 100.0, loss = 1.2815675488540104\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:50:58 max_test_acc1 99.27981241625726 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80460298482811 train_acc5 99.80460298482811\n",
      "Epoch: [97]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.3673263345227  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1164  data: 0.0049  max mem: 8056\n",
      "Epoch: [97]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1148.5122697877202  loss: 1.2741 (1.2766)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [97]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.7457302173514  loss: 1.2742 (1.2764)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [97]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1149.8085590312728  loss: 1.2742 (1.2763)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [97]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.1858768127574  loss: 1.2741 (1.2762)  acc1: 100.0000 (99.8110)  acc5: 100.0000 (100.0000)  time: 0.1135  data: 0.0020  max mem: 8056\n",
      "Epoch: [97]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1148.7432722448673  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8160)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [97] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2758 (1.2758)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2774 (1.2813)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723533885933, Acc@5 = 100.0, loss = 1.2815946689673832\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:52:07 max_test_acc1 99.27981241625726 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81158144928678 train_acc5 99.81158144928678\n",
      "Epoch: [98]  [  0/560]  eta: 0:01:05  lr: 0.01  img/s: 1148.9596140964375  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1163  data: 0.0049  max mem: 8056\n",
      "Epoch: [98]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.3876208806382  loss: 1.2744 (1.2759)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [98]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1149.392542352561  loss: 1.2744 (1.2760)  acc1: 100.0000 (99.8290)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [98]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.9301081366807  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [98]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.0432225463526  loss: 1.2748 (1.2763)  acc1: 100.0000 (99.8052)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [98]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.2596774020915  loss: 1.2743 (1.2763)  acc1: 100.0000 (99.8051)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [98] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2786 (1.2786)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2785 (1.2813)  acc1: 100.0000 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22956677087986, Acc@5 = 100.0, loss = 1.2814738614218575\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:53:15 max_test_acc1 99.27981241625726 test_acc5_at_max_test_acc1 100.0 train_acc1 99.81018575639504 train_acc5 99.81018575639504\n",
      "Epoch: [99]  [  0/560]  eta: 0:01:07  lr: 0.01  img/s: 1148.3550446725546  loss: 1.2748 (1.2748)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1202  data: 0.0087  max mem: 8056\n",
      "Epoch: [99]  [100/560]  eta: 0:00:51  lr: 0.01  img/s: 1149.028467229833  loss: 1.2745 (1.2762)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [99]  [200/560]  eta: 0:00:40  lr: 0.01  img/s: 1148.5564971086642  loss: 1.2746 (1.2763)  acc1: 100.0000 (99.8134)  acc5: 100.0000 (100.0000)  time: 0.1130  data: 0.0016  max mem: 8056\n",
      "Epoch: [99]  [300/560]  eta: 0:00:29  lr: 0.01  img/s: 1148.8809349046328  loss: 1.2745 (1.2763)  acc1: 100.0000 (99.8027)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [99]  [400/560]  eta: 0:00:18  lr: 0.01  img/s: 1149.09240967182  loss: 1.2744 (1.2762)  acc1: 100.0000 (99.8091)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [99]  [500/560]  eta: 0:00:06  lr: 0.01  img/s: 1149.5475902943722  loss: 1.2742 (1.2762)  acc1: 100.0000 (99.8113)  acc5: 100.0000 (100.0000)  time: 0.1128  data: 0.0014  max mem: 8056\n",
      "Epoch: [99] Total time: 0:01:03\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2867 (1.2867)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0414  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2798 (1.2810)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2816311384950365\n",
      "Namespace(device='cuda:0', batch_size=128, data_path='../data', epochs=100, workers=16, lr=0.01, print_freq=100, output_dir='./logs', resume='', start_epoch=0, tb=True, cache_dataset=True, distributed=False)\n",
      "./logs/b_128_lr0.01_2025_3_12_7__15\n",
      "Training time 1:54:24 max_test_acc1 99.27981241625726 test_acc5_at_max_test_acc1 100.0 train_acc1 99.80599867771984 train_acc5 99.80599867771984\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "print(device)\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    save_max = False\n",
    "\n",
    "    train_loss, train_acc1, train_acc5 = train_one_epoch(net, criterion,data_loader, device, epoch, args.print_freq,lr=args.lr)\n",
    "\n",
    "    if utils.is_main_process():\n",
    "        train_tb_writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc1', train_acc1, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc5', train_acc5, epoch)\n",
    "\n",
    "    test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "    if te_tb_writer is not None:\n",
    "        if utils.is_main_process():\n",
    "            te_tb_writer.add_scalar('test_loss', test_loss, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc1', test_acc1, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc5', test_acc5, epoch)\n",
    "\n",
    "\n",
    "    if max_test_acc1 < test_acc1:\n",
    "        max_test_acc1 = test_acc1\n",
    "        test_acc5_at_max_test_acc1 = test_acc5\n",
    "        save_max = True\n",
    "\n",
    "    if output_dir:\n",
    "\n",
    "        checkpoint = {\n",
    "            'model': net.state_dict(),\n",
    "            'pre-train_epoch': epoch,\n",
    "            'args': args,\n",
    "            'max_test_acc1': max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1': test_acc5_at_max_test_acc1,\n",
    "        }\n",
    "\n",
    "        utils.save_on_master(\n",
    "            checkpoint,\n",
    "            os.path.join(output_dir, 'checkpoint_latest.pth'))\n",
    "        save_flag = False\n",
    "\n",
    "        if epoch % 64 == 0 or epoch == args.epochs - 1:\n",
    "            save_flag = True\n",
    "\n",
    "\n",
    "        if save_flag:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir, f'checkpoint_{epoch}.pth'))\n",
    "\n",
    "        if save_max:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net,os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net.state_dict(),os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth'))\n",
    "    print(args)\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(output_dir)\n",
    "\n",
    "    print('Training time {}'.format(total_time_str), 'max_test_acc1', max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1', test_acc5_at_max_test_acc1,'train_acc1', train_acc1,\n",
    "            'train_acc5', train_acc1)\n",
    "\n",
    "    Train_logs= {\n",
    "        'Epoch:': epoch,\n",
    "        'max_test_acc1 ': max_test_acc1 ,\n",
    "        'test_acc5_at_max_test_acc1 ': test_acc5_at_max_test_acc1,\n",
    "        'train_acc1 ': train_acc1,\n",
    "        'train_acc5 ': train_acc1,\n",
    "        'args': args\n",
    "    }\n",
    "    with open(output_dir + '_logs/args.txt', 'a', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(str(Train_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth')\n",
    "# print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [  0/140]  eta: 0:00:10  loss: 1.2881 (1.2881)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0757  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2831 (1.2836)  acc1: 99.2188 (98.9867)  acc5: 100.0000 (100.0000)  time: 0.0354  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.01183560683612, Acc@5 = 100.0, loss = 1.2834796471255165\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2831 (1.2831)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2838)  acc1: 98.4375 (98.9867)  acc5: 100.0000 (100.0000)  time: 0.0353  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183560683612, Acc@5 = 100.0, loss = 1.2834827610424586\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2831 (1.2831)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2828 (1.2838)  acc1: 99.2188 (98.9712)  acc5: 100.0000 (100.0000)  time: 0.0354  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183564091112, Acc@5 = 100.0, loss = 1.2834753266402654\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2841)  acc1: 99.2188 (98.9712)  acc5: 100.0000 (100.0000)  time: 0.0353  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183564091112, Acc@5 = 100.0, loss = 1.2834759201322283\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2869 (1.2869)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2831 (1.2840)  acc1: 99.2188 (98.9480)  acc5: 100.0000 (100.0000)  time: 0.0354  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183564091112, Acc@5 = 100.0, loss = 1.2834864803722927\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2839)  acc1: 99.2188 (98.9790)  acc5: 100.0000 (100.0000)  time: 0.0353  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183562387362, Acc@5 = 100.0, loss = 1.2834796462740217\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2828 (1.2828)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0398  data: 0.0057  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2836)  acc1: 98.4375 (99.0022)  acc5: 100.0000 (100.0000)  time: 0.0354  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183560683612, Acc@5 = 100.0, loss = 1.2834827652999332\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2831 (1.2831)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2832)  acc1: 99.2188 (99.0408)  acc5: 100.0000 (100.0000)  time: 0.0353  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183562387362, Acc@5 = 100.0, loss = 1.2834790442671096\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2753 (1.2753)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2834)  acc1: 99.2188 (98.9867)  acc5: 100.0000 (100.0000)  time: 0.0353  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183564091112, Acc@5 = 100.0, loss = 1.2834759294986724\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2766 (1.2824)  acc1: 100.0000 (99.1105)  acc5: 100.0000 (100.0000)  time: 0.0353  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.01183560683612, Acc@5 = 100.0, loss = 1.2834833698613304\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2776 (1.2776)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0483  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2829)  acc1: 99.2188 (99.0563)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.10116119861816, Acc@5 = 100.0, loss = 1.2825256398745946\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2809 (1.2809)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2825)  acc1: 99.2188 (99.0873)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116121565567, Acc@5 = 100.0, loss = 1.2825233936309814\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2823 (1.2831)  acc1: 99.2188 (99.0408)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116123269317, Acc@5 = 100.0, loss = 1.2825195525373732\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2809 (1.2822)  acc1: 99.2188 (99.1182)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116119861816, Acc@5 = 100.0, loss = 1.2824986679213388\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2827)  acc1: 99.2188 (99.1027)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116119861816, Acc@5 = 100.0, loss = 1.2825238713196345\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2823 (1.2823)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2793 (1.2828)  acc1: 99.2188 (99.0486)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116121565567, Acc@5 = 100.0, loss = 1.2825183740683965\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2854 (1.2854)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2808 (1.2824)  acc1: 99.2188 (99.1259)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116121565567, Acc@5 = 100.0, loss = 1.2825197168758937\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2896 (1.2896)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2822)  acc1: 99.2188 (99.1182)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116123269317, Acc@5 = 100.0, loss = 1.2825164326599665\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2781 (1.2781)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2814 (1.2831)  acc1: 99.2188 (99.0331)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116121565567, Acc@5 = 100.0, loss = 1.2825203895568849\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2906 (1.2906)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2823 (1.2825)  acc1: 99.2188 (99.1105)  acc5: 100.0000 (100.0000)  time: 0.0355  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.10116123269317, Acc@5 = 100.0, loss = 1.2825237776551928\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2910 (1.2910)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0496  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2787 (1.2826)  acc1: 100.0000 (99.1105)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2822021859032766\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2896 (1.2896)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2795 (1.2825)  acc1: 99.2188 (99.1105)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2821999950068337\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2743 (1.2743)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2790 (1.2824)  acc1: 99.2188 (99.1414)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2822001550878797\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2928 (1.2928)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2819)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554265297, Acc@5 = 100.0, loss = 1.2822030442101615\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2835 (1.2835)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2822)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2821998485497066\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.3030 (1.3030)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2847 (1.2827)  acc1: 98.4375 (99.0950)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2822007060050964\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2824)  acc1: 99.2188 (99.1259)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554265297, Acc@5 = 100.0, loss = 1.2821965847696577\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2787 (1.2787)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2824)  acc1: 99.2188 (99.1646)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.2822002223559787\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2849 (1.2849)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2846 (1.2821)  acc1: 98.4375 (99.1337)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681554094922, Acc@5 = 100.0, loss = 1.282201534509659\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2770 (1.2770)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2773 (1.2826)  acc1: 99.2188 (99.1337)  acc5: 100.0000 (100.0000)  time: 0.0357  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.1681553924547, Acc@5 = 100.0, loss = 1.2821990515504564\n",
      "Test:  [  0/140]  eta: 0:00:07  loss: 1.2784 (1.2784)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0530  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2812)  acc1: 99.2188 (99.2884)  acc5: 100.0000 (100.0000)  time: 0.0359  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2820180909974235\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0379  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2792 (1.2819)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2820184060505457\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2766 (1.2766)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0366  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2792 (1.2815)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.282022192648479\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2757 (1.2757)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0366  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2813 (1.2820)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2820179751941136\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2796 (1.2796)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2797 (1.2817)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2820210644177028\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2740 (1.2740)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2820 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2820263121809279\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2823 (1.2823)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0367  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2810 (1.2820)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723537293435, Acc@5 = 100.0, loss = 1.2820173919200897\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2882 (1.2882)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2820)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2820214211940766\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2745 (1.2745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2840 (1.2818)  acc1: 98.4375 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723535589684, Acc@5 = 100.0, loss = 1.2820210107735226\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2782 (1.2782)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2820 (1.2822)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0358  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20723533885933, Acc@5 = 100.0, loss = 1.2820240037781852\n",
      "Test:  [  0/140]  eta: 0:00:07  loss: 1.2841 (1.2841)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0547  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2779 (1.2822)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.2818775858197893\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2754 (1.2754)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0383  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2856 (1.2820)  acc1: 98.4375 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.2818782252924783\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2864 (1.2864)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2826)  acc1: 99.2188 (99.1182)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.2818776735237667\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2927 (1.2927)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0367  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2822)  acc1: 99.2188 (99.1491)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165248937296, Acc@5 = 100.0, loss = 1.2818844965526035\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2868 (1.2868)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2817)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165250641047, Acc@5 = 100.0, loss = 1.2818904561655862\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2760 (1.2760)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2791 (1.2817)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.2818796021597727\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2830 (1.2830)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2765 (1.2815)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165248937296, Acc@5 = 100.0, loss = 1.2818835496902465\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2759 (1.2759)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0367  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2763 (1.2816)  acc1: 100.0000 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0361  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165250641047, Acc@5 = 100.0, loss = 1.2818805634975434\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2850 (1.2850)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0367  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2823)  acc1: 99.2188 (99.1491)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19606965692408, Acc@5 = 100.0, loss = 1.2818812429904938\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2972 (1.2972)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0366  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2796 (1.2824)  acc1: 99.2188 (99.1491)  acc5: 100.0000 (100.0000)  time: 0.0360  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.20165252344796, Acc@5 = 100.0, loss = 1.281877989428384\n",
      "Test:  [  0/140]  eta: 0:00:07  loss: 1.2804 (1.2804)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0553  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2808 (1.2823)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.281712635074343\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2844 (1.2844)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0385  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2782 (1.2822)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2817163552556718\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2997 (1.2997)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2805 (1.2814)  acc1: 99.2188 (99.2884)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2817158588341304\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2831 (1.2831)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2787 (1.2816)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0363  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.281716307571956\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2788 (1.2788)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2818)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2407324357776, Acc@5 = 100.0, loss = 1.2817188969680242\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2821 (1.2821)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0369  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2816 (1.2820)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2817223259380885\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2907 (1.2907)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2816)  acc1: 99.2188 (99.2420)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2817138263157435\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2826 (1.2826)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2798 (1.2816)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2817155063152312\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2826 (1.2826)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2815)  acc1: 99.2188 (99.2652)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2817128445420947\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2900 (1.2900)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2784 (1.2821)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0362  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2817194870540074\n",
      "Test:  [  0/140]  eta: 0:00:08  loss: 1.2849 (1.2849)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0598  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2815 (1.2815)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2816954714911324\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2911 (1.2911)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0387  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2808 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2816961118153163\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2900 (1.2900)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2821 (1.2819)  acc1: 99.2188 (99.1723)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2816888672964915\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2908 (1.2908)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2832 (1.2823)  acc1: 99.2188 (99.1646)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2816840520926884\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2821 (1.2821)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2800 (1.2818)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2816914337021963\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2843 (1.2843)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2823 (1.2817)  acc1: 99.2188 (99.2652)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2816890282290323\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2886 (1.2886)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0371  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2795 (1.2820)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.2407324357776, Acc@5 = 100.0, loss = 1.2816910752228328\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2870 (1.2870)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2811 (1.2822)  acc1: 99.2188 (99.1569)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.2816899589129858\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2741 (1.2741)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2806 (1.2817)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073246985262, Acc@5 = 100.0, loss = 1.281697632585253\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2928 (1.2928)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0372  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2812 (1.2817)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0364  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24073245281511, Acc@5 = 100.0, loss = 1.2816924359117234\n",
      "Test:  [  0/140]  eta: 0:00:08  loss: 1.2804 (1.2804)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0598  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2822 (1.2815)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189816882536, Acc@5 = 100.0, loss = 1.2816404615129744\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2788 (1.2788)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0388  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2829 (1.2820)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189815178787, Acc@5 = 100.0, loss = 1.2816322462899343\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2832 (1.2832)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0374  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2798 (1.2815)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189816882536, Acc@5 = 100.0, loss = 1.281630277633667\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2868 (1.2868)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0373  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2817 (1.2815)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189815178787, Acc@5 = 100.0, loss = 1.2816281914710999\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2751 (1.2751)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0374  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2802 (1.2820)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0366  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189816882536, Acc@5 = 100.0, loss = 1.2816303661891393\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2742 (1.2742)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0373  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2794 (1.2821)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189815178787, Acc@5 = 100.0, loss = 1.2816337823867798\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2746 (1.2746)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0375  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2822 (1.2813)  acc1: 99.2188 (99.2729)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189816882536, Acc@5 = 100.0, loss = 1.2816307774611881\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2820 (1.2820)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0373  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2837 (1.2812)  acc1: 99.2188 (99.3193)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189816882536, Acc@5 = 100.0, loss = 1.2816355228424072\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2810 (1.2810)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0373  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2779 (1.2811)  acc1: 100.0000 (99.3425)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189815178787, Acc@5 = 100.0, loss = 1.2816333838871548\n",
      "Test:  [  0/140]  eta: 0:00:06  loss: 1.2781 (1.2781)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0459  data: 0.0106  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2820)  acc1: 99.2188 (99.2110)  acc5: 100.0000 (100.0000)  time: 0.0365  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.25189815178787, Acc@5 = 100.0, loss = 1.2816334273133958\n",
      "Test:  [  0/140]  eta: 0:00:08  loss: 1.2847 (1.2847)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0614  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2807 (1.2822)  acc1: 99.2188 (99.1646)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514962036623, Acc@5 = 100.0, loss = 1.2817086866923741\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2844 (1.2844)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0389  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2822)  acc1: 99.2188 (99.1878)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514958629123, Acc@5 = 100.0, loss = 1.281718362229211\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2810 (1.2810)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2810 (1.2816)  acc1: 99.2188 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2817120918205807\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2788 (1.2788)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2839 (1.2819)  acc1: 99.2188 (99.2265)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.281706941127777\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2866 (1.2866)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2786 (1.2819)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.281711416585105\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2818 (1.2818)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2818 (1.2820)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2817154705524445\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2940 (1.2940)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2812 (1.2814)  acc1: 99.2188 (99.2574)  acc5: 100.0000 (100.0000)  time: 0.0369  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514962036623, Acc@5 = 100.0, loss = 1.281708800792694\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2817 (1.2817)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0375  data: 0.0020  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2774 (1.2813)  acc1: 100.0000 (99.3193)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514962036623, Acc@5 = 100.0, loss = 1.2817098242895943\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2750 (1.2750)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2764 (1.2814)  acc1: 100.0000 (99.2806)  acc5: 100.0000 (100.0000)  time: 0.0368  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2817133954593114\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2782 (1.2782)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0376  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2820 (1.2816)  acc1: 99.2188 (99.1955)  acc5: 100.0000 (100.0000)  time: 0.0369  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23514960332874, Acc@5 = 100.0, loss = 1.2817124085766929\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2855 (1.2855)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2819 (1.2821)  acc1: 99.2188 (99.2033)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.281660042490278\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2764 (1.2764)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2839 (1.2815)  acc1: 99.2188 (99.3116)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.2816597419125693\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2887 (1.2887)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2857 (1.2818)  acc1: 98.4375 (99.2497)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981239921975, Acc@5 = 100.0, loss = 1.2816626965999602\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2760 (1.2760)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2778 (1.2820)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981239921975, Acc@5 = 100.0, loss = 1.2816629307610647\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2878 (1.2878)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2787 (1.2812)  acc1: 99.2188 (99.3348)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.281658764396395\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2830 (1.2830)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2781 (1.2820)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.281658513205392\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2836 (1.2836)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0377  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2832 (1.2816)  acc1: 98.4375 (99.2806)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.281658434016364\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2814 (1.2814)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2792 (1.2815)  acc1: 99.2188 (99.2884)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.2816576966217585\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2932 (1.2932)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0022  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2778 (1.2812)  acc1: 100.0000 (99.3270)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981241625726, Acc@5 = 100.0, loss = 1.2816593842847006\n",
      "Test:  [  0/140]  eta: 0:00:05  loss: 1.2805 (1.2805)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0378  data: 0.0021  max mem: 8056\n",
      "Test:  [100/140]  eta: 0:00:01  loss: 1.2806 (1.2813)  acc1: 99.2188 (99.3348)  acc5: 100.0000 (100.0000)  time: 0.0370  data: 0.0014  max mem: 8056\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27981239921975, Acc@5 = 100.0, loss = 1.2816567386899675\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for time in range(1,11):\n",
    "    acc = 0\n",
    "    for i in range(10):\n",
    "        net = NetworkA().to(device)\n",
    "        functional.reset_net(net)\n",
    "        functional.set_step_mode(net,step_mode='m')\n",
    "        functional.set_backend(net, backend='cupy')\n",
    "        weights = torch.load(model_dir)\n",
    "        net.load_state_dict(weights)\n",
    "        net.set_T(time)\n",
    "        # print(net.T)\n",
    "        test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "        acc += test_acc1\n",
    "    acc_list.append(acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'a') as file:\n",
    "    line = ' '.join(map(str, acc_list))\n",
    "    file.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
