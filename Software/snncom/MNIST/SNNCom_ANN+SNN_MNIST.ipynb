{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import math\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributed.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import layer,functional,neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "np.int = int\n",
    "\n",
    "train_tb_writer = None\n",
    "te_tb_writer = None\n",
    "device = torch.device('cuda:0')\n",
    "deviceIds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "\n",
    "    parser.add_argument('--device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--data-path', default='./data/', help='dataset')\n",
    "    parser.add_argument('--epochs', default=320, type=int, metavar='N',\n",
    "                        help='number of total epochs to pre-train')\n",
    "    parser.add_argument('-j', '--workers', default=16, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', default=0.0025, type=float, help='initial learning rate')\n",
    "\n",
    "    parser.add_argument('--print-freq', default=10, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='./logs', help='path where to save')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--tb', action='store_true',\n",
    "                        help='Use TensorBoard to record logs')\n",
    "    parser.add_argument(\n",
    "        \"--cache-dataset\",\n",
    "        dest=\"cache_dataset\",\n",
    "        help=\"Cache the datasets for quicker initialization. It also serializes the transforms\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(args=['--data-path','../data','--lr','0.01','-b','128','--epochs','100','--print-freq','100','--tb','--cache-dataset'])\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkA, self).__init__()\n",
    "        self.T = 10\n",
    "        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, padding=3) \n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.sn1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1) \n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.sn2 = nn.ReLU()\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv3 = nn.Conv2d(96, 128, kernel_size=3, padding=1) \n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.sn3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1) \n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.sn4 = nn.ReLU()\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1) \n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.sn5 = nn.ReLU()\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, padding=1) \n",
    "        self.bn8 = nn.BatchNorm2d(512)\n",
    "        self.sn8 = nn.ReLU()\n",
    "\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, padding=1) \n",
    "        self.bn10 = nn.BatchNorm2d(512)\n",
    "        self.sn10 = nn.ReLU()\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 256, kernel_size=3, padding=1) \n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "        self.sn11 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.conv13 = layer.SeqToANNContainer(nn.Conv2d(256, 128, kernel_size=3, padding=1)) \n",
    "        self.bn13 = layer.SeqToANNContainer(nn.BatchNorm2d(128))\n",
    "        self.sn13 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.linear1 = layer.SeqToANNContainer(nn.Linear(512, 256)) \n",
    "        self.bn14 = layer.SeqToANNContainer(nn.BatchNorm1d(256))\n",
    "        self.sn14 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.linear3 = layer.SeqToANNContainer(nn.Linear(256, 10)) \n",
    "        self.bn15 = layer.SeqToANNContainer(nn.BatchNorm1d(10))\n",
    "        self.sn15 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        T = self.T     \n",
    "        x = self.sn1(self.bn1(self.conv1(x)))\n",
    "        x = self.sn2(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.sn3(self.bn3(self.conv3(x)))\n",
    "        x = self.sn4(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.sn5(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.sn8(self.bn8(self.conv8(x)))\n",
    "        x = self.sn10(self.bn10(self.conv10(x)))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.bn11(self.conv11(x))\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.repeat(T, 1, 1, 1, 1)\n",
    "        x = self.sn11(x)\n",
    "  \n",
    "        x = self.sn13(self.bn13(self.conv13(x)))\n",
    "        \n",
    "        x = torch.flatten(x,2)\n",
    "\n",
    "        x = self.sn14(self.bn14(self.linear1(x)))\n",
    "\n",
    "        x = self.sn15(self.bn15(self.linear3(x)))\n",
    "\n",
    "        return x.mean(0)\n",
    "    \n",
    "    def set_T(self, T):\n",
    "        self.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "max_test_acc1 = 0.\n",
    "test_acc5_at_max_test_acc1 = 0.\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "print(args)\n",
    "output_dir = os.path.join(args.output_dir, f'b_{args.batch_size}_lr{args.lr}')\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "output_dir += f'_{time_now.year}_{time_now.month}_{time_now.day}_{time_now.hour}__{time_now.minute}'\n",
    "\n",
    "\n",
    "if output_dir:\n",
    "    utils.mkdir(output_dir)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Creating model\")\n",
    "\n",
    "net = NetworkA().to(device)\n",
    "functional.set_step_mode(net,step_mode='m')\n",
    "functional.set_backend(net, backend='cupy')\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4, last_epoch=-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    args.start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc1 = checkpoint['max_test_acc1']\n",
    "    test_acc5_at_max_test_acc1 = checkpoint['test_acc5_at_max_test_acc1']\n",
    "\n",
    "\n",
    "if args.tb and utils.is_main_process():\n",
    "    purge_step_train = args.start_epoch\n",
    "    purge_step_te = args.start_epoch\n",
    "    train_tb_writer = SummaryWriter(output_dir + '_logs/train', purge_step=purge_step_train)\n",
    "    te_tb_writer = SummaryWriter(output_dir + '_logs/te', purge_step=purge_step_te)\n",
    "    with open(output_dir + '_logs/args.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "\n",
    "    with open(output_dir + '_logs/resluts.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('Results\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(net, criterion, data_loader, device, epoch, print_freq, scaler=None,lr = 1e-2):\n",
    "    net.train()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        functional.reset_net(net)\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        loss_s = loss.item()\n",
    "        if math.isnan(loss_s):\n",
    "            raise ValueError('loss is Nan')\n",
    "        acc1_s = acc1.item()\n",
    "        acc5_s = acc5.item()\n",
    "\n",
    "        metric_logger.update(loss=loss_s, lr=lr)\n",
    "\n",
    "        metric_logger.meters['acc1'].update(acc1_s, n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5_s, n=batch_size)\n",
    "        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n",
    "        \n",
    "    scheduler.step()\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    return metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, data_loader, device, print_freq=100, header='Test:'):\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    with torch.no_grad():\n",
    "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = net(image)\n",
    "            loss = criterion(output, target)\n",
    "            functional.reset_net(net)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    loss, acc1, acc5 = metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg\n",
    "    print(f' * Acc@1 = {acc1}, Acc@5 = {acc5}, loss = {loss}')\n",
    "    return loss, acc1, acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/468]  eta: 0:24:07  lr: 0.01  img/s: 50.85773310567841  loss: 2.3557 (2.3557)  acc1: 7.8125 (7.8125)  acc5: 39.8438 (39.8438)  time: 3.0923  data: 0.5754  max mem: 2151\n",
      "Epoch: [0]  [100/468]  eta: 0:00:22  lr: 0.01  img/s: 4272.4429766272215  loss: 1.4936 (1.6087)  acc1: 97.6562 (86.6259)  acc5: 100.0000 (97.2308)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [0]  [200/468]  eta: 0:00:12  lr: 0.01  img/s: 4320.371077938277  loss: 1.4848 (1.5492)  acc1: 96.8750 (91.7910)  acc5: 100.0000 (98.4608)  time: 0.0306  data: 0.0003  max mem: 2151\n",
      "Epoch: [0]  [300/468]  eta: 0:00:06  lr: 0.01  img/s: 4512.46826644253  loss: 1.4794 (1.5262)  acc1: 97.6562 (93.8746)  acc5: 100.0000 (98.8917)  time: 0.0297  data: 0.0003  max mem: 2151\n",
      "Epoch: [0]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3991.991136689792  loss: 1.4736 (1.5140)  acc1: 98.4375 (94.9832)  acc5: 99.2188 (99.1019)  time: 0.0290  data: 0.0002  max mem: 2151\n",
      "Epoch: [0] Total time: 0:00:16\n",
      "Test:  [ 0/79]  eta: 0:07:34  loss: 1.4743 (1.4743)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 5.7484  data: 0.4986  max mem: 2151\n",
      "Test: Total time: 0:00:07\n",
      " * Acc@1 = 98.39, Acc@5 = 99.81, loss = 1.475868154175674\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:00:24 max_test_acc1 98.39 test_acc5_at_max_test_acc1 99.81 train_acc1 95.47943376068376 train_acc5 95.47943376068376\n",
      "Epoch: [1]  [  0/468]  eta: 0:03:24  lr: 0.01  img/s: 2711.866445085391  loss: 1.4707 (1.4707)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4369  data: 0.3896  max mem: 2151\n",
      "Epoch: [1]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4307.89096890672  loss: 1.4694 (1.4716)  acc1: 99.2188 (98.8784)  acc5: 100.0000 (99.7912)  time: 0.0292  data: 0.0003  max mem: 2151\n",
      "Epoch: [1]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4293.971094706028  loss: 1.4690 (1.4722)  acc1: 99.2188 (98.8029)  acc5: 100.0000 (99.7862)  time: 0.0291  data: 0.0002  max mem: 2151\n",
      "Epoch: [1]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4314.919483692594  loss: 1.4676 (1.4716)  acc1: 99.2188 (98.8528)  acc5: 100.0000 (99.8131)  time: 0.0290  data: 0.0003  max mem: 2151\n",
      "Epoch: [1]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4324.686541916047  loss: 1.4673 (1.4711)  acc1: 99.2188 (98.9148)  acc5: 100.0000 (99.8247)  time: 0.0300  data: 0.0003  max mem: 2151\n",
      "Epoch: [1] Total time: 0:00:13\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4790 (1.4790)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5384  data: 0.5164  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 98.2, Acc@5 = 99.75, loss = 1.4777591319023808\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:00:40 max_test_acc1 98.39 test_acc5_at_max_test_acc1 99.81 train_acc1 98.89990651709402 train_acc5 98.89990651709402\n",
      "Epoch: [2]  [  0/468]  eta: 0:04:55  lr: 0.01  img/s: 2975.541002505154  loss: 1.4649 (1.4649)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6316  data: 0.5886  max mem: 2151\n",
      "Epoch: [2]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4272.646988133988  loss: 1.4673 (1.4683)  acc1: 99.2188 (99.2652)  acc5: 100.0000 (99.9304)  time: 0.0292  data: 0.0003  max mem: 2151\n",
      "Epoch: [2]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4313.879343039887  loss: 1.4631 (1.4681)  acc1: 100.0000 (99.2537)  acc5: 100.0000 (99.9106)  time: 0.0275  data: 0.0003  max mem: 2151\n",
      "Epoch: [2]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3990.3592335478884  loss: 1.4649 (1.4681)  acc1: 99.2188 (99.2239)  acc5: 100.0000 (99.9066)  time: 0.0286  data: 0.0002  max mem: 2151\n",
      "Epoch: [2]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4067.5428406912697  loss: 1.4661 (1.4680)  acc1: 99.2188 (99.2324)  acc5: 100.0000 (99.8987)  time: 0.0294  data: 0.0003  max mem: 2151\n",
      "Epoch: [2] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4688 (1.4688)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5991  data: 0.5773  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 98.41, Acc@5 = 99.76, loss = 1.475809556019457\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:00:56 max_test_acc1 98.41 test_acc5_at_max_test_acc1 99.76 train_acc1 99.20038728632478 train_acc5 99.20038728632478\n",
      "Epoch: [3]  [  0/468]  eta: 0:04:50  lr: 0.01  img/s: 2968.2203092777804  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6208  data: 0.5777  max mem: 2151\n",
      "Epoch: [3]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4328.9408235834835  loss: 1.4631 (1.4669)  acc1: 100.0000 (99.3657)  acc5: 100.0000 (99.8762)  time: 0.0297  data: 0.0003  max mem: 2151\n",
      "Epoch: [3]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4052.1311787215736  loss: 1.4658 (1.4665)  acc1: 99.2188 (99.3898)  acc5: 100.0000 (99.9028)  time: 0.0320  data: 0.0003  max mem: 2151\n",
      "Epoch: [3]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3331.291337800943  loss: 1.4654 (1.4664)  acc1: 99.2188 (99.4108)  acc5: 100.0000 (99.9118)  time: 0.0342  data: 0.0003  max mem: 2151\n",
      "Epoch: [3]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3755.8128497873295  loss: 1.4670 (1.4668)  acc1: 99.2188 (99.3590)  acc5: 100.0000 (99.9045)  time: 0.0334  data: 0.0002  max mem: 2151\n",
      "Epoch: [3] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5812  data: 0.5539  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.04, Acc@5 = 99.87, loss = 1.4690928081922894\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:01:13 max_test_acc1 99.04 test_acc5_at_max_test_acc1 99.87 train_acc1 99.34561965811966 train_acc5 99.34561965811966\n",
      "Epoch: [4]  [  0/468]  eta: 0:04:56  lr: 0.01  img/s: 2124.3704969927194  loss: 1.4700 (1.4700)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6330  data: 0.5727  max mem: 2151\n",
      "Epoch: [4]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3760.943418167553  loss: 1.4637 (1.4649)  acc1: 99.2188 (99.5900)  acc5: 100.0000 (99.9459)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [4]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3788.1706709567256  loss: 1.4639 (1.4653)  acc1: 99.2188 (99.5258)  acc5: 100.0000 (99.9378)  time: 0.0331  data: 0.0003  max mem: 2151\n",
      "Epoch: [4]  [300/468]  eta: 0:00:06  lr: 0.01  img/s: 4065.3559897016507  loss: 1.4639 (1.4654)  acc1: 100.0000 (99.5250)  acc5: 100.0000 (99.9273)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [4]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3787.823220635548  loss: 1.4622 (1.4654)  acc1: 100.0000 (99.5324)  acc5: 100.0000 (99.9182)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [4] Total time: 0:00:16\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4712 (1.4712)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.5789  data: 0.5477  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.17, Acc@5 = 99.89, loss = 1.4682998838303964\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:01:31 max_test_acc1 99.17 test_acc5_at_max_test_acc1 99.89 train_acc1 99.53926282051282 train_acc5 99.53926282051282\n",
      "Epoch: [5]  [  0/468]  eta: 0:04:39  lr: 0.01  img/s: 2149.2374257394035  loss: 1.4737 (1.4737)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.5969  data: 0.5373  max mem: 2151\n",
      "Epoch: [5]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3746.037888038404  loss: 1.4627 (1.4637)  acc1: 100.0000 (99.7138)  acc5: 100.0000 (99.9691)  time: 0.0334  data: 0.0002  max mem: 2151\n",
      "Epoch: [5]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4327.579938415903  loss: 1.4614 (1.4633)  acc1: 100.0000 (99.7901)  acc5: 100.0000 (99.9572)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [5]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4337.054068682495  loss: 1.4621 (1.4635)  acc1: 100.0000 (99.7638)  acc5: 100.0000 (99.9429)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [5]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3794.5161500077747  loss: 1.4622 (1.4635)  acc1: 100.0000 (99.7662)  acc5: 100.0000 (99.9513)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [5] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3779  data: 0.3555  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.52, Acc@5 = 99.89, loss = 1.4655567286889764\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:01:48 max_test_acc1 99.52 test_acc5_at_max_test_acc1 99.89 train_acc1 99.7779780982906 train_acc5 99.7779780982906\n",
      "Epoch: [6]  [  0/468]  eta: 0:03:26  lr: 0.01  img/s: 2871.981084232938  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4411  data: 0.3965  max mem: 2151\n",
      "Epoch: [6]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3806.62321676735  loss: 1.4620 (1.4628)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (99.9536)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [6]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3777.881147569823  loss: 1.4614 (1.4630)  acc1: 100.0000 (99.8329)  acc5: 100.0000 (99.9456)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [6]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4360.549967511371  loss: 1.4614 (1.4628)  acc1: 100.0000 (99.8469)  acc5: 100.0000 (99.9585)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [6]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4686.291370611547  loss: 1.4613 (1.4627)  acc1: 100.0000 (99.8539)  acc5: 100.0000 (99.9591)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [6] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3723  data: 0.3490  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.59, Acc@5 = 99.89, loss = 1.465122090110296\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:02:04 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.85643696581197 train_acc5 99.85643696581197\n",
      "Epoch: [7]  [  0/468]  eta: 0:03:13  lr: 0.01  img/s: 2704.584854713255  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4139  data: 0.3665  max mem: 2151\n",
      "Epoch: [7]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3964.86822690112  loss: 1.4617 (1.4621)  acc1: 100.0000 (99.9072)  acc5: 100.0000 (99.9613)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [7]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4391.977290390138  loss: 1.4614 (1.4623)  acc1: 100.0000 (99.8756)  acc5: 100.0000 (99.9650)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [7]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4353.548646588495  loss: 1.4614 (1.4625)  acc1: 100.0000 (99.8547)  acc5: 100.0000 (99.9585)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [7]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4320.405845619005  loss: 1.4612 (1.4625)  acc1: 100.0000 (99.8539)  acc5: 100.0000 (99.9591)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [7] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:25  loss: 1.4622 (1.4622)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3253  data: 0.3038  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.47, Acc@5 = 99.86, loss = 1.4659395504601394\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:02:20 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.85810630341881 train_acc5 99.85810630341881\n",
      "Epoch: [8]  [  0/468]  eta: 0:03:27  lr: 0.01  img/s: 2437.663058481656  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4426  data: 0.3901  max mem: 2151\n",
      "Epoch: [8]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4357.683070754296  loss: 1.4613 (1.4621)  acc1: 100.0000 (99.9226)  acc5: 100.0000 (99.9845)  time: 0.0301  data: 0.0002  max mem: 2151\n",
      "Epoch: [8]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4630.992081428448  loss: 1.4612 (1.4621)  acc1: 100.0000 (99.9223)  acc5: 100.0000 (99.9728)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [8]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3750.9321036819674  loss: 1.4612 (1.4621)  acc1: 100.0000 (99.9351)  acc5: 100.0000 (99.9740)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [8]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3795.6697185438657  loss: 1.4614 (1.4622)  acc1: 100.0000 (99.9201)  acc5: 100.0000 (99.9649)  time: 0.0340  data: 0.0003  max mem: 2151\n",
      "Epoch: [8] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3951  data: 0.3727  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.42, Acc@5 = 99.84, loss = 1.4661531765249711\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:02:36 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.9198717948718 train_acc5 99.9198717948718\n",
      "Epoch: [9]  [  0/468]  eta: 0:04:39  lr: 0.01  img/s: 2473.649127333714  loss: 1.4616 (1.4616)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5965  data: 0.5447  max mem: 2151\n",
      "Epoch: [9]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3810.027052728692  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9691)  time: 0.0338  data: 0.0003  max mem: 2151\n",
      "Epoch: [9]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3864.910927297727  loss: 1.4612 (1.4623)  acc1: 100.0000 (99.8912)  acc5: 100.0000 (99.9456)  time: 0.0340  data: 0.0003  max mem: 2151\n",
      "Epoch: [9]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3798.516396980267  loss: 1.4613 (1.4622)  acc1: 100.0000 (99.9092)  acc5: 100.0000 (99.9585)  time: 0.0341  data: 0.0002  max mem: 2151\n",
      "Epoch: [9]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3759.2843178444386  loss: 1.4613 (1.4621)  acc1: 100.0000 (99.9182)  acc5: 100.0000 (99.9649)  time: 0.0298  data: 0.0003  max mem: 2151\n",
      "Epoch: [9] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5833  data: 0.5613  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4653573036193848\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:02:54 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.91820245726495 train_acc5 99.91820245726495\n",
      "Epoch: [10]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 3040.211291692621  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6076  data: 0.5654  max mem: 2151\n",
      "Epoch: [10]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 5098.29552533617  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9845)  time: 0.0254  data: 0.0002  max mem: 2151\n",
      "Epoch: [10]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 3998.5916806315868  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9845)  time: 0.0312  data: 0.0002  max mem: 2151\n",
      "Epoch: [10]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4340.420176083951  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9766)  time: 0.0318  data: 0.0002  max mem: 2151\n",
      "Epoch: [10]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4239.74880753072  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9532)  acc5: 100.0000 (99.9688)  time: 0.0319  data: 0.0002  max mem: 2151\n",
      "Epoch: [10] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4630 (1.4630)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4061  data: 0.3898  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4656149646903895\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:03:09 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.94491185897436 train_acc5 99.94491185897436\n",
      "Epoch: [11]  [  0/468]  eta: 0:03:53  lr: 0.01  img/s: 2701.549925274371  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4993  data: 0.4519  max mem: 2151\n",
      "Epoch: [11]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3767.0393353821974  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [11]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4358.709057253272  loss: 1.4612 (1.4619)  acc1: 100.0000 (99.9417)  acc5: 100.0000 (99.9611)  time: 0.0301  data: 0.0002  max mem: 2151\n",
      "Epoch: [11]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4379.223557241323  loss: 1.4612 (1.4619)  acc1: 100.0000 (99.9403)  acc5: 100.0000 (99.9663)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [11]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4354.608007267536  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9454)  acc5: 100.0000 (99.9669)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [11] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4616 (1.4616)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3690  data: 0.3495  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.85, loss = 1.4654313899293732\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:03:25 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.94658119658119 train_acc5 99.94658119658119\n",
      "Epoch: [12]  [  0/468]  eta: 0:03:08  lr: 0.01  img/s: 3271.0501072333786  loss: 1.4619 (1.4619)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4030  data: 0.3639  max mem: 2151\n",
      "Epoch: [12]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4281.950167490828  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9691)  time: 0.0307  data: 0.0002  max mem: 2151\n",
      "Epoch: [12]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4370.524931007253  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9728)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [12]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4245.985606048623  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9507)  acc5: 100.0000 (99.9714)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [12]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4216.14229956729  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9474)  acc5: 100.0000 (99.9649)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [12] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:26  loss: 1.4651 (1.4651)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3374  data: 0.3187  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.53, Acc@5 = 99.86, loss = 1.465613348574578\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:03:41 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.94825053418803 train_acc5 99.94825053418803\n",
      "Epoch: [13]  [  0/468]  eta: 0:03:09  lr: 0.01  img/s: 2766.5772354371934  loss: 1.4672 (1.4672)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4055  data: 0.3592  max mem: 2151\n",
      "Epoch: [13]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4732.642031029619  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9845)  time: 0.0312  data: 0.0002  max mem: 2151\n",
      "Epoch: [13]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4367.787041556836  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9456)  acc5: 100.0000 (99.9611)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [13]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3778.1470101830414  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9481)  acc5: 100.0000 (99.9663)  time: 0.0319  data: 0.0002  max mem: 2151\n",
      "Epoch: [13]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4037.4126671379368  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9532)  acc5: 100.0000 (99.9688)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [13] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3763  data: 0.3550  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.88, loss = 1.4650679192965543\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:03:58 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.95492788461539 train_acc5 99.95492788461539\n",
      "Epoch: [14]  [  0/468]  eta: 0:03:06  lr: 0.01  img/s: 2774.8421629332533  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3977  data: 0.3515  max mem: 2151\n",
      "Epoch: [14]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4373.37312946505  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9768)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [14]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4032.0759444235823  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9845)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [14]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4510.800057133735  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9740)  acc5: 100.0000 (99.9844)  time: 0.0290  data: 0.0001  max mem: 2151\n",
      "Epoch: [14]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4382.405041385728  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [14] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4648 (1.4648)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4432  data: 0.4232  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.88, loss = 1.4651964103119284\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:04:13 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.9599358974359 train_acc5 99.9599358974359\n",
      "Epoch: [15]  [  0/468]  eta: 0:03:23  lr: 0.01  img/s: 2831.836610684446  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4340  data: 0.3887  max mem: 2151\n",
      "Epoch: [15]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3512.4497016643986  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9845)  time: 0.0335  data: 0.0003  max mem: 2151\n",
      "Epoch: [15]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4347.801783270301  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9883)  time: 0.0298  data: 0.0001  max mem: 2151\n",
      "Epoch: [15]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4354.219515162329  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9818)  time: 0.0295  data: 0.0001  max mem: 2151\n",
      "Epoch: [15]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4376.581793281106  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [15] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5745  data: 0.5460  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4652548168278947\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:04:29 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [16]  [  0/468]  eta: 0:03:52  lr: 0.01  img/s: 2902.5226770180625  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4968  data: 0.4527  max mem: 2151\n",
      "Epoch: [16]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3777.243229932528  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0349  data: 0.0003  max mem: 2151\n",
      "Epoch: [16]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4256.623630337916  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9806)  time: 0.0337  data: 0.0003  max mem: 2151\n",
      "Epoch: [16]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3813.4640688151267  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9714)  acc5: 100.0000 (99.9792)  time: 0.0338  data: 0.0002  max mem: 2151\n",
      "Epoch: [16]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4908.175054624576  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9688)  time: 0.0290  data: 0.0002  max mem: 2151\n",
      "Epoch: [16] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5980  data: 0.5704  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.54, Acc@5 = 99.87, loss = 1.4652441468419908\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:04:46 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [17]  [  0/468]  eta: 0:04:34  lr: 0.01  img/s: 2536.597741554453  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5859  data: 0.5354  max mem: 2151\n",
      "Epoch: [17]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3798.946455233122  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [17]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3774.9325833216144  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0332  data: 0.0002  max mem: 2151\n",
      "Epoch: [17]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4359.806335826411  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9740)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [17]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4119.066672804554  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9727)  time: 0.0262  data: 0.0002  max mem: 2151\n",
      "Epoch: [17] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4627 (1.4627)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4587  data: 0.4320  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.4652582256099846\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:05:03 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [18]  [  0/468]  eta: 0:04:15  lr: 0.01  img/s: 2442.320589573287  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5449  data: 0.4924  max mem: 2151\n",
      "Epoch: [18]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3799.215291095527  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0340  data: 0.0003  max mem: 2151\n",
      "Epoch: [18]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4383.585867905579  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9845)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [18]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4649.319858321859  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9740)  acc5: 100.0000 (99.9844)  time: 0.0293  data: 0.0002  max mem: 2151\n",
      "Epoch: [18]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3791.970052478793  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9747)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [18] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5913  data: 0.5662  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4653188488151454\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:05:20 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [19]  [  0/468]  eta: 0:04:24  lr: 0.01  img/s: 2263.8739347324654  loss: 1.4690 (1.4690)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5658  data: 0.5092  max mem: 2151\n",
      "Epoch: [19]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3820.519857959195  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0338  data: 0.0003  max mem: 2151\n",
      "Epoch: [19]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3719.9262210458487  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9495)  acc5: 100.0000 (99.9650)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [19]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3770.1873749113406  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9689)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [19]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4392.6241153320625  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9571)  acc5: 100.0000 (99.9669)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [19] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3480  data: 0.3236  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.88, loss = 1.4651861386963083\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:05:37 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [20]  [  0/468]  eta: 0:05:05  lr: 0.01  img/s: 2276.3814724987706  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6518  data: 0.5955  max mem: 2151\n",
      "Epoch: [20]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3513.0242960810874  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9845)  time: 0.0347  data: 0.0002  max mem: 2151\n",
      "Epoch: [20]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 5070.943327792051  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9806)  time: 0.0294  data: 0.0001  max mem: 2151\n",
      "Epoch: [20]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4380.68861073486  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9689)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [20]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4364.9816008780845  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9688)  acc5: 100.0000 (99.9727)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [20] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4650 (1.4650)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3885  data: 0.3624  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4651388020455083\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:05:54 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [21]  [  0/468]  eta: 0:03:09  lr: 0.01  img/s: 2804.8509571177797  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4042  data: 0.3586  max mem: 2151\n",
      "Epoch: [21]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4260.880253968254  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0307  data: 0.0002  max mem: 2151\n",
      "Epoch: [21]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 3794.7038924504695  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9689)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [21]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3838.493633146248  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9740)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [21]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3786.620999992947  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9747)  time: 0.0333  data: 0.0004  max mem: 2151\n",
      "Epoch: [21] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5407  data: 0.5160  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652954943572418\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:06:11 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.9599358974359 train_acc5 99.9599358974359\n",
      "Epoch: [22]  [  0/468]  eta: 0:04:12  lr: 0.01  img/s: 2333.2474793129823  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5395  data: 0.4846  max mem: 2151\n",
      "Epoch: [22]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3790.6849021033827  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [22]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3835.066161868705  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9456)  acc5: 100.0000 (99.9611)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [22]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4146.425740280202  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9689)  time: 0.0345  data: 0.0003  max mem: 2151\n",
      "Epoch: [22]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3783.818784094273  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9688)  time: 0.0340  data: 0.0003  max mem: 2151\n",
      "Epoch: [22] Total time: 0:00:16\n",
      "Test:  [ 0/79]  eta: 0:00:26  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3362  data: 0.3143  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652438465552995\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:06:28 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [23]  [  0/468]  eta: 0:04:27  lr: 0.01  img/s: 2182.0472768655504  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5710  data: 0.5122  max mem: 2151\n",
      "Epoch: [23]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3764.160446479278  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0341  data: 0.0002  max mem: 2151\n",
      "Epoch: [23]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4340.314906139344  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9806)  time: 0.0294  data: 0.0001  max mem: 2151\n",
      "Epoch: [23]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4053.385519063798  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9740)  time: 0.0311  data: 0.0002  max mem: 2151\n",
      "Epoch: [23]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4379.545070399557  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9688)  time: 0.0313  data: 0.0002  max mem: 2151\n",
      "Epoch: [23] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4205  data: 0.3971  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.86, loss = 1.4652338269390637\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:06:45 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [24]  [  0/468]  eta: 0:03:19  lr: 0.01  img/s: 2725.357564558787  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4260  data: 0.3790  max mem: 2151\n",
      "Epoch: [24]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4420.145825786267  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0339  data: 0.0002  max mem: 2151\n",
      "Epoch: [24]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4292.563460462141  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9728)  time: 0.0325  data: 0.0001  max mem: 2151\n",
      "Epoch: [24]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4420.546171644065  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9740)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [24]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4356.657567150856  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9766)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [24] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:26  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3344  data: 0.3086  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.87, loss = 1.465179693849781\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:07:01 max_test_acc1 99.59 test_acc5_at_max_test_acc1 99.89 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [25]  [  0/468]  eta: 0:03:12  lr: 0.01  img/s: 2839.550174803908  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4116  data: 0.3665  max mem: 2151\n",
      "Epoch: [25]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3749.25563920276  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9613)  time: 0.0317  data: 0.0002  max mem: 2151\n",
      "Epoch: [25]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4570.51447251924  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9611)  time: 0.0311  data: 0.0002  max mem: 2151\n",
      "Epoch: [25]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4388.781897848407  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9689)  time: 0.0289  data: 0.0002  max mem: 2151\n",
      "Epoch: [25]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4364.910623836354  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [25] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4086  data: 0.3883  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:07:17 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [26]  [  0/468]  eta: 0:03:27  lr: 0.01  img/s: 2400.8823776686613  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4432  data: 0.3898  max mem: 2151\n",
      "Epoch: [26]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3774.9325833216144  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9845)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [26]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3799.0539850124187  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9728)  time: 0.0317  data: 0.0002  max mem: 2151\n",
      "Epoch: [26]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4200.506310098504  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9740)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [26]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4389.320121328068  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9786)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [26] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3759  data: 0.3537  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.85, loss = 1.4653016932402985\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:07:33 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [27]  [  0/468]  eta: 0:03:14  lr: 0.01  img/s: 2812.1970373164036  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4157  data: 0.3701  max mem: 2151\n",
      "Epoch: [27]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3797.19994907558  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9536)  acc5: 100.0000 (99.9536)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [27]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4357.966053266014  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9611)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [27]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4432.041474730464  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9740)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [27]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4053.018314686476  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9727)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [27] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3437  data: 0.3198  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.86, loss = 1.465289671209794\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:07:49 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [28]  [  0/468]  eta: 0:03:19  lr: 0.01  img/s: 2417.5751429729366  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4261  data: 0.3731  max mem: 2151\n",
      "Epoch: [28]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4289.134073659822  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9691)  time: 0.0307  data: 0.0002  max mem: 2151\n",
      "Epoch: [28]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3767.7531352857372  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9689)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [28]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4376.510438489945  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9740)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [28]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3783.818784094273  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0334  data: 0.0003  max mem: 2151\n",
      "Epoch: [28] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6096  data: 0.5753  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4652095354056056\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:08:06 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [29]  [  0/468]  eta: 0:04:43  lr: 0.01  img/s: 2075.641542916572  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6066  data: 0.5449  max mem: 2151\n",
      "Epoch: [29]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 4867.6347942771135  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0304  data: 0.0002  max mem: 2151\n",
      "Epoch: [29]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4389.284235655771  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9845)  time: 0.0288  data: 0.0001  max mem: 2151\n",
      "Epoch: [29]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4344.9867838557475  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9740)  acc5: 100.0000 (99.9818)  time: 0.0288  data: 0.0001  max mem: 2151\n",
      "Epoch: [29]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4336.703732723733  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9727)  time: 0.0285  data: 0.0001  max mem: 2151\n",
      "Epoch: [29] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3899  data: 0.3659  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.86, loss = 1.4652817943428136\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:08:22 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [30]  [  0/468]  eta: 0:03:08  lr: 0.01  img/s: 2787.1589166402764  loss: 1.4619 (1.4619)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4027  data: 0.3567  max mem: 2151\n",
      "Epoch: [30]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3784.9391726121653  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9613)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [30]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4419.199841957098  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9611)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [30]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3939.3539373660883  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9714)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [30]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3772.3596759347092  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [30] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3758  data: 0.3538  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.86, loss = 1.4652749692337423\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:08:38 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [31]  [  0/468]  eta: 0:03:11  lr: 0.01  img/s: 2819.5520823486163  loss: 1.4614 (1.4614)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4096  data: 0.3641  max mem: 2151\n",
      "Epoch: [31]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3880.695310241138  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0336  data: 0.0003  max mem: 2151\n",
      "Epoch: [31]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3781.020712580375  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9883)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [31]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4320.092956635794  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9714)  acc5: 100.0000 (99.9766)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [31]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3738.6033063606355  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9727)  time: 0.0331  data: 0.0001  max mem: 2151\n",
      "Epoch: [31] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:24  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3128  data: 0.2887  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.54, Acc@5 = 99.87, loss = 1.46533938751945\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:08:55 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [32]  [  0/468]  eta: 0:03:10  lr: 0.01  img/s: 2769.645802487606  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4064  data: 0.3601  max mem: 2151\n",
      "Epoch: [32]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3786.2471314221234  loss: 1.4612 (1.4613)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9923)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [32]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4311.350427624975  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9806)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [32]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4384.373439171587  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9714)  acc5: 100.0000 (99.9766)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [32]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4357.683070754296  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9727)  time: 0.0294  data: 0.0001  max mem: 2151\n",
      "Epoch: [32] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4623 (1.4623)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3782  data: 0.3567  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.87, loss = 1.4652969429764566\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:09:11 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [33]  [  0/468]  eta: 0:03:15  lr: 0.01  img/s: 2842.210956525422  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4184  data: 0.3734  max mem: 2151\n",
      "Epoch: [33]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3736.3656811981514  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9923)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [33]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4368.817791955211  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0292  data: 0.0001  max mem: 2151\n",
      "Epoch: [33]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3769.1286234809286  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9714)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [33]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4259.054944706237  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9747)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [33] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3801  data: 0.3612  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.465332399440717\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:09:27 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [34]  [  0/468]  eta: 0:03:10  lr: 0.01  img/s: 2668.092535993122  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4066  data: 0.3586  max mem: 2151\n",
      "Epoch: [34]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4326.185047301326  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [34]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3771.4321681465663  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9728)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [34]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4225.998992443325  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9714)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [34]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4179.70767709639  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9688)  acc5: 100.0000 (99.9786)  time: 0.0333  data: 0.0003  max mem: 2151\n",
      "Epoch: [34] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4649 (1.4649)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3527  data: 0.3311  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.88, loss = 1.4653223285192176\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:09:43 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [35]  [  0/468]  eta: 0:03:35  lr: 0.01  img/s: 2639.8078033189922  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4596  data: 0.4111  max mem: 2151\n",
      "Epoch: [35]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4065.725433175815  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9691)  time: 0.0280  data: 0.0002  max mem: 2151\n",
      "Epoch: [35]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4579.246946434664  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9767)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [35]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4308.962807197779  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9740)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [35]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4361.045862914886  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [35] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4050  data: 0.3824  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.465211137940612\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:10:00 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [36]  [  0/468]  eta: 0:03:28  lr: 0.01  img/s: 2444.4556796036936  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4464  data: 0.3940  max mem: 2151\n",
      "Epoch: [36]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 3768.3878512216866  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [36]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4224.768541907662  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9728)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [36]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3848.1508092377826  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9740)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [36]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4316.411226975615  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9727)  time: 0.0310  data: 0.0002  max mem: 2151\n",
      "Epoch: [36] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3801  data: 0.3594  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.87, loss = 1.465242927587485\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:10:16 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [37]  [  0/468]  eta: 0:03:27  lr: 0.01  img/s: 2423.4900870318875  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4434  data: 0.3905  max mem: 2151\n",
      "Epoch: [37]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3782.192733907726  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0321  data: 0.0002  max mem: 2151\n",
      "Epoch: [37]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4669.498425731035  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9806)  time: 0.0301  data: 0.0002  max mem: 2151\n",
      "Epoch: [37]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4425.173604127858  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9740)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [37]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3762.4457713116362  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0299  data: 0.0001  max mem: 2151\n",
      "Epoch: [37] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3733  data: 0.3522  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652412646933446\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:10:32 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [38]  [  0/468]  eta: 0:03:20  lr: 0.01  img/s: 2711.1543204577247  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4289  data: 0.3816  max mem: 2151\n",
      "Epoch: [38]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3380.7353261588255  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9768)  time: 0.0336  data: 0.0003  max mem: 2151\n",
      "Epoch: [38]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3859.1600678570403  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9689)  time: 0.0332  data: 0.0002  max mem: 2151\n",
      "Epoch: [38]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3862.5751800450385  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9714)  acc5: 100.0000 (99.9766)  time: 0.0345  data: 0.0002  max mem: 2151\n",
      "Epoch: [38]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3790.738432643493  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9688)  acc5: 100.0000 (99.9766)  time: 0.0336  data: 0.0003  max mem: 2151\n",
      "Epoch: [38] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5865  data: 0.5590  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.88, loss = 1.4653718139551863\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:10:49 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [39]  [  0/468]  eta: 0:05:00  lr: 0.01  img/s: 2311.269446022972  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6429  data: 0.5875  max mem: 2151\n",
      "Epoch: [39]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3764.503569074565  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9923)  time: 0.0342  data: 0.0003  max mem: 2151\n",
      "Epoch: [39]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3778.6788476833312  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9845)  time: 0.0338  data: 0.0002  max mem: 2151\n",
      "Epoch: [39]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4271.695101089265  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9818)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [39]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4374.549093101707  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9766)  time: 0.0299  data: 0.0001  max mem: 2151\n",
      "Epoch: [39] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4459  data: 0.4242  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652145014533513\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:11:06 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [40]  [  0/468]  eta: 0:03:19  lr: 0.01  img/s: 2616.9548868881943  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4270  data: 0.3780  max mem: 2151\n",
      "Epoch: [40]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3770.29328276976  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9536)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [40]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4343.650935687182  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9689)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [40]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3786.3806474363496  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9533)  acc5: 100.0000 (99.9663)  time: 0.0319  data: 0.0002  max mem: 2151\n",
      "Epoch: [40]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4340.525451135114  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9571)  acc5: 100.0000 (99.9708)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [40] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3902  data: 0.3685  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.88, loss = 1.465175168423713\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:11:22 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [41]  [  0/468]  eta: 0:03:27  lr: 0.01  img/s: 2837.749086891944  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4437  data: 0.3985  max mem: 2151\n",
      "Epoch: [41]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4319.710598307103  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [41]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4368.497851842208  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9650)  time: 0.0290  data: 0.0002  max mem: 2151\n",
      "Epoch: [41]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4425.137129810506  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9689)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [41]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4405.781512605042  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0302  data: 0.0002  max mem: 2151\n",
      "Epoch: [41] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5697  data: 0.5466  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.465149011793016\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:11:38 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [42]  [  0/468]  eta: 0:04:21  lr: 0.01  img/s: 2911.542197685391  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5584  data: 0.5143  max mem: 2151\n",
      "Epoch: [42]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3890.4816951215976  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0337  data: 0.0002  max mem: 2151\n",
      "Epoch: [42]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3753.9482711603678  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0324  data: 0.0001  max mem: 2151\n",
      "Epoch: [42]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3743.0344135199957  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9740)  time: 0.0338  data: 0.0002  max mem: 2151\n",
      "Epoch: [42]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4372.981282072167  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0332  data: 0.0002  max mem: 2151\n",
      "Epoch: [42] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3586  data: 0.3358  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.4652497692953181\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:11:55 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [43]  [  0/468]  eta: 0:04:29  lr: 0.01  img/s: 2436.910652359424  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5756  data: 0.5230  max mem: 2151\n",
      "Epoch: [43]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3768.096913207653  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9381)  acc5: 100.0000 (99.9536)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [43]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3848.4818282175165  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9456)  acc5: 100.0000 (99.9650)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [43]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4260.068812289723  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9533)  acc5: 100.0000 (99.9663)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [43]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4380.581378460634  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9708)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [43] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4653 (1.4653)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5386  data: 0.5143  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.87, loss = 1.4654281742965118\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:12:12 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [44]  [  0/468]  eta: 0:04:49  lr: 0.01  img/s: 2126.3898605830163  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6178  data: 0.5575  max mem: 2151\n",
      "Epoch: [44]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3729.79840351255  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9768)  time: 0.0345  data: 0.0003  max mem: 2151\n",
      "Epoch: [44]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4283.692617031972  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9689)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [44]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4354.25482976204  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9689)  time: 0.0328  data: 0.0001  max mem: 2151\n",
      "Epoch: [44]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4381.403626748494  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9708)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [44] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4799  data: 0.4628  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4652770259712316\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:12:29 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [45]  [  0/468]  eta: 0:04:47  lr: 0.01  img/s: 2460.182711342474  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6152  data: 0.5631  max mem: 2151\n",
      "Epoch: [45]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3781.9795850797786  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9845)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [45]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4421.966164236884  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9728)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [45]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3781.4201836930183  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9689)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [45]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3778.9182234109944  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [45] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4650 (1.4650)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4080  data: 0.3883  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652331237551532\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:12:46 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [46]  [  0/468]  eta: 0:03:13  lr: 0.01  img/s: 2761.141916703525  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4130  data: 0.3666  max mem: 2151\n",
      "Epoch: [46]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4866.487599709934  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [46]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3774.959126417708  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [46]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4527.2324285124005  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9766)  time: 0.0316  data: 0.0002  max mem: 2151\n",
      "Epoch: [46]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3811.2982969268014  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [46] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3841  data: 0.3626  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.4652608723580083\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:13:02 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [47]  [  0/468]  eta: 0:03:16  lr: 0.01  img/s: 2851.055792168067  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4201  data: 0.3752  max mem: 2151\n",
      "Epoch: [47]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3780.4882157016004  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9923)  time: 0.0328  data: 0.0001  max mem: 2151\n",
      "Epoch: [47]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4380.795848259092  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9806)  time: 0.0294  data: 0.0001  max mem: 2151\n",
      "Epoch: [47]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4358.49674454854  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0302  data: 0.0002  max mem: 2151\n",
      "Epoch: [47]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4398.526196776916  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9747)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [47] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3448  data: 0.3209  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.87, loss = 1.4653200680696512\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:13:18 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [48]  [  0/468]  eta: 0:03:10  lr: 0.01  img/s: 2733.781326380968  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4061  data: 0.3592  max mem: 2151\n",
      "Epoch: [48]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3806.0834845735026  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [48]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3811.9207043453566  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9689)  time: 0.0331  data: 0.0003  max mem: 2151\n",
      "Epoch: [48]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4385.734456307745  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9766)  time: 0.0314  data: 0.0003  max mem: 2151\n",
      "Epoch: [48]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3787.342240783329  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9708)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [48] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4655 (1.4655)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3753  data: 0.3562  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.88, loss = 1.4650817656818824\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:13:34 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [49]  [  0/468]  eta: 0:03:01  lr: 0.01  img/s: 4146.425740280202  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3887  data: 0.3578  max mem: 2151\n",
      "Epoch: [49]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3876.3802509783536  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0323  data: 0.0002  max mem: 2151\n",
      "Epoch: [49]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3892.5690752744304  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9611)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [49]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3782.6191036489563  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9663)  time: 0.0329  data: 0.0001  max mem: 2151\n",
      "Epoch: [49]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4420.50977356937  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0310  data: 0.0002  max mem: 2151\n",
      "Epoch: [49] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4734  data: 0.4505  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.88, loss = 1.4652784142313124\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:13:51 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [50]  [  0/468]  eta: 0:03:08  lr: 0.01  img/s: 2730.3889171430314  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4028  data: 0.3559  max mem: 2151\n",
      "Epoch: [50]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3791.0328776409447  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9613)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [50]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4371.841761534828  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [50]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4395.609163405328  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [50]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3775.675931135366  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9727)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [50] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3849  data: 0.3626  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.88, loss = 1.4652692592596706\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:14:07 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [51]  [  0/468]  eta: 0:03:15  lr: 0.01  img/s: 2853.3590144243544  loss: 1.4690 (1.4690)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.4185  data: 0.3735  max mem: 2151\n",
      "Epoch: [51]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3786.968229783872  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9381)  acc5: 100.0000 (99.9459)  time: 0.0326  data: 0.0003  max mem: 2151\n",
      "Epoch: [51]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3803.899133466065  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9495)  acc5: 100.0000 (99.9689)  time: 0.0342  data: 0.0002  max mem: 2151\n",
      "Epoch: [51]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3913.309998469287  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9714)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [51]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4350.69094563165  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9727)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [51] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4141  data: 0.3909  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.465376749823365\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:14:24 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [52]  [  0/468]  eta: 0:03:30  lr: 0.01  img/s: 2913.201070058441  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4501  data: 0.4061  max mem: 2151\n",
      "Epoch: [52]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4356.94041648407  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9845)  time: 0.0268  data: 0.0002  max mem: 2151\n",
      "Epoch: [52]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3775.330768960304  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9845)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [52]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4376.403410665666  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9766)  acc5: 100.0000 (99.9844)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [52]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3855.806373305946  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0318  data: 0.0002  max mem: 2151\n",
      "Epoch: [52] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3787  data: 0.3539  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652745768993716\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:14:40 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [53]  [  0/468]  eta: 0:03:18  lr: 0.01  img/s: 2489.235810958053  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4242  data: 0.3727  max mem: 2151\n",
      "Epoch: [53]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3816.9072915481743  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9536)  acc5: 100.0000 (99.9613)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [53]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4319.50206774479  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9728)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [53]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4386.236096700137  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9714)  time: 0.0321  data: 0.0002  max mem: 2151\n",
      "Epoch: [53]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4299.610875745805  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0301  data: 0.0002  max mem: 2151\n",
      "Epoch: [53] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3448  data: 0.3234  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.88, loss = 1.4653005298179915\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:14:57 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [54]  [  0/468]  eta: 0:03:16  lr: 0.01  img/s: 2414.6502053171057  loss: 1.4627 (1.4627)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4191  data: 0.3661  max mem: 2151\n",
      "Epoch: [54]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3813.1390461308997  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [54]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4360.585384871547  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9767)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [54]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4300.024124370259  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [54]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3937.6492522535077  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [54] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4405  data: 0.4174  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4653178061111063\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:15:13 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [55]  [  0/468]  eta: 0:03:18  lr: 0.01  img/s: 2583.7311503496335  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4237  data: 0.3741  max mem: 2151\n",
      "Epoch: [55]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3771.6971238285255  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [55]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4359.735526988948  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [55]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4379.009241360185  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9740)  acc5: 100.0000 (99.9818)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [55]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4415.964729590788  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [55] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4218  data: 0.3993  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4652010836178744\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:15:29 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [56]  [  0/468]  eta: 0:04:03  lr: 0.01  img/s: 2352.4992528909397  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5199  data: 0.4654  max mem: 2151\n",
      "Epoch: [56]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4545.47766084446  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [56]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 5114.566319580066  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9650)  time: 0.0278  data: 0.0002  max mem: 2151\n",
      "Epoch: [56]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3357.4156817130065  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0313  data: 0.0002  max mem: 2151\n",
      "Epoch: [56]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3806.0565019814685  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [56] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3944  data: 0.3755  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.53, Acc@5 = 99.87, loss = 1.4652442826500423\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:15:45 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [57]  [  0/468]  eta: 0:03:19  lr: 0.01  img/s: 2852.631279157501  loss: 1.4614 (1.4614)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4254  data: 0.3805  max mem: 2151\n",
      "Epoch: [57]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3776.8712107888314  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9613)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [57]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3784.832440358694  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9689)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [57]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 5077.273614526196  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9740)  time: 0.0323  data: 0.0002  max mem: 2151\n",
      "Epoch: [57]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3779.982482574104  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0320  data: 0.0002  max mem: 2151\n",
      "Epoch: [57] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4645 (1.4645)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3766  data: 0.3548  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.89, loss = 1.465198118475419\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:16:02 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [58]  [  0/468]  eta: 0:03:23  lr: 0.01  img/s: 2689.976611117235  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4344  data: 0.3868  max mem: 2151\n",
      "Epoch: [58]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3778.492687527272  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0321  data: 0.0002  max mem: 2151\n",
      "Epoch: [58]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4361.045862914886  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9611)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [58]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4387.885151978292  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9689)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [58]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3794.569788810042  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9766)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [58] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3561  data: 0.3302  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.89, loss = 1.4652035794680631\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:16:18 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [59]  [  0/468]  eta: 0:03:18  lr: 0.01  img/s: 2822.0271547441957  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4244  data: 0.3789  max mem: 2151\n",
      "Epoch: [59]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4957.531460653407  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9691)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [59]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4183.518366710824  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9650)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [59]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4382.333496587978  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9689)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [59]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4216.837726601527  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9727)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [59] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3653  data: 0.3437  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.87, loss = 1.465196292611617\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:16:33 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [60]  [  0/468]  eta: 0:03:05  lr: 0.01  img/s: 3001.6432608926584  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3966  data: 0.3539  max mem: 2151\n",
      "Epoch: [60]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4404.841666529923  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [60]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4178.47151029303  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9495)  acc5: 100.0000 (99.9611)  time: 0.0299  data: 0.0001  max mem: 2151\n",
      "Epoch: [60]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4358.5321285629625  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9533)  acc5: 100.0000 (99.9637)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [60]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4030.9558140058716  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9688)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [60] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:25  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3254  data: 0.3080  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.88, loss = 1.4651572236531898\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:16:49 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [61]  [  0/468]  eta: 0:03:30  lr: 0.01  img/s: 3027.848875704271  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4499  data: 0.4076  max mem: 2151\n",
      "Epoch: [61]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4021.203745037825  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9613)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [61]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4376.403410665666  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9650)  time: 0.0312  data: 0.0002  max mem: 2151\n",
      "Epoch: [61]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3812.299660574042  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9740)  acc5: 100.0000 (99.9740)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [61]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3851.4083043989785  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9688)  acc5: 100.0000 (99.9747)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [61] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:24  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3076  data: 0.2833  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4652781094176859\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:17:05 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [62]  [  0/468]  eta: 0:03:12  lr: 0.01  img/s: 2549.353543123875  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4122  data: 0.3619  max mem: 2151\n",
      "Epoch: [62]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 3757.9686130671557  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9691)  time: 0.0319  data: 0.0001  max mem: 2151\n",
      "Epoch: [62]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4275.300911805693  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9650)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [62]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4349.069723358581  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9663)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [62]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4304.782199414665  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9727)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [62] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4644 (1.4644)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3640  data: 0.3455  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.53, Acc@5 = 99.86, loss = 1.4654744395726844\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:17:21 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [63]  [  0/468]  eta: 0:03:17  lr: 0.01  img/s: 2646.444246173564  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4212  data: 0.3727  max mem: 2151\n",
      "Epoch: [63]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3791.380917070966  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9923)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [63]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3870.930126250063  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9728)  time: 0.0332  data: 0.0002  max mem: 2151\n",
      "Epoch: [63]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4401.916253289932  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9740)  time: 0.0293  data: 0.0002  max mem: 2151\n",
      "Epoch: [63]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4627.599120803345  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9747)  time: 0.0293  data: 0.0002  max mem: 2151\n",
      "Epoch: [63] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3841  data: 0.3605  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4651533591596386\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:17:37 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [64]  [  0/468]  eta: 0:02:52  lr: 0.01  img/s: 2577.5288757447584  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3678  data: 0.3181  max mem: 2151\n",
      "Epoch: [64]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3775.410416168549  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9536)  time: 0.0316  data: 0.0002  max mem: 2151\n",
      "Epoch: [64]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4455.54514295199  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9689)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [64]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4018.765575525297  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9766)  time: 0.0315  data: 0.0002  max mem: 2151\n",
      "Epoch: [64]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4289.476765739853  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [64] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4185  data: 0.3989  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.88, loss = 1.4653894176966027\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:17:54 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [65]  [  0/468]  eta: 0:03:33  lr: 0.01  img/s: 2835.845422468254  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4563  data: 0.4111  max mem: 2151\n",
      "Epoch: [65]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3796.313875787553  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9536)  time: 0.0323  data: 0.0002  max mem: 2151\n",
      "Epoch: [65]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4169.8387740677745  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9495)  acc5: 100.0000 (99.9572)  time: 0.0303  data: 0.0001  max mem: 2151\n",
      "Epoch: [65]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3774.295660976913  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9637)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [65]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4228.4287413264865  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9688)  time: 0.0301  data: 0.0001  max mem: 2151\n",
      "Epoch: [65] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3540  data: 0.3345  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.54, Acc@5 = 99.88, loss = 1.4653259319595144\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:18:10 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [66]  [  0/468]  eta: 0:03:12  lr: 0.01  img/s: 3281.5669246097236  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4113  data: 0.3723  max mem: 2151\n",
      "Epoch: [66]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3851.6569837933234  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [66]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 6364.423116590599  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9767)  time: 0.0267  data: 0.0002  max mem: 2151\n",
      "Epoch: [66]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3684.7694715168154  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9714)  acc5: 100.0000 (99.9766)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [66]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4341.78915019571  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9688)  acc5: 100.0000 (99.9786)  time: 0.0329  data: 0.0003  max mem: 2151\n",
      "Epoch: [66] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:26  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3366  data: 0.3132  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.88, loss = 1.4652096063275881\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:18:26 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [67]  [  0/468]  eta: 0:04:53  lr: 0.01  img/s: 2489.7668331547875  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6268  data: 0.5753  max mem: 2151\n",
      "Epoch: [67]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3767.277238630543  loss: 1.4612 (1.4613)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (99.9923)  time: 0.0343  data: 0.0003  max mem: 2151\n",
      "Epoch: [67]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4364.555773248677  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9845)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [67]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3783.472131586551  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9870)  acc5: 100.0000 (99.9896)  time: 0.0309  data: 0.0002  max mem: 2151\n",
      "Epoch: [67]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3780.4882157016004  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9766)  acc5: 100.0000 (99.9805)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [67] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:39  loss: 1.4626 (1.4626)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5013  data: 0.4761  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.465254834935635\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:18:43 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [68]  [  0/468]  eta: 0:04:58  lr: 0.01  img/s: 2440.7217180993252  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6375  data: 0.5850  max mem: 2151\n",
      "Epoch: [68]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3778.093834666892  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9536)  acc5: 100.0000 (99.9768)  time: 0.0338  data: 0.0002  max mem: 2151\n",
      "Epoch: [68]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4318.1818415803355  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9806)  time: 0.0330  data: 0.0002  max mem: 2151\n",
      "Epoch: [68]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4385.12547578208  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9792)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [68]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3821.063692590194  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9766)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [68] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5905  data: 0.5635  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.87, loss = 1.4652564178539227\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:19:01 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [69]  [  0/468]  eta: 0:04:57  lr: 0.01  img/s: 2545.376977052911  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6359  data: 0.5855  max mem: 2151\n",
      "Epoch: [69]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3337.068466754931  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9613)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [69]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3768.916944547797  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9456)  acc5: 100.0000 (99.9534)  time: 0.0342  data: 0.0002  max mem: 2151\n",
      "Epoch: [69]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4730.515300772749  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9533)  acc5: 100.0000 (99.9637)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [69]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3774.1895281480233  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9688)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [69] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4625 (1.4625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3990  data: 0.3802  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.87, loss = 1.46514175209818\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:19:18 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [70]  [  0/468]  eta: 0:03:02  lr: 0.01  img/s: 2552.6505546336757  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3906  data: 0.3404  max mem: 2151\n",
      "Epoch: [70]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4600.081501855041  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9459)  time: 0.0307  data: 0.0002  max mem: 2151\n",
      "Epoch: [70]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4369.386690105884  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9572)  time: 0.0287  data: 0.0002  max mem: 2151\n",
      "Epoch: [70]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4413.8590020800275  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9689)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [70]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4350.76146097555  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9708)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [70] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3875  data: 0.3646  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651598673832567\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:19:33 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [71]  [  0/468]  eta: 0:04:43  lr: 0.01  img/s: 2797.7326767242503  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6053  data: 0.5595  max mem: 2151\n",
      "Epoch: [71]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 4136.872573722617  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9845)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [71]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4696.9922572855885  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [71]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4159.146217133295  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9663)  acc5: 100.0000 (99.9766)  time: 0.0343  data: 0.0003  max mem: 2151\n",
      "Epoch: [71]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4298.165130857358  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9688)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [71] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4524  data: 0.4281  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4653080958354323\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:19:51 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [72]  [  0/468]  eta: 0:04:51  lr: 0.01  img/s: 2513.640654921038  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6232  data: 0.5722  max mem: 2151\n",
      "Epoch: [72]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3757.7844878875053  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0342  data: 0.0002  max mem: 2151\n",
      "Epoch: [72]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4171.6208118356435  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9767)  time: 0.0333  data: 0.0003  max mem: 2151\n",
      "Epoch: [72]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3724.674876334649  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9714)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [72]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3830.2506456629994  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0334  data: 0.0002  max mem: 2151\n",
      "Epoch: [72] Total time: 0:00:16\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4201  data: 0.3984  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4653350673144376\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:20:08 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [73]  [  0/468]  eta: 0:03:10  lr: 0.01  img/s: 2903.4331049326966  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4080  data: 0.3639  max mem: 2151\n",
      "Epoch: [73]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3765.850269705323  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9691)  time: 0.0338  data: 0.0002  max mem: 2151\n",
      "Epoch: [73]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3798.086436085545  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9728)  time: 0.0334  data: 0.0003  max mem: 2151\n",
      "Epoch: [73]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4354.961242070767  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9689)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [73]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4374.085759212639  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9708)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [73] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4053  data: 0.3854  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.52, Acc@5 = 99.86, loss = 1.465455850468406\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:20:24 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [74]  [  0/468]  eta: 0:03:13  lr: 0.01  img/s: 3419.1243917972233  loss: 1.4707 (1.4707)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.4144  data: 0.3770  max mem: 2151\n",
      "Epoch: [74]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4404.5886995545125  loss: 1.4612 (1.4619)  acc1: 100.0000 (99.9304)  acc5: 100.0000 (99.9613)  time: 0.0318  data: 0.0002  max mem: 2151\n",
      "Epoch: [74]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 3764.9523622516604  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9728)  time: 0.0298  data: 0.0002  max mem: 2151\n",
      "Epoch: [74]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4306.819663714542  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9740)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [74]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4294.0741285812555  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0311  data: 0.0003  max mem: 2151\n",
      "Epoch: [74] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4624 (1.4624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5789  data: 0.5497  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.88, loss = 1.4652084564860863\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:20:41 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [75]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 2679.2505876305636  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6085  data: 0.5607  max mem: 2151\n",
      "Epoch: [75]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3324.6898191726527  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9613)  time: 0.0345  data: 0.0002  max mem: 2151\n",
      "Epoch: [75]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4361.967110822229  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9689)  time: 0.0300  data: 0.0001  max mem: 2151\n",
      "Epoch: [75]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4376.974286226744  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [75]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4370.453773577226  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [75] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3787  data: 0.3570  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.88, loss = 1.4652791898461837\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:20:57 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [76]  [  0/468]  eta: 0:03:25  lr: 0.01  img/s: 2730.5694479058056  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4388  data: 0.3918  max mem: 2151\n",
      "Epoch: [76]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3780.4882157016004  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9536)  acc5: 100.0000 (99.9768)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [76]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3802.201926345609  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9806)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [76]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3786.3806474363496  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9740)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [76]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 5108.677438386145  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0287  data: 0.0002  max mem: 2151\n",
      "Epoch: [76] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4644 (1.4644)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3648  data: 0.3422  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.86, loss = 1.465158912199962\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:21:13 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [77]  [  0/468]  eta: 0:03:14  lr: 0.01  img/s: 2853.025423008248  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4148  data: 0.3699  max mem: 2151\n",
      "Epoch: [77]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 5339.502043820303  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [77]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4028.082651820951  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9806)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [77]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3805.3281165830285  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9689)  time: 0.0336  data: 0.0002  max mem: 2151\n",
      "Epoch: [77]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4383.478493745713  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9688)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [77] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4650 (1.4650)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3497  data: 0.3288  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.89, loss = 1.465117585809925\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:21:30 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [78]  [  0/468]  eta: 0:03:15  lr: 0.01  img/s: 2848.076221598595  loss: 1.4614 (1.4614)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4173  data: 0.3723  max mem: 2151\n",
      "Epoch: [78]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3692.829318622663  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9691)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [78]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3781.1804908969257  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9806)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [78]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4317.313711772133  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [78]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4714.3150481643115  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9688)  acc5: 100.0000 (99.9747)  time: 0.0299  data: 0.0002  max mem: 2151\n",
      "Epoch: [78] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3635  data: 0.3412  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.54, Acc@5 = 99.88, loss = 1.46542081048217\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:21:47 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [79]  [  0/468]  eta: 0:03:12  lr: 0.01  img/s: 2840.6469554911214  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4120  data: 0.3669  max mem: 2151\n",
      "Epoch: [79]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3784.8057582358706  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [79]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4401.122367504201  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9728)  time: 0.0318  data: 0.0002  max mem: 2151\n",
      "Epoch: [79]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4714.894675366875  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9740)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [79]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3785.499615718184  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9610)  acc5: 100.0000 (99.9727)  time: 0.0332  data: 0.0002  max mem: 2151\n",
      "Epoch: [79] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3867  data: 0.3655  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.46526756015005\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:22:03 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [80]  [  0/468]  eta: 0:03:37  lr: 0.01  img/s: 3487.624155493192  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4657  data: 0.4290  max mem: 2151\n",
      "Epoch: [80]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3342.470237391126  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0336  data: 0.0002  max mem: 2151\n",
      "Epoch: [80]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4250.389213924362  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9806)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [80]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4363.562498476043  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9792)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [80]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4398.5622337287805  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9747)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [80] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:26  loss: 1.4624 (1.4624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3404  data: 0.3196  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4652554430539095\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:22:19 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.9599358974359 train_acc5 99.9599358974359\n",
      "Epoch: [81]  [  0/468]  eta: 0:03:34  lr: 0.01  img/s: 2731.2084408019577  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4583  data: 0.4114  max mem: 2151\n",
      "Epoch: [81]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3772.6512726097285  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9459)  time: 0.0319  data: 0.0002  max mem: 2151\n",
      "Epoch: [81]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4399.8960161942  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9650)  time: 0.0294  data: 0.0001  max mem: 2151\n",
      "Epoch: [81]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3787.1285111666034  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9740)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [81]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4043.3724864058804  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [81] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:24  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3148  data: 0.2939  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4654095519947101\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:22:36 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n",
      "Epoch: [82]  [  0/468]  eta: 0:03:07  lr: 0.01  img/s: 2881.290785166103  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4002  data: 0.3557  max mem: 2151\n",
      "Epoch: [82]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3776.047714836332  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9691)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [82]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3790.0158978920467  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9728)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [82]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4220.185607043195  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9766)  time: 0.0337  data: 0.0003  max mem: 2151\n",
      "Epoch: [82]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3798.865811893238  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9708)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [82] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4652 (1.4652)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3870  data: 0.3670  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.86, loss = 1.4652237213110622\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:22:52 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [83]  [  0/468]  eta: 0:03:09  lr: 0.01  img/s: 2786.695969479121  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4047  data: 0.3587  max mem: 2151\n",
      "Epoch: [83]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3772.041621876076  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9768)  acc5: 100.0000 (99.9768)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [83]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 5155.627053863809  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9728)  time: 0.0288  data: 0.0002  max mem: 2151\n",
      "Epoch: [83]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4330.093010501186  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9689)  time: 0.0290  data: 0.0002  max mem: 2151\n",
      "Epoch: [83]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3795.481880523153  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9708)  time: 0.0284  data: 0.0002  max mem: 2151\n",
      "Epoch: [83] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4071  data: 0.3872  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.85, loss = 1.465292145934286\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:23:08 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [84]  [  0/468]  eta: 0:03:16  lr: 0.01  img/s: 2666.3301680638883  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4208  data: 0.3728  max mem: 2151\n",
      "Epoch: [84]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3791.809361028908  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9613)  time: 0.0301  data: 0.0002  max mem: 2151\n",
      "Epoch: [84]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3775.3838667257373  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9689)  time: 0.0333  data: 0.0002  max mem: 2151\n",
      "Epoch: [84]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4043.8902388502647  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9689)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [84]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3794.6234291287938  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9708)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [84] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:39  loss: 1.4654 (1.4654)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5058  data: 0.4803  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.87, loss = 1.4651818245272092\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:23:25 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [85]  [  0/468]  eta: 0:04:13  lr: 0.01  img/s: 2579.6590956048763  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5427  data: 0.4930  max mem: 2151\n",
      "Epoch: [85]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3700.3378111064394  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9768)  time: 0.0340  data: 0.0003  max mem: 2151\n",
      "Epoch: [85]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3774.799873439972  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9650)  time: 0.0335  data: 0.0002  max mem: 2151\n",
      "Epoch: [85]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3781.846379261764  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9689)  time: 0.0343  data: 0.0004  max mem: 2151\n",
      "Epoch: [85]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3820.9277194181113  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9708)  time: 0.0334  data: 0.0002  max mem: 2151\n",
      "Epoch: [85] Total time: 0:00:16\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3606  data: 0.3340  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651851352257064\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:23:42 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [86]  [  0/468]  eta: 0:04:32  lr: 0.01  img/s: 2636.152511330325  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5820  data: 0.5334  max mem: 2151\n",
      "Epoch: [86]  [100/468]  eta: 0:00:14  lr: 0.01  img/s: 3817.151535404239  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9691)  time: 0.0340  data: 0.0002  max mem: 2151\n",
      "Epoch: [86]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4367.218559854228  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (99.9650)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [86]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4406.649418871889  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9689)  time: 0.0293  data: 0.0002  max mem: 2151\n",
      "Epoch: [86]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3767.3829830532263  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9766)  time: 0.0320  data: 0.0002  max mem: 2151\n",
      "Epoch: [86] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4446  data: 0.4217  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.54, Acc@5 = 99.87, loss = 1.4652562382854992\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:23:59 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [87]  [  0/468]  eta: 0:03:18  lr: 0.01  img/s: 2728.765213855498  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4242  data: 0.3772  max mem: 2151\n",
      "Epoch: [87]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3756.5224011139335  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [87]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4320.266778253452  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9728)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [87]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4728.765310526454  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9663)  time: 0.0296  data: 0.0001  max mem: 2151\n",
      "Epoch: [87]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4349.175418415126  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9708)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [87] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3900  data: 0.3707  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4653926091858103\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:24:15 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [88]  [  0/468]  eta: 0:03:17  lr: 0.01  img/s: 2836.1750081883206  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4218  data: 0.3766  max mem: 2151\n",
      "Epoch: [88]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4311.246563021971  loss: 1.4612 (1.4619)  acc1: 100.0000 (99.9304)  acc5: 100.0000 (99.9536)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [88]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4353.86640066824  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9534)  acc5: 100.0000 (99.9650)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [88]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3774.2160607956584  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9714)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [88]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4062.3106409703464  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9747)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [88] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3718  data: 0.3532  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.89, loss = 1.4650469007371347\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:24:31 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [89]  [  0/468]  eta: 0:03:12  lr: 0.01  img/s: 2760.5740083711266  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4106  data: 0.3642  max mem: 2151\n",
      "Epoch: [89]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4037.0787081249764  loss: 1.4612 (1.4613)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (99.9923)  time: 0.0321  data: 0.0002  max mem: 2151\n",
      "Epoch: [89]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4370.311465668118  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9767)  time: 0.0315  data: 0.0002  max mem: 2151\n",
      "Epoch: [89]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 5130.794193258599  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9714)  time: 0.0292  data: 0.0002  max mem: 2151\n",
      "Epoch: [89]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3771.9091151797884  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0331  data: 0.0001  max mem: 2151\n",
      "Epoch: [89] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4060  data: 0.3851  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.87, loss = 1.4652586662316625\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:24:48 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [90]  [  0/468]  eta: 0:04:00  lr: 0.01  img/s: 2685.925826608566  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5128  data: 0.4651  max mem: 2151\n",
      "Epoch: [90]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4417.599868345264  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [90]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4348.964033439181  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9767)  acc5: 100.0000 (99.9845)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [90]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4713.073469638577  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9740)  acc5: 100.0000 (99.9818)  time: 0.0303  data: 0.0002  max mem: 2151\n",
      "Epoch: [90]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3934.878678383747  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9786)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [90] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:26  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3402  data: 0.3240  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4652039054073864\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:25:04 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [91]  [  0/468]  eta: 0:03:17  lr: 0.01  img/s: 3133.8780237227984  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4212  data: 0.3803  max mem: 2151\n",
      "Epoch: [91]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4677.5130209014005  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [91]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3783.3121595433563  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (99.9806)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [91]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4017.5025031242285  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9637)  acc5: 100.0000 (99.9766)  time: 0.0325  data: 0.0002  max mem: 2151\n",
      "Epoch: [91]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4305.88702549666  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9688)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [91] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4203  data: 0.3999  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.54, Acc@5 = 99.88, loss = 1.4652966260910034\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:25:21 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [92]  [  0/468]  eta: 0:03:36  lr: 0.01  img/s: 2902.381454891445  loss: 1.4614 (1.4614)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4633  data: 0.4191  max mem: 2151\n",
      "Epoch: [92]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3766.9071798937716  loss: 1.4612 (1.4613)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (99.9923)  time: 0.0326  data: 0.0002  max mem: 2151\n",
      "Epoch: [92]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4638.31383966755  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9728)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [92]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4369.066666666667  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9714)  acc5: 100.0000 (99.9792)  time: 0.0294  data: 0.0002  max mem: 2151\n",
      "Epoch: [92]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3782.725711105005  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9786)  time: 0.0324  data: 0.0003  max mem: 2151\n",
      "Epoch: [92] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3984  data: 0.3765  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.465328958970082\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:25:37 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [93]  [  0/468]  eta: 0:03:10  lr: 0.01  img/s: 2593.792301783238  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4079  data: 0.3585  max mem: 2151\n",
      "Epoch: [93]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4369.031111400461  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0313  data: 0.0002  max mem: 2151\n",
      "Epoch: [93]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 3783.125542589774  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9806)  acc5: 100.0000 (99.9883)  time: 0.0307  data: 0.0002  max mem: 2151\n",
      "Epoch: [93]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3871.9909992427247  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9766)  acc5: 100.0000 (99.9844)  time: 0.0324  data: 0.0002  max mem: 2151\n",
      "Epoch: [93]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4381.761222291143  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9708)  acc5: 100.0000 (99.9805)  time: 0.0298  data: 0.0001  max mem: 2151\n",
      "Epoch: [93] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3820  data: 0.3560  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.58, Acc@5 = 99.88, loss = 1.4651932731459412\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:25:53 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [94]  [  0/468]  eta: 0:03:24  lr: 0.01  img/s: 2297.4029766438725  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4368  data: 0.3811  max mem: 2151\n",
      "Epoch: [94]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4375.012525160333  loss: 1.4612 (1.4617)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (99.9536)  time: 0.0320  data: 0.0002  max mem: 2151\n",
      "Epoch: [94]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4397.625464851493  loss: 1.4612 (1.4618)  acc1: 100.0000 (99.9417)  acc5: 100.0000 (99.9572)  time: 0.0295  data: 0.0002  max mem: 2151\n",
      "Epoch: [94]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 5057.234073418174  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9689)  time: 0.0310  data: 0.0002  max mem: 2151\n",
      "Epoch: [94]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4272.374977120984  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9649)  acc5: 100.0000 (99.9727)  time: 0.0320  data: 0.0002  max mem: 2151\n",
      "Epoch: [94] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:25  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3249  data: 0.3125  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.54, Acc@5 = 99.87, loss = 1.4652067362507688\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:26:09 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [95]  [  0/468]  eta: 0:03:14  lr: 0.01  img/s: 2700.109700100084  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4162  data: 0.3688  max mem: 2151\n",
      "Epoch: [95]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3806.4342930879234  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9613)  acc5: 100.0000 (99.9845)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [95]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3805.5978564441357  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9728)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [95]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 3785.5263076250512  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9689)  time: 0.0326  data: 0.0001  max mem: 2151\n",
      "Epoch: [95]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3787.8499453204927  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9727)  time: 0.0331  data: 0.0001  max mem: 2151\n",
      "Epoch: [95] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4652 (1.4652)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3584  data: 0.3385  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.55, Acc@5 = 99.86, loss = 1.4652975903281682\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:26:26 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96661324786325 train_acc5 99.96661324786325\n",
      "Epoch: [96]  [  0/468]  eta: 0:03:02  lr: 0.01  img/s: 3008.961305653948  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3893  data: 0.3468  max mem: 2151\n",
      "Epoch: [96]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4369.671194745367  loss: 1.4612 (1.4614)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (99.9923)  time: 0.0328  data: 0.0002  max mem: 2151\n",
      "Epoch: [96]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4403.649362260591  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9845)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [96]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4356.975775233118  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9559)  acc5: 100.0000 (99.9689)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [96]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4386.988772491788  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9591)  acc5: 100.0000 (99.9708)  time: 0.0297  data: 0.0002  max mem: 2151\n",
      "Epoch: [96] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:24  loss: 1.4650 (1.4650)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3154  data: 0.2931  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.58, Acc@5 = 99.87, loss = 1.4653305630140667\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:26:41 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [97]  [  0/468]  eta: 0:02:49  lr: 0.01  img/s: 2631.9136799274456  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3612  data: 0.3125  max mem: 2151\n",
      "Epoch: [97]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 4192.960942198202  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9768)  time: 0.0322  data: 0.0002  max mem: 2151\n",
      "Epoch: [97]  [200/468]  eta: 0:00:08  lr: 0.01  img/s: 4289.065541814463  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9728)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [97]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4365.407511607295  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9766)  time: 0.0297  data: 0.0001  max mem: 2151\n",
      "Epoch: [97]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4598.781175583766  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9669)  acc5: 100.0000 (99.9747)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [97] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3500  data: 0.3217  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.86, loss = 1.4652125563802598\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:26:57 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96494391025641 train_acc5 99.96494391025641\n",
      "Epoch: [98]  [  0/468]  eta: 0:03:14  lr: 0.01  img/s: 2921.4761736329156  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4148  data: 0.3709  max mem: 2151\n",
      "Epoch: [98]  [100/468]  eta: 0:00:12  lr: 0.01  img/s: 4367.111986008867  loss: 1.4612 (1.4619)  acc1: 100.0000 (99.9304)  acc5: 100.0000 (99.9536)  time: 0.0331  data: 0.0002  max mem: 2151\n",
      "Epoch: [98]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 3784.6189939093165  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9611)  acc5: 100.0000 (99.9728)  time: 0.0329  data: 0.0002  max mem: 2151\n",
      "Epoch: [98]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4297.683431928979  loss: 1.4612 (1.4615)  acc1: 100.0000 (99.9689)  acc5: 100.0000 (99.9792)  time: 0.0296  data: 0.0002  max mem: 2151\n",
      "Epoch: [98]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 4392.588175614865  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9630)  acc5: 100.0000 (99.9727)  time: 0.0303  data: 0.0002  max mem: 2151\n",
      "Epoch: [98] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3678  data: 0.3454  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.54, Acc@5 = 99.87, loss = 1.4652084700668915\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:27:13 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [99]  [  0/468]  eta: 0:03:19  lr: 0.01  img/s: 2472.7832270901654  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4272  data: 0.3753  max mem: 2151\n",
      "Epoch: [99]  [100/468]  eta: 0:00:13  lr: 0.01  img/s: 3748.444140338628  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9691)  acc5: 100.0000 (99.9845)  time: 0.0324  data: 0.0001  max mem: 2151\n",
      "Epoch: [99]  [200/468]  eta: 0:00:09  lr: 0.01  img/s: 4308.305810790206  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9650)  acc5: 100.0000 (99.9767)  time: 0.0292  data: 0.0001  max mem: 2151\n",
      "Epoch: [99]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4390.0738560167465  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9585)  acc5: 100.0000 (99.9740)  time: 0.0310  data: 0.0002  max mem: 2151\n",
      "Epoch: [99]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 3968.7664444017328  loss: 1.4612 (1.4616)  acc1: 100.0000 (99.9571)  acc5: 100.0000 (99.9708)  time: 0.0327  data: 0.0002  max mem: 2151\n",
      "Epoch: [99] Total time: 0:00:15\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3890  data: 0.3700  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.465162918537478\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_4__8\n",
      "Training time 0:27:29 max_test_acc1 99.6 test_acc5_at_max_test_acc1 99.87 train_acc1 99.96160523504274 train_acc5 99.96160523504274\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    save_max = False\n",
    "\n",
    "    train_loss, train_acc1, train_acc5 = train_one_epoch(net, criterion,data_loader, device, epoch, args.print_freq,lr=args.lr)\n",
    "\n",
    "    if utils.is_main_process():\n",
    "        train_tb_writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc1', train_acc1, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc5', train_acc5, epoch)\n",
    "\n",
    "    test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "    if te_tb_writer is not None:\n",
    "        if utils.is_main_process():\n",
    "            te_tb_writer.add_scalar('test_loss', test_loss, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc1', test_acc1, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc5', test_acc5, epoch)\n",
    "\n",
    "\n",
    "    if max_test_acc1 < test_acc1:\n",
    "        max_test_acc1 = test_acc1\n",
    "        test_acc5_at_max_test_acc1 = test_acc5\n",
    "        save_max = True\n",
    "\n",
    "    if output_dir:\n",
    "\n",
    "        checkpoint = {\n",
    "            'model': net.state_dict(),\n",
    "            'pre-train_epoch': epoch,\n",
    "            'args': args,\n",
    "            'max_test_acc1': max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1': test_acc5_at_max_test_acc1,\n",
    "        }\n",
    "\n",
    "        utils.save_on_master(\n",
    "            checkpoint,\n",
    "            os.path.join(output_dir, 'checkpoint_latest.pth'))\n",
    "        save_flag = False\n",
    "\n",
    "        if epoch % 64 == 0 or epoch == args.epochs - 1:\n",
    "            save_flag = True\n",
    "\n",
    "\n",
    "        if save_flag:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir, f'checkpoint_{epoch}.pth'))\n",
    "\n",
    "        if save_max:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net,os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net.state_dict(),os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth'))\n",
    "    print(args)\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(output_dir)\n",
    "\n",
    "    print('Training time {}'.format(total_time_str), 'max_test_acc1', max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1', test_acc5_at_max_test_acc1,'train_acc1', train_acc1,\n",
    "            'train_acc5', train_acc1)\n",
    "\n",
    "    Train_logs= {\n",
    "        'Epoch:': epoch,\n",
    "        'max_test_acc1 ': max_test_acc1 ,\n",
    "        'test_acc5_at_max_test_acc1 ': test_acc5_at_max_test_acc1,\n",
    "        'train_acc1 ': train_acc1,\n",
    "        'train_acc5 ': train_acc1,\n",
    "        'args': args\n",
    "    }\n",
    "    with open(output_dir + '_logs/args.txt', 'a', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(str(Train_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [ 0/79]  eta: 0:01:30  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 1.1475  data: 0.3457  max mem: 2151\n",
      "Test: Total time: 0:00:02\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3780  data: 0.3613  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4184  data: 0.4012  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3900  data: 0.3707  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4409  data: 0.4211  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4071  data: 0.3901  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4193  data: 0.3990  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3806  data: 0.3623  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3824  data: 0.3639  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4677 (1.4677)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3840  data: 0.3640  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.3, Acc@5 = 99.53, loss = 1.4673201690746258\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6303  data: 0.4941  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5949  data: 0.5697  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5711  data: 0.5540  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5955  data: 0.5697  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5982  data: 0.5783  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5541  data: 0.5344  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5985  data: 0.5718  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5901  data: 0.5709  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5699  data: 0.5464  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6296  data: 0.6090  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.76, loss = 1.4660183387466623\n",
      "Test:  [ 0/79]  eta: 0:00:54  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6836  data: 0.5310  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5870  data: 0.5630  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6097  data: 0.5887  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5897  data: 0.5682  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5957  data: 0.5705  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6180  data: 0.5971  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5737  data: 0.5519  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5587  data: 0.5392  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5723  data: 0.5499  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4657 (1.4657)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5702  data: 0.5495  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.52, Acc@5 = 99.78, loss = 1.465761501577836\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5347  data: 0.4005  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3865  data: 0.3677  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4185  data: 0.4022  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3828  data: 0.3600  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3911  data: 0.3730  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4242  data: 0.4002  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4588  data: 0.4374  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3969  data: 0.3752  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4077  data: 0.3957  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4645 (1.4645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3952  data: 0.3786  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.82, loss = 1.4653799835639665\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4754  data: 0.3527  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3909  data: 0.3728  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4004  data: 0.3810  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3806  data: 0.3622  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3639  data: 0.3532  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4086  data: 0.3895  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3991  data: 0.3809  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3829  data: 0.3645  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3872  data: 0.3676  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3779  data: 0.3582  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.56, Acc@5 = 99.84, loss = 1.4653886405727532\n",
      "Test:  [ 0/79]  eta: 0:00:39  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5058  data: 0.3841  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4329  data: 0.4134  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3825  data: 0.3588  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3969  data: 0.3786  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3890  data: 0.3711  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3955  data: 0.3793  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4059  data: 0.3876  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4020  data: 0.3823  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4132  data: 0.3950  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3619  data: 0.3481  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.57, Acc@5 = 99.85, loss = 1.4652744395823418\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5210  data: 0.3949  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4279  data: 0.4056  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3844  data: 0.3641  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4484  data: 0.4298  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:25  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3168  data: 0.2979  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4236  data: 0.4067  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4103  data: 0.3867  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4394  data: 0.4146  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4406  data: 0.4186  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4222  data: 0.3971  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.85, loss = 1.4652757312678084\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4277  data: 0.4054  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4323  data: 0.4084  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4351  data: 0.4147  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4143  data: 0.3905  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3863  data: 0.3671  max mem: 2151\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3877  data: 0.3618  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4179  data: 0.3971  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4038  data: 0.3798  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4227  data: 0.4011  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4444  data: 0.4217  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.6, Acc@5 = 99.87, loss = 1.4651458851898773\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5537  data: 0.4246  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4180  data: 0.3934  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3738  data: 0.3539  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3802  data: 0.3659  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3782  data: 0.3524  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3918  data: 0.3704  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3648  data: 0.3508  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4194  data: 0.3971  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3953  data: 0.3720  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4637 (1.4637)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4134  data: 0.3914  max mem: 2151\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.59, Acc@5 = 99.87, loss = 1.4651574228383317\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5109  data: 0.3766  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4198  data: 0.3970  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4617  data: 0.4397  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4389  data: 0.4154  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4041  data: 0.3892  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4406  data: 0.4157  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4857  data: 0.4635  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4646  data: 0.4386  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5701  data: 0.5362  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5793  data: 0.5527  max mem: 2317\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.56, Acc@5 = 99.87, loss = 1.4651070048537436\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for time in range(1,11):\n",
    "    acc = 0\n",
    "    for i in range(10):\n",
    "        net = NetworkA().to(device)\n",
    "        functional.reset_net(net)\n",
    "        functional.set_step_mode(net,step_mode='m')\n",
    "        functional.set_backend(net, backend='cupy')\n",
    "        weights = torch.load(model_dir)\n",
    "        net.load_state_dict(weights)\n",
    "        net.set_T(time)\n",
    "        # print(net.T)\n",
    "        test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "        acc += test_acc1\n",
    "    acc_list.append(acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt', 'a') as file:\n",
    "    line = ' '.join(map(str, acc_list))\n",
    "    file.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
