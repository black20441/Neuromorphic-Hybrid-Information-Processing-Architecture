{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import math\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributed.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import functional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "train_tb_writer = None\n",
    "te_tb_writer = None\n",
    "device = torch.device('cuda:0')\n",
    "deviceIds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "\n",
    "    parser.add_argument('--device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--data-path', default='./data/', help='dataset')\n",
    "    parser.add_argument('--epochs', default=320, type=int, metavar='N',\n",
    "                        help='number of total epochs to pre-train')\n",
    "    parser.add_argument('-j', '--workers', default=16, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', default=0.0025, type=float, help='initial learning rate')\n",
    "\n",
    "    parser.add_argument('--print-freq', default=10, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='./logs', help='path where to save')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--tb', action='store_true',\n",
    "                        help='Use TensorBoard to record logs')\n",
    "    parser.add_argument(\n",
    "        \"--cache-dataset\",\n",
    "        dest=\"cache_dataset\",\n",
    "        help=\"Cache the datasets for quicker initialization. It also serializes the transforms\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(args=['--data-path','../data','--lr','0.01','-b','128','--epochs','100','--print-freq','100','--tb','--cache-dataset'])\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkA, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, padding=3) \n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.sn1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1) \n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        self.sn2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv3 = nn.Conv2d(96, 128, kernel_size=3, padding=1) \n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.sn3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1) \n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.sn4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1) \n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.sn5 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, padding=1) \n",
    "        self.bn8 = nn.BatchNorm2d(512)\n",
    "        self.sn8 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, padding=1) \n",
    "        self.bn10 = nn.BatchNorm2d(512)\n",
    "        self.sn10 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.conv11 = nn.Conv2d(512, 256, kernel_size=3, padding=1) \n",
    "        self.sn11 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(256, 128, kernel_size=3, padding=1) \n",
    "        self.bn13 = nn.BatchNorm2d(128)\n",
    "        self.sn13 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(512, 256) \n",
    "        self.sn14 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.linear3 = nn.Linear(256, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.sn1(self.bn1(self.conv1(x)))\n",
    "        x = self.sn2(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.sn3(self.bn3(self.conv3(x)))\n",
    "        x = self.sn4(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.sn5(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.sn8(self.bn8(self.conv8(x)))\n",
    "        x = self.sn10(self.bn10(self.conv10(x)))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.sn11(self.conv11(x))\n",
    "       \n",
    "        x = self.sn13(self.bn13(self.conv13(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "      \n",
    "        x = self.sn14(self.linear1(x))\n",
    "       \n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "max_test_acc1 = 0.\n",
    "test_acc5_at_max_test_acc1 = 0.\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "print(args)\n",
    "output_dir = os.path.join(args.output_dir, f'b_{args.batch_size}_lr{args.lr}')\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "output_dir += f'_{time_now.year}_{time_now.month}_{time_now.day}_{time_now.hour}__{time_now.minute}'\n",
    "\n",
    "\n",
    "if output_dir:\n",
    "    utils.mkdir(output_dir)\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Creating model\")\n",
    "\n",
    "net = NetworkA().to(device)\n",
    "net.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-3)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4, last_epoch=-1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    args.start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc1 = checkpoint['max_test_acc1']\n",
    "    test_acc5_at_max_test_acc1 = checkpoint['test_acc5_at_max_test_acc1']\n",
    "\n",
    "if args.tb and utils.is_main_process():\n",
    "    purge_step_train = args.start_epoch\n",
    "    purge_step_te = args.start_epoch\n",
    "    train_tb_writer = SummaryWriter(output_dir + '_logs/train', purge_step=purge_step_train)\n",
    "    te_tb_writer = SummaryWriter(output_dir + '_logs/te', purge_step=purge_step_te)\n",
    "    with open(output_dir + '_logs/args.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "\n",
    "    with open(output_dir + '_logs/resluts.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('Results\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(net, criterion, data_loader, device, epoch, print_freq, scaler=None,lr = 1e-2):\n",
    "    net.train()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        loss_s = loss.item()\n",
    "        if math.isnan(loss_s):\n",
    "            raise ValueError('loss is Nan')\n",
    "        acc1_s = acc1.item()\n",
    "        acc5_s = acc5.item()\n",
    "\n",
    "        metric_logger.update(loss=loss_s, lr=lr)\n",
    "\n",
    "        metric_logger.meters['acc1'].update(acc1_s, n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5_s, n=batch_size)\n",
    "        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n",
    "        \n",
    "    scheduler.step()\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    return metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, data_loader, device, print_freq=100, header='Test:'):\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    with torch.no_grad():\n",
    "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = net(image)\n",
    "            loss = criterion(output, target)\n",
    "            functional.reset_net(net)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    loss, acc1, acc5 = metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg\n",
    "    print(f' * Acc@1 = {acc1}, Acc@5 = {acc5}, loss = {loss}')\n",
    "    return loss, acc1, acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0]  [  0/468]  eta: 0:25:11  lr: 0.01  img/s: 47.72197337718055  loss: 2.3552 (2.3552)  acc1: 7.0312 (7.0312)  acc5: 39.8438 (39.8438)  time: 3.2292  data: 0.5469  max mem: 1118\n",
      "Epoch: [0]  [100/468]  eta: 0:00:20  lr: 0.01  img/s: 4878.471517233233  loss: 0.0706 (0.3911)  acc1: 97.6562 (90.2228)  acc5: 100.0000 (98.0121)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [0]  [200/468]  eta: 0:00:10  lr: 0.01  img/s: 5512.134869299164  loss: 0.0565 (0.2335)  acc1: 98.4375 (93.9327)  acc5: 100.0000 (98.9700)  time: 0.0227  data: 0.0002  max mem: 1118\n",
      "Epoch: [0]  [300/468]  eta: 0:00:05  lr: 0.01  img/s: 4655.569052532996  loss: 0.0503 (0.1724)  acc1: 98.4375 (95.4734)  acc5: 100.0000 (99.3044)  time: 0.0233  data: 0.0002  max mem: 1118\n",
      "Epoch: [0]  [400/468]  eta: 0:00:02  lr: 0.01  img/s: 6800.655046615322  loss: 0.0366 (0.1397)  acc1: 99.2188 (96.3197)  acc5: 100.0000 (99.4759)  time: 0.0217  data: 0.0003  max mem: 1118\n",
      "Epoch: [0] Total time: 0:00:14\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0721 (0.0721)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  time: 0.5949  data: 0.5779  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 98.32, Acc@5 = 99.99, loss = 0.05642704702795872\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:00:16 max_test_acc1 98.32 test_acc5_at_max_test_acc1 99.99 train_acc1 96.69638087606837 train_acc5 96.69638087606837\n",
      "Epoch: [1]  [  0/468]  eta: 0:04:34  lr: 0.01  img/s: 3394.265107163179  loss: 0.0463 (0.0463)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5875  data: 0.5497  max mem: 1118\n",
      "Epoch: [1]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 4916.940616184928  loss: 0.0256 (0.0309)  acc1: 99.2188 (99.2342)  acc5: 100.0000 (99.9923)  time: 0.0235  data: 0.0003  max mem: 1118\n",
      "Epoch: [1]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 6119.512053892011  loss: 0.0315 (0.0312)  acc1: 99.2188 (99.1838)  acc5: 100.0000 (99.9922)  time: 0.0228  data: 0.0003  max mem: 1118\n",
      "Epoch: [1]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6490.454344330669  loss: 0.0200 (0.0318)  acc1: 99.2188 (99.1565)  acc5: 100.0000 (99.9948)  time: 0.0231  data: 0.0003  max mem: 1118\n",
      "Epoch: [1]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5254.528221741556  loss: 0.0176 (0.0319)  acc1: 100.0000 (99.1506)  acc5: 100.0000 (99.9922)  time: 0.0239  data: 0.0002  max mem: 1118\n",
      "Epoch: [1] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0309 (0.0309)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6141  data: 0.6004  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.15, Acc@5 = 100.0, loss = 0.03504460860232386\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:00:29 max_test_acc1 99.15 test_acc5_at_max_test_acc1 100.0 train_acc1 99.11858974358974 train_acc5 99.11858974358974\n",
      "Epoch: [2]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 5281.615283967378  loss: 0.0234 (0.0234)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6126  data: 0.5883  max mem: 1118\n",
      "Epoch: [2]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 5477.715661667176  loss: 0.0175 (0.0226)  acc1: 100.0000 (99.5204)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0002  max mem: 1118\n",
      "Epoch: [2]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5511.908502905484  loss: 0.0273 (0.0249)  acc1: 99.2188 (99.4209)  acc5: 100.0000 (99.9961)  time: 0.0232  data: 0.0002  max mem: 1118\n",
      "Epoch: [2]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5851.135218789167  loss: 0.0257 (0.0259)  acc1: 99.2188 (99.3875)  acc5: 100.0000 (99.9922)  time: 0.0177  data: 0.0004  max mem: 1118\n",
      "Epoch: [2]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5609.760529972938  loss: 0.0202 (0.0263)  acc1: 99.2188 (99.3882)  acc5: 100.0000 (99.9883)  time: 0.0238  data: 0.0002  max mem: 1118\n",
      "Epoch: [2] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0342 (0.0342)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5858  data: 0.5704  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 98.91, Acc@5 = 100.0, loss = 0.043823500882975666\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:00:41 max_test_acc1 99.15 test_acc5_at_max_test_acc1 100.0 train_acc1 99.35062767094017 train_acc5 99.35062767094017\n",
      "Epoch: [3]  [  0/468]  eta: 0:05:00  lr: 0.01  img/s: 3874.8135167515916  loss: 0.0319 (0.0319)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6427  data: 0.6096  max mem: 1118\n",
      "Epoch: [3]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5507.046118496635  loss: 0.0130 (0.0199)  acc1: 100.0000 (99.6132)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0003  max mem: 1118\n",
      "Epoch: [3]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5698.480167280524  loss: 0.0201 (0.0212)  acc1: 100.0000 (99.5763)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 1118\n",
      "Epoch: [3]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 4602.565985974658  loss: 0.0212 (0.0245)  acc1: 99.2188 (99.4887)  acc5: 100.0000 (99.9974)  time: 0.0239  data: 0.0002  max mem: 1118\n",
      "Epoch: [3]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5069.889814342645  loss: 0.0257 (0.0256)  acc1: 99.2188 (99.4467)  acc5: 100.0000 (99.9981)  time: 0.0238  data: 0.0002  max mem: 1118\n",
      "Epoch: [3] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0221 (0.0221)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5145  data: 0.5043  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.36, Acc@5 = 99.99, loss = 0.028984200073806924\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:00:54 max_test_acc1 99.36 test_acc5_at_max_test_acc1 99.99 train_acc1 99.43242521367522 train_acc5 99.43242521367522\n",
      "Epoch: [4]  [  0/468]  eta: 0:04:56  lr: 0.01  img/s: 4723.356870749496  loss: 0.0187 (0.0187)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6345  data: 0.6074  max mem: 1118\n",
      "Epoch: [4]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 4569.347473062454  loss: 0.0163 (0.0183)  acc1: 100.0000 (99.7061)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [4]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5475.760232546279  loss: 0.0207 (0.0206)  acc1: 99.2188 (99.6035)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [4]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5451.0195146715405  loss: 0.0167 (0.0225)  acc1: 100.0000 (99.5769)  acc5: 100.0000 (99.9974)  time: 0.0232  data: 0.0002  max mem: 1118\n",
      "Epoch: [4]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5571.165265757632  loss: 0.0175 (0.0235)  acc1: 100.0000 (99.5461)  acc5: 100.0000 (99.9981)  time: 0.0200  data: 0.0002  max mem: 1118\n",
      "Epoch: [4] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0321 (0.0321)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5805  data: 0.5655  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.31, Acc@5 = 100.0, loss = 0.031750163393495956\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:01:06 max_test_acc1 99.36 test_acc5_at_max_test_acc1 99.99 train_acc1 99.50420673076923 train_acc5 99.50420673076923\n",
      "Epoch: [5]  [  0/468]  eta: 0:04:21  lr: 0.01  img/s: 3525.85203622584  loss: 0.0302 (0.0302)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5589  data: 0.5225  max mem: 1118\n",
      "Epoch: [5]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5445.214382068056  loss: 0.0117 (0.0182)  acc1: 100.0000 (99.6751)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0003  max mem: 1118\n",
      "Epoch: [5]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5574.5204136728  loss: 0.0091 (0.0166)  acc1: 100.0000 (99.7279)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0002  max mem: 1118\n",
      "Epoch: [5]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5245.287505007181  loss: 0.0091 (0.0154)  acc1: 100.0000 (99.7612)  acc5: 100.0000 (100.0000)  time: 0.0245  data: 0.0002  max mem: 1118\n",
      "Epoch: [5]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5085.449578478734  loss: 0.0087 (0.0151)  acc1: 100.0000 (99.7643)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [5] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 0.0182 (0.0182)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5306  data: 0.5145  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.45, Acc@5 = 100.0, loss = 0.022691509951660527\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:01:19 max_test_acc1 99.45 test_acc5_at_max_test_acc1 100.0 train_acc1 99.78131677350427 train_acc5 99.78131677350427\n",
      "Epoch: [6]  [  0/468]  eta: 0:04:41  lr: 0.01  img/s: 3750.0412952977003  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6025  data: 0.5683  max mem: 1118\n",
      "Epoch: [6]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5848.394431251226  loss: 0.0089 (0.0111)  acc1: 100.0000 (99.8917)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0002  max mem: 1118\n",
      "Epoch: [6]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5236.487802974884  loss: 0.0088 (0.0114)  acc1: 100.0000 (99.8873)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0003  max mem: 1118\n",
      "Epoch: [6]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5323.7764467891  loss: 0.0090 (0.0116)  acc1: 100.0000 (99.8962)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0002  max mem: 1118\n",
      "Epoch: [6]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5556.289451896009  loss: 0.0097 (0.0118)  acc1: 100.0000 (99.8948)  acc5: 100.0000 (99.9981)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [6] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 0.0270 (0.0270)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3917  data: 0.3767  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.5, Acc@5 = 100.0, loss = 0.023737143666212317\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:01:32 max_test_acc1 99.5 test_acc5_at_max_test_acc1 100.0 train_acc1 99.87479967948718 train_acc5 99.87479967948718\n",
      "Epoch: [7]  [  0/468]  eta: 0:03:15  lr: 0.01  img/s: 3969.441349786693  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4175  data: 0.3852  max mem: 1118\n",
      "Epoch: [7]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5193.782524572402  loss: 0.0086 (0.0099)  acc1: 100.0000 (99.9459)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [7]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 4862.3445577553575  loss: 0.0085 (0.0105)  acc1: 100.0000 (99.9339)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0002  max mem: 1118\n",
      "Epoch: [7]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6657.955652562131  loss: 0.0103 (0.0109)  acc1: 100.0000 (99.9273)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0002  max mem: 1118\n",
      "Epoch: [7]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 4894.839689645426  loss: 0.0113 (0.0116)  acc1: 100.0000 (99.9084)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0002  max mem: 1118\n",
      "Epoch: [7] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 0.0177 (0.0177)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3943  data: 0.3787  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.49, Acc@5 = 99.99, loss = 0.023319692050307234\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:01:44 max_test_acc1 99.5 test_acc5_at_max_test_acc1 100.0 train_acc1 99.90484775641026 train_acc5 99.90484775641026\n",
      "Epoch: [8]  [  0/468]  eta: 0:04:32  lr: 0.01  img/s: 4197.353639753884  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5820  data: 0.5514  max mem: 1118\n",
      "Epoch: [8]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5163.113923563694  loss: 0.0089 (0.0109)  acc1: 100.0000 (99.9304)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0001  max mem: 1118\n",
      "Epoch: [8]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 4704.4831447874585  loss: 0.0086 (0.0103)  acc1: 100.0000 (99.9572)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0002  max mem: 1118\n",
      "Epoch: [8]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5518.253797923733  loss: 0.0088 (0.0107)  acc1: 100.0000 (99.9429)  acc5: 100.0000 (100.0000)  time: 0.0244  data: 0.0002  max mem: 1118\n",
      "Epoch: [8]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6520.56734074209  loss: 0.0091 (0.0106)  acc1: 100.0000 (99.9454)  acc5: 100.0000 (100.0000)  time: 0.0189  data: 0.0003  max mem: 1118\n",
      "Epoch: [8] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0105 (0.0105)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6136  data: 0.5995  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.55, Acc@5 = 99.99, loss = 0.023085398487510938\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:01:57 max_test_acc1 99.55 test_acc5_at_max_test_acc1 99.99 train_acc1 99.94491185897436 train_acc5 99.94491185897436\n",
      "Epoch: [9]  [  0/468]  eta: 0:05:34  lr: 0.01  img/s: 4623.932338274178  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7149  data: 0.6872  max mem: 1118\n",
      "Epoch: [9]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 6008.560754776107  loss: 0.0082 (0.0093)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [9]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5794.2379554481095  loss: 0.0082 (0.0093)  acc1: 100.0000 (99.9845)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0002  max mem: 1118\n",
      "Epoch: [9]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 4323.850618129102  loss: 0.0087 (0.0093)  acc1: 100.0000 (99.9844)  acc5: 100.0000 (100.0000)  time: 0.0248  data: 0.0002  max mem: 1118\n",
      "Epoch: [9]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5220.6514450192535  loss: 0.0097 (0.0098)  acc1: 100.0000 (99.9727)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [9] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0108 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5447  data: 0.5323  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.45, Acc@5 = 100.0, loss = 0.025894271581186148\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:02:10 max_test_acc1 99.55 test_acc5_at_max_test_acc1 99.99 train_acc1 99.96327457264957 train_acc5 99.96327457264957\n",
      "Epoch: [10]  [  0/468]  eta: 0:05:13  lr: 0.01  img/s: 4507.883656881843  loss: 0.0138 (0.0138)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6689  data: 0.6405  max mem: 1118\n",
      "Epoch: [10]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5613.749275892717  loss: 0.0082 (0.0101)  acc1: 100.0000 (99.9536)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0003  max mem: 1118\n",
      "Epoch: [10]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5547.046670455133  loss: 0.0082 (0.0095)  acc1: 100.0000 (99.9728)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [10]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5595.436194605411  loss: 0.0080 (0.0093)  acc1: 100.0000 (99.9792)  acc5: 100.0000 (100.0000)  time: 0.0226  data: 0.0002  max mem: 1118\n",
      "Epoch: [10]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5700.476874070928  loss: 0.0083 (0.0093)  acc1: 100.0000 (99.9805)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [10] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5657  data: 0.5522  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.61, Acc@5 = 99.99, loss = 0.01962108402571912\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:02:23 max_test_acc1 99.61 test_acc5_at_max_test_acc1 99.99 train_acc1 99.98163728632478 train_acc5 99.98163728632478\n",
      "Epoch: [11]  [  0/468]  eta: 0:05:02  lr: 0.01  img/s: 3441.1493253853796  loss: 0.0088 (0.0088)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6474  data: 0.6102  max mem: 1118\n",
      "Epoch: [11]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 4847.54911468068  loss: 0.0081 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0241  data: 0.0003  max mem: 1118\n",
      "Epoch: [11]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5514.682773001346  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9922)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [11]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5202.1367027770775  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9948)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [11]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5675.948195840866  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9942)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [11] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0099 (0.0099)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5914  data: 0.5817  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.01943850370501227\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:02:36 max_test_acc1 99.63 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99499198717949 train_acc5 99.99499198717949\n",
      "Epoch: [12]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 3717.479206193134  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6128  data: 0.5783  max mem: 1118\n",
      "Epoch: [12]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 5493.409516013507  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0003  max mem: 1118\n",
      "Epoch: [12]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5124.232010766338  loss: 0.0083 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [12]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5797.241188666206  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0215  data: 0.0003  max mem: 1118\n",
      "Epoch: [12]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6273.175574303008  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0002  max mem: 1118\n",
      "Epoch: [12] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0100 (0.0100)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5833  data: 0.5686  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 99.99, loss = 0.019403410822011625\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:02:49 max_test_acc1 99.65 test_acc5_at_max_test_acc1 99.99 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [13]  [  0/468]  eta: 0:04:51  lr: 0.01  img/s: 3018.485851310855  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6233  data: 0.5808  max mem: 1118\n",
      "Epoch: [13]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5918.86789041398  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0003  max mem: 1118\n",
      "Epoch: [13]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5509.985138963011  loss: 0.0083 (0.0088)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0003  max mem: 1118\n",
      "Epoch: [13]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5151.471564140207  loss: 0.0084 (0.0087)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [13]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5084.534487493963  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0243  data: 0.0002  max mem: 1118\n",
      "Epoch: [13] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0100 (0.0100)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5728  data: 0.5618  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.020096875579815498\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:03:01 max_test_acc1 99.65 test_acc5_at_max_test_acc1 99.99 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [14]  [  0/468]  eta: 0:05:19  lr: 0.01  img/s: 4017.0515982281813  loss: 0.0077 (0.0077)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6833  data: 0.6514  max mem: 1118\n",
      "Epoch: [14]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 5499.092605680689  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [14]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5557.784964492019  loss: 0.0083 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [14]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6177.0360586326715  loss: 0.0085 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [14]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5436.77757524203  loss: 0.0086 (0.0087)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [14] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0097 (0.0097)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6099  data: 0.6002  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019611015904081774\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:03:14 max_test_acc1 99.65 test_acc5_at_max_test_acc1 99.99 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [15]  [  0/468]  eta: 0:04:54  lr: 0.01  img/s: 3910.3456935795184  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6300  data: 0.5972  max mem: 1118\n",
      "Epoch: [15]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5727.967224308638  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0226  data: 0.0003  max mem: 1118\n",
      "Epoch: [15]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5537.263418457857  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [15]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5611.109030100334  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0240  data: 0.0002  max mem: 1118\n",
      "Epoch: [15]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5492.060805695931  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0244  data: 0.0003  max mem: 1118\n",
      "Epoch: [15] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0107 (0.0107)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5110  data: 0.4994  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.66, Acc@5 = 100.0, loss = 0.019500878562891406\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:03:27 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [16]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 2988.610001169011  loss: 0.0078 (0.0078)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6120  data: 0.5691  max mem: 1118\n",
      "Epoch: [16]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 6790.590961409544  loss: 0.0083 (0.0087)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0215  data: 0.0003  max mem: 1118\n",
      "Epoch: [16]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5553.9327781513475  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0229  data: 0.0002  max mem: 1118\n",
      "Epoch: [16]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5706.111492554764  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0210  data: 0.0002  max mem: 1118\n",
      "Epoch: [16]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5526.717987255639  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0003  max mem: 1118\n",
      "Epoch: [16] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:50  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6441  data: 0.6267  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.66, Acc@5 = 100.0, loss = 0.019564776268752315\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:03:39 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [17]  [  0/468]  eta: 0:04:33  lr: 0.01  img/s: 3066.8348709277548  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5840  data: 0.5422  max mem: 1118\n",
      "Epoch: [17]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5240.52585752494  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0003  max mem: 1118\n",
      "Epoch: [17]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5205.869521371499  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0240  data: 0.0003  max mem: 1118\n",
      "Epoch: [17]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6328.636740852508  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0227  data: 0.0003  max mem: 1118\n",
      "Epoch: [17]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5631.178342546073  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0003  max mem: 1118\n",
      "Epoch: [17] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:50  loss: 0.0103 (0.0103)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6349  data: 0.6155  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019870043431609113\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:03:52 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [18]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 3416.5351185892746  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6080  data: 0.5704  max mem: 1118\n",
      "Epoch: [18]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5140.275286277814  loss: 0.0082 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0002  max mem: 1118\n",
      "Epoch: [18]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5164.852395932542  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [18]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5941.795274196226  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0003  max mem: 1118\n",
      "Epoch: [18]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 4721.363034359033  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0243  data: 0.0003  max mem: 1118\n",
      "Epoch: [18] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0107 (0.0107)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5981  data: 0.5784  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.66, Acc@5 = 100.0, loss = 0.019574427988993216\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:04:05 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [19]  [  0/468]  eta: 0:04:56  lr: 0.01  img/s: 3376.5041446019545  loss: 0.0080 (0.0080)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6337  data: 0.5958  max mem: 1118\n",
      "Epoch: [19]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7044.070956229663  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0196  data: 0.0004  max mem: 1118\n",
      "Epoch: [19]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5630.883034066119  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [19]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6629.918520073601  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0002  max mem: 1118\n",
      "Epoch: [19]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5640.881660099816  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [19] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6021  data: 0.5894  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019832568101679222\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:04:17 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [20]  [  0/468]  eta: 0:04:41  lr: 0.01  img/s: 3542.579987858632  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6005  data: 0.5643  max mem: 1118\n",
      "Epoch: [20]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5503.20751158309  loss: 0.0083 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0002  max mem: 1118\n",
      "Epoch: [20]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5521.091238173591  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0003  max mem: 1118\n",
      "Epoch: [20]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5764.437773125033  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0003  max mem: 1118\n",
      "Epoch: [20]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5896.634836952343  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0002  max mem: 1118\n",
      "Epoch: [20] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0107 (0.0107)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5844  data: 0.5677  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.01986225103204952\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:04:30 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [21]  [  0/468]  eta: 0:04:52  lr: 0.01  img/s: 3653.2268539310553  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6247  data: 0.5896  max mem: 1118\n",
      "Epoch: [21]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5591.3569539044765  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [21]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5631.178342546073  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0229  data: 0.0003  max mem: 1118\n",
      "Epoch: [21]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5622.685839364075  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0003  max mem: 1118\n",
      "Epoch: [21]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6182.4421566595265  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [21] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5386  data: 0.5252  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019764773076093648\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:04:43 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [22]  [  0/468]  eta: 0:05:16  lr: 0.01  img/s: 4177.463599863052  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6769  data: 0.6462  max mem: 1118\n",
      "Epoch: [22]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 5512.4178534391585  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [22]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 6093.258486647221  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [22]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5534.523442332275  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0003  max mem: 1118\n",
      "Epoch: [22]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5548.250506386673  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0002  max mem: 1118\n",
      "Epoch: [22] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5984  data: 0.5853  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.0198202987519812\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:04:56 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [23]  [  0/468]  eta: 0:05:01  lr: 0.01  img/s: 4316.411226975615  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6434  data: 0.6136  max mem: 1118\n",
      "Epoch: [23]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7196.082245395813  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0210  data: 0.0002  max mem: 1118\n",
      "Epoch: [23]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6712.480614145859  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 1118\n",
      "Epoch: [23]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5511.738740311072  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [23]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5648.359393575945  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [23] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6013  data: 0.5843  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.01967825869074728\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:05:08 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [24]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 3636.6715573709416  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6123  data: 0.5770  max mem: 1118\n",
      "Epoch: [24]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5721.984439281223  loss: 0.0085 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0240  data: 0.0002  max mem: 1118\n",
      "Epoch: [24]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 6447.583220243314  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0003  max mem: 1118\n",
      "Epoch: [24]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5797.241188666206  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0192  data: 0.0003  max mem: 1118\n",
      "Epoch: [24]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5303.423970917999  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0003  max mem: 1118\n",
      "Epoch: [24] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5484  data: 0.5321  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019665248014174307\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:05:21 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [25]  [  0/468]  eta: 0:04:58  lr: 0.01  img/s: 3858.2448454534347  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6389  data: 0.6056  max mem: 1118\n",
      "Epoch: [25]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 5525.6372169617125  loss: 0.0085 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0003  max mem: 1118\n",
      "Epoch: [25]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 6054.9123349160345  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [25]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6755.1325179928535  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0002  max mem: 1118\n",
      "Epoch: [25]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5492.060805695931  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0002  max mem: 1118\n",
      "Epoch: [25] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0107 (0.0107)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6139  data: 0.6008  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.019995858621653876\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:05:34 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [26]  [  0/468]  eta: 0:05:11  lr: 0.01  img/s: 3693.7185631626385  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6664  data: 0.6317  max mem: 1118\n",
      "Epoch: [26]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 4813.129573348395  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [26]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5093.796901240074  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0003  max mem: 1118\n",
      "Epoch: [26]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5984.115564670738  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0241  data: 0.0003  max mem: 1118\n",
      "Epoch: [26]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6132.934029404037  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0003  max mem: 1118\n",
      "Epoch: [26] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5675  data: 0.5552  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019910625488603416\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:05:47 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [27]  [  0/468]  eta: 0:04:43  lr: 0.01  img/s: 4217.102711534232  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6065  data: 0.5760  max mem: 1118\n",
      "Epoch: [27]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7154.272434103568  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0002  max mem: 1118\n",
      "Epoch: [27]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6547.924918588626  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0211  data: 0.0002  max mem: 1118\n",
      "Epoch: [27]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5501.684842646772  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [27]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6271.197093763506  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0228  data: 0.0003  max mem: 1118\n",
      "Epoch: [27] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6185  data: 0.6086  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019874668827492604\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:05:59 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [28]  [  0/468]  eta: 0:04:51  lr: 0.01  img/s: 3289.8114613461444  loss: 0.0080 (0.0080)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6233  data: 0.5843  max mem: 1118\n",
      "Epoch: [28]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 4785.24428440277  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0242  data: 0.0004  max mem: 1118\n",
      "Epoch: [28]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 6614.072907811903  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0002  max mem: 1118\n",
      "Epoch: [28]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5571.801276529501  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0209  data: 0.0004  max mem: 1118\n",
      "Epoch: [28]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5151.768162669968  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0002  max mem: 1118\n",
      "Epoch: [28] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6087  data: 0.5996  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019692369471480953\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:06:12 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [29]  [  0/468]  eta: 0:04:31  lr: 0.01  img/s: 3560.1991538349316  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5808  data: 0.5448  max mem: 1118\n",
      "Epoch: [29]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 6137.070324645633  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0003  max mem: 1118\n",
      "Epoch: [29]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5709.9348251510255  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [29]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5567.005869055766  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [29]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6152.190591875322  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [29] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6159  data: 0.6064  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019709889570699086\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:06:24 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [30]  [  0/468]  eta: 0:04:35  lr: 0.01  img/s: 3653.027992869099  loss: 0.0090 (0.0090)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5894  data: 0.5543  max mem: 1118\n",
      "Epoch: [30]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5678.169349550502  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [30]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5496.44653753225  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0002  max mem: 1118\n",
      "Epoch: [30]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5542.637071297309  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0239  data: 0.0003  max mem: 1118\n",
      "Epoch: [30]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6191.497180288545  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0242  data: 0.0002  max mem: 1118\n",
      "Epoch: [30] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0115 (0.0115)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6169  data: 0.5963  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019638383554742685\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:06:37 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [31]  [  0/468]  eta: 0:04:50  lr: 0.01  img/s: 3334.8712132035507  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6209  data: 0.5824  max mem: 1118\n",
      "Epoch: [31]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7142.660209674845  loss: 0.0088 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0191  data: 0.0003  max mem: 1118\n",
      "Epoch: [31]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5155.775588207049  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [31]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5791.8001186687525  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0239  data: 0.0002  max mem: 1118\n",
      "Epoch: [31]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5662.896598280681  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0002  max mem: 1118\n",
      "Epoch: [31] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5910  data: 0.5761  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01975903832766263\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:06:50 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 100.0 train_acc5 100.0\n",
      "Epoch: [32]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 3647.5925671773616  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6081  data: 0.5730  max mem: 1118\n",
      "Epoch: [32]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5258.851707823565  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0003  max mem: 1118\n",
      "Epoch: [32]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 6595.95193748925  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0003  max mem: 1118\n",
      "Epoch: [32]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 6267.170713485245  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0003  max mem: 1118\n",
      "Epoch: [32]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5118.02810349101  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0239  data: 0.0002  max mem: 1118\n",
      "Epoch: [32] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0107 (0.0107)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5711  data: 0.5543  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.020168901945735458\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:07:03 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [33]  [  0/468]  eta: 0:04:57  lr: 0.01  img/s: 3185.3457376115434  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6351  data: 0.5949  max mem: 1118\n",
      "Epoch: [33]  [100/468]  eta: 0:00:11  lr: 0.01  img/s: 5320.610798382621  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0240  data: 0.0002  max mem: 1118\n",
      "Epoch: [33]  [200/468]  eta: 0:00:07  lr: 0.01  img/s: 5676.188236786737  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0002  max mem: 1118\n",
      "Epoch: [33]  [300/468]  eta: 0:00:04  lr: 0.01  img/s: 5122.178661043955  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0239  data: 0.0002  max mem: 1118\n",
      "Epoch: [33]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6011.72301352683  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0235  data: 0.0002  max mem: 1118\n",
      "Epoch: [33] Total time: 0:00:11\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5880  data: 0.5730  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019768766351515733\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:07:15 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [34]  [  0/468]  eta: 0:05:13  lr: 0.01  img/s: 4254.296224097627  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6708  data: 0.6407  max mem: 1118\n",
      "Epoch: [34]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6410.016261715718  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0002  max mem: 1118\n",
      "Epoch: [34]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 7023.704645655899  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0193  data: 0.0002  max mem: 1118\n",
      "Epoch: [34]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7045.827421027075  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0003  max mem: 1118\n",
      "Epoch: [34]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7771.727156919514  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0003  max mem: 1118\n",
      "Epoch: [34] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5664  data: 0.5484  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019711315808699854\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:07:27 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [35]  [  0/468]  eta: 0:04:56  lr: 0.01  img/s: 4215.248516064194  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6339  data: 0.6035  max mem: 1118\n",
      "Epoch: [35]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 5949.762971828801  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 1118\n",
      "Epoch: [35]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5860.268436449373  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0211  data: 0.0003  max mem: 1118\n",
      "Epoch: [35]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6479.956934738265  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0228  data: 0.0003  max mem: 1118\n",
      "Epoch: [35]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7080.6746326923585  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 1118\n",
      "Epoch: [35] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5591  data: 0.5450  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019891207460078258\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:07:38 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [36]  [  0/468]  eta: 0:04:52  lr: 0.01  img/s: 3586.6474620204963  loss: 0.0093 (0.0093)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6256  data: 0.5898  max mem: 1118\n",
      "Epoch: [36]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 5294.89823855455  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0241  data: 0.0003  max mem: 1118\n",
      "Epoch: [36]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6241.015914348488  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 1118\n",
      "Epoch: [36]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5541.206890501306  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0168  data: 0.0003  max mem: 1118\n",
      "Epoch: [36]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7239.652521002738  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0189  data: 0.0003  max mem: 1118\n",
      "Epoch: [36] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0115 (0.0115)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6053  data: 0.5973  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019562225464637144\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:07:50 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [37]  [  0/468]  eta: 0:05:10  lr: 0.01  img/s: 4338.841662895196  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6630  data: 0.6334  max mem: 1118\n",
      "Epoch: [37]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7145.321976149915  loss: 0.0087 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0003  max mem: 1118\n",
      "Epoch: [37]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6414.764819041019  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0004  max mem: 1118\n",
      "Epoch: [37]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5383.3518369966305  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0215  data: 0.0003  max mem: 1118\n",
      "Epoch: [37]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5311.714424228033  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0223  data: 0.0002  max mem: 1118\n",
      "Epoch: [37] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6170  data: 0.6029  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019850911914453477\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:08:01 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [38]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 3537.9342721767152  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6083  data: 0.5721  max mem: 1118\n",
      "Epoch: [38]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 6263.295635638205  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0213  data: 0.0003  max mem: 1118\n",
      "Epoch: [38]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 4973.55979433971  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0238  data: 0.0003  max mem: 1118\n",
      "Epoch: [38]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5750.483735178501  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0004  max mem: 1118\n",
      "Epoch: [38]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7004.1867188519245  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0190  data: 0.0002  max mem: 1118\n",
      "Epoch: [38] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6117  data: 0.6008  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019846856240418893\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:08:13 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [39]  [  0/468]  eta: 0:05:18  lr: 0.01  img/s: 4845.711479967146  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6808  data: 0.6543  max mem: 1118\n",
      "Epoch: [39]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5097.230617321459  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0244  data: 0.0003  max mem: 1118\n",
      "Epoch: [39]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 7016.728033144695  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0212  data: 0.0003  max mem: 1118\n",
      "Epoch: [39]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6291.406848383997  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 1118\n",
      "Epoch: [39]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7141.710059329023  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0195  data: 0.0003  max mem: 1118\n",
      "Epoch: [39] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6295  data: 0.6184  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.0199723925170359\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:08:24 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [40]  [  0/468]  eta: 0:05:11  lr: 0.01  img/s: 4373.230631379161  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6658  data: 0.6365  max mem: 1118\n",
      "Epoch: [40]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6395.66029329426  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0003  max mem: 1118\n",
      "Epoch: [40]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6148.52677027383  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0209  data: 0.0004  max mem: 1118\n",
      "Epoch: [40]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7124.272300220282  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 1118\n",
      "Epoch: [40]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5246.979202501954  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0220  data: 0.0003  max mem: 1118\n",
      "Epoch: [40] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 0.0108 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6236  data: 0.6098  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019786735342320384\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:08:36 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [41]  [  0/468]  eta: 0:04:51  lr: 0.01  img/s: 4277.958134457397  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6226  data: 0.5926  max mem: 1118\n",
      "Epoch: [41]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5846.483774012284  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0220  data: 0.0003  max mem: 1118\n",
      "Epoch: [41]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 4921.493046834178  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0227  data: 0.0002  max mem: 1118\n",
      "Epoch: [41]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6339.397695068959  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0243  data: 0.0003  max mem: 1118\n",
      "Epoch: [41]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7771.389661711275  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0213  data: 0.0003  max mem: 1118\n",
      "Epoch: [41] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:50  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6434  data: 0.6259  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.01983242025127328\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:08:48 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [42]  [  0/468]  eta: 0:05:10  lr: 0.01  img/s: 3717.891109541419  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6625  data: 0.6280  max mem: 1118\n",
      "Epoch: [42]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 4846.41136698051  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0228  data: 0.0004  max mem: 1118\n",
      "Epoch: [42]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 7211.93562773703  loss: 0.0083 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0236  data: 0.0003  max mem: 1118\n",
      "Epoch: [42]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6289.637901544085  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0003  max mem: 1118\n",
      "Epoch: [42]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6549.442638949885  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0003  max mem: 1118\n",
      "Epoch: [42] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6220  data: 0.6080  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019728202832556222\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:09:00 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [43]  [  0/468]  eta: 0:05:23  lr: 0.01  img/s: 4143.321721010998  loss: 0.0097 (0.0097)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6919  data: 0.6610  max mem: 1118\n",
      "Epoch: [43]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 6377.5782183628135  loss: 0.0084 (0.0087)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0004  max mem: 1118\n",
      "Epoch: [43]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5844.701619926842  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 1118\n",
      "Epoch: [43]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 4804.17098728423  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0222  data: 0.0004  max mem: 1118\n",
      "Epoch: [43]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5767.100416791991  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0225  data: 0.0003  max mem: 1118\n",
      "Epoch: [43] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5936  data: 0.5820  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019727026018066498\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:09:12 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [44]  [  0/468]  eta: 0:04:52  lr: 0.01  img/s: 4056.386847195358  loss: 0.0088 (0.0088)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6249  data: 0.5933  max mem: 1118\n",
      "Epoch: [44]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 4857.021866377166  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0004  max mem: 1118\n",
      "Epoch: [44]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5261.789556217657  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0003  max mem: 1118\n",
      "Epoch: [44]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 4816.411242789346  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0221  data: 0.0003  max mem: 1118\n",
      "Epoch: [44]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5957.223199920108  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0223  data: 0.0003  max mem: 1118\n",
      "Epoch: [44] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:50  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6454  data: 0.6290  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019864806852338813\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:09:23 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [45]  [  0/468]  eta: 0:05:02  lr: 0.01  img/s: 4166.667277200444  loss: 0.0080 (0.0080)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6473  data: 0.6165  max mem: 1118\n",
      "Epoch: [45]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5778.8328902188305  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0216  data: 0.0003  max mem: 1118\n",
      "Epoch: [45]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6792.910797884455  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0003  max mem: 1118\n",
      "Epoch: [45]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5619.801867437089  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0237  data: 0.0002  max mem: 1118\n",
      "Epoch: [45]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7175.595931514722  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0225  data: 0.0002  max mem: 1118\n",
      "Epoch: [45] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6203  data: 0.6042  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01972335074214807\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:09:35 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [46]  [  0/468]  eta: 0:04:45  lr: 0.01  img/s: 4108.978493471505  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6111  data: 0.5799  max mem: 1118\n",
      "Epoch: [46]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 4889.223018568944  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0240  data: 0.0003  max mem: 1118\n",
      "Epoch: [46]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 8891.682737375577  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0228  data: 0.0003  max mem: 1118\n",
      "Epoch: [46]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6644.44198019802  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0002  max mem: 1118\n",
      "Epoch: [46]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7235.554549252685  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [46] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5996  data: 0.5848  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019827129873388177\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:09:46 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [47]  [  0/468]  eta: 0:05:09  lr: 0.01  img/s: 4204.684314401178  loss: 0.0096 (0.0096)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6613  data: 0.6308  max mem: 1118\n",
      "Epoch: [47]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 5111.985222143931  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0222  data: 0.0003  max mem: 1118\n",
      "Epoch: [47]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 7195.792893618733  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0002  max mem: 1118\n",
      "Epoch: [47]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7001.446426708399  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0192  data: 0.0003  max mem: 1118\n",
      "Epoch: [47]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7147.129304950943  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0003  max mem: 1118\n",
      "Epoch: [47] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6184  data: 0.6051  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01969489041432927\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:09:58 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [48]  [  0/468]  eta: 0:05:08  lr: 0.01  img/s: 4215.11613592111  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6585  data: 0.6281  max mem: 1118\n",
      "Epoch: [48]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7128.8130659938915  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0002  max mem: 1118\n",
      "Epoch: [48]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 7909.816896013201  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0215  data: 0.0004  max mem: 1118\n",
      "Epoch: [48]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6931.570268420849  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0215  data: 0.0002  max mem: 1118\n",
      "Epoch: [48]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7097.617852751814  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0002  max mem: 1118\n",
      "Epoch: [48] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3756  data: 0.3698  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019722407389007792\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:10:09 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [49]  [  0/468]  eta: 0:04:42  lr: 0.01  img/s: 4431.163538519949  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6027  data: 0.5737  max mem: 1118\n",
      "Epoch: [49]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6697.240771927199  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0003  max mem: 1118\n",
      "Epoch: [49]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 5679.370697133185  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0003  max mem: 1118\n",
      "Epoch: [49]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5205.011508071162  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0233  data: 0.0003  max mem: 1118\n",
      "Epoch: [49]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6259.936242901951  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0234  data: 0.0002  max mem: 1118\n",
      "Epoch: [49] Total time: 0:00:10\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6070  data: 0.5969  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01985553422754135\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:10:20 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [50]  [  0/468]  eta: 0:04:50  lr: 0.01  img/s: 3666.950658433965  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6201  data: 0.5852  max mem: 1118\n",
      "Epoch: [50]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 5314.764262733257  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0003  max mem: 1118\n",
      "Epoch: [50]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 6601.4670830976565  loss: 0.0087 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0003  max mem: 1118\n",
      "Epoch: [50]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6434.677853153391  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0189  data: 0.0003  max mem: 1118\n",
      "Epoch: [50]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 8797.845271455026  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [50] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6061  data: 0.5934  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019810650379786007\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:10:31 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [51]  [  0/468]  eta: 0:04:50  lr: 0.01  img/s: 4757.806735200284  loss: 0.0080 (0.0080)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6216  data: 0.5947  max mem: 1118\n",
      "Epoch: [51]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 5783.252671492589  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0195  data: 0.0003  max mem: 1118\n",
      "Epoch: [51]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 6876.612767701608  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0194  data: 0.0003  max mem: 1118\n",
      "Epoch: [51]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7468.157578455375  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0004  max mem: 1118\n",
      "Epoch: [51]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7275.560867856514  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [51] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5910  data: 0.5795  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019823613087351942\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:10:42 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [52]  [  0/468]  eta: 0:04:36  lr: 0.01  img/s: 3907.2152541756122  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5898  data: 0.5570  max mem: 1118\n",
      "Epoch: [52]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6653.747344677581  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0003  max mem: 1118\n",
      "Epoch: [52]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7225.329888027562  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [52]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7053.60335290949  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [52]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7153.700458373308  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [52] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5956  data: 0.5797  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019772016661406697\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:10:52 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [53]  [  0/468]  eta: 0:04:59  lr: 0.01  img/s: 4052.8347374460245  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6403  data: 0.6086  max mem: 1118\n",
      "Epoch: [53]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7229.805704435886  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0177  data: 0.0002  max mem: 1118\n",
      "Epoch: [53]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7200.521888412017  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0177  data: 0.0002  max mem: 1118\n",
      "Epoch: [53]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7230.9742208334455  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0176  data: 0.0002  max mem: 1118\n",
      "Epoch: [53]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7378.451829251532  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [53] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4005  data: 0.3925  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.019722890922257416\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:11:02 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [54]  [  0/468]  eta: 0:03:04  lr: 0.01  img/s: 4136.171403477685  loss: 0.0090 (0.0090)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3944  data: 0.3633  max mem: 1118\n",
      "Epoch: [54]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 8126.527488496004  loss: 0.0086 (0.0087)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0190  data: 0.0003  max mem: 1118\n",
      "Epoch: [54]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7174.253497788409  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0002  max mem: 1118\n",
      "Epoch: [54]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7173.294924040993  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [54]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7347.5517600043795  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [54] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0108 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5070  data: 0.4943  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.01973241124938749\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:11:12 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [55]  [  0/468]  eta: 0:04:38  lr: 0.01  img/s: 4444.369211410785  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5953  data: 0.5664  max mem: 1118\n",
      "Epoch: [55]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 8878.595488522855  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0169  data: 0.0003  max mem: 1118\n",
      "Epoch: [55]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7272.604164126739  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [55]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7708.125082555635  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0178  data: 0.0002  max mem: 1118\n",
      "Epoch: [55]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7392.065209010299  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0003  max mem: 1118\n",
      "Epoch: [55] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0116 (0.0116)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5457  data: 0.5332  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019660325939000786\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:11:23 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [56]  [  0/468]  eta: 0:03:03  lr: 0.01  img/s: 3342.158121467168  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3926  data: 0.3543  max mem: 1118\n",
      "Epoch: [56]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7174.253497788409  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [56]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7257.169861310119  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [56]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6967.824944841012  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0003  max mem: 1118\n",
      "Epoch: [56]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7145.987727774894  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [56] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5654  data: 0.5507  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01974103118210465\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:11:33 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [57]  [  0/468]  eta: 0:04:58  lr: 0.01  img/s: 4285.060236732674  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6378  data: 0.6079  max mem: 1118\n",
      "Epoch: [57]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6324.5362894200525  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0002  max mem: 1118\n",
      "Epoch: [57]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7243.755137286649  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0193  data: 0.0003  max mem: 1118\n",
      "Epoch: [57]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7178.378285867095  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [57]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 8229.67245079404  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [57] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5791  data: 0.5654  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01977145729020615\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:11:43 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [58]  [  0/468]  eta: 0:04:25  lr: 0.01  img/s: 3710.1061608099235  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5671  data: 0.5325  max mem: 1118\n",
      "Epoch: [58]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7163.6276686592655  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0003  max mem: 1118\n",
      "Epoch: [58]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7045.180200514409  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [58]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6350.946506731019  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0196  data: 0.0003  max mem: 1118\n",
      "Epoch: [58]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 5846.292776948961  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0003  max mem: 1118\n",
      "Epoch: [58] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5104  data: 0.4941  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019809049654374772\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:11:54 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [59]  [  0/468]  eta: 0:04:50  lr: 0.01  img/s: 3551.344225858944  loss: 0.0094 (0.0094)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6198  data: 0.5837  max mem: 1118\n",
      "Epoch: [59]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7863.1297801602295  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [59]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7185.199373653288  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [59]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7761.278417879808  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [59]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7174.157628885266  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [59] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5805  data: 0.5609  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01980692666330481\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:12:04 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [60]  [  0/468]  eta: 0:04:26  lr: 0.01  img/s: 3845.890369351557  loss: 0.0082 (0.0082)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5693  data: 0.5360  max mem: 1118\n",
      "Epoch: [60]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6348.393151073692  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [60]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7149.508762584563  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [60]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7644.2492311197175  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [60]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7033.089827733019  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [60] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5615  data: 0.5462  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019743816638247497\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:12:15 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [61]  [  0/468]  eta: 0:04:29  lr: 0.01  img/s: 3766.775033677593  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5762  data: 0.5422  max mem: 1118\n",
      "Epoch: [61]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 6354.479529395055  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0002  max mem: 1118\n",
      "Epoch: [61]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7269.5514271786815  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [61]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7166.592073471894  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [61]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7695.088177961243  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0003  max mem: 1118\n",
      "Epoch: [61] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5154  data: 0.5040  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019664782624031547\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:12:25 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [62]  [  0/468]  eta: 0:04:58  lr: 0.01  img/s: 4194.533388544686  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6379  data: 0.6073  max mem: 1118\n",
      "Epoch: [62]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7147.034159588913  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [62]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7170.133447299535  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [62]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7168.314466920355  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0196  data: 0.0003  max mem: 1118\n",
      "Epoch: [62]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7182.603911915019  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [62] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5125  data: 0.5059  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.01987323708407864\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:12:35 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [63]  [  0/468]  eta: 0:04:54  lr: 0.01  img/s: 3512.77145137862  loss: 0.0088 (0.0088)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6301  data: 0.5936  max mem: 1118\n",
      "Epoch: [63]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7734.554716763672  loss: 0.0082 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [63]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7227.664404954227  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0002  max mem: 1118\n",
      "Epoch: [63]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7186.161131858276  loss: 0.0086 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0003  max mem: 1118\n",
      "Epoch: [63]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7152.270919094627  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [63] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5789  data: 0.5633  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019647266191159245\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:12:46 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [64]  [  0/468]  eta: 0:04:37  lr: 0.01  img/s: 3871.069681587448  loss: 0.0101 (0.0101)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5936  data: 0.5605  max mem: 1118\n",
      "Epoch: [64]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7160.665715238413  loss: 0.0085 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0003  max mem: 1118\n",
      "Epoch: [64]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 6402.677511299806  loss: 0.0087 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 1118\n",
      "Epoch: [64]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7118.793253421025  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [64]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7168.218756675924  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0177  data: 0.0002  max mem: 1118\n",
      "Epoch: [64] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0105 (0.0105)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5552  data: 0.5419  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.020073711984095317\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:12:56 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [65]  [  0/468]  eta: 0:04:13  lr: 0.01  img/s: 3848.012901468617  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5420  data: 0.5087  max mem: 1118\n",
      "Epoch: [65]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7166.400747513849  loss: 0.0082 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [65]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7151.127698967699  loss: 0.0082 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [65]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7145.321976149915  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [65]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7198.397897616047  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0003  max mem: 1118\n",
      "Epoch: [65] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4425  data: 0.4266  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01970174044512118\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:13:06 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [66]  [  0/468]  eta: 0:03:20  lr: 0.01  img/s: 3931.363361428226  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4286  data: 0.3960  max mem: 1118\n",
      "Epoch: [66]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7215.1340832426185  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0003  max mem: 1118\n",
      "Epoch: [66]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7255.894798015975  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0003  max mem: 1118\n",
      "Epoch: [66]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7266.00952793417  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0003  max mem: 1118\n",
      "Epoch: [66]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7165.348637322158  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0003  max mem: 1118\n",
      "Epoch: [66] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0115 (0.0115)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5415  data: 0.5291  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019807547537161956\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:13:17 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [67]  [  0/468]  eta: 0:04:31  lr: 0.01  img/s: 4158.115401892901  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5809  data: 0.5500  max mem: 1118\n",
      "Epoch: [67]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 8000.46065121824  loss: 0.0086 (0.0087)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [67]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7431.973642681138  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0003  max mem: 1118\n",
      "Epoch: [67]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7131.275065086871  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [67]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7299.499816448898  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0002  max mem: 1118\n",
      "Epoch: [67] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0115 (0.0115)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5380  data: 0.5266  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019633521473247418\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:13:27 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [68]  [  0/468]  eta: 0:04:31  lr: 0.01  img/s: 4436.289742021848  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5802  data: 0.5513  max mem: 1118\n",
      "Epoch: [68]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7730.100097909348  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [68]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7134.971253903914  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0179  data: 0.0002  max mem: 1118\n",
      "Epoch: [68]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7203.130318114124  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0189  data: 0.0003  max mem: 1118\n",
      "Epoch: [68]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7155.416660002666  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [68] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5279  data: 0.5147  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019786307658953003\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:13:37 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [69]  [  0/468]  eta: 0:04:01  lr: 0.01  img/s: 3270.7113344908466  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5157  data: 0.4765  max mem: 1118\n",
      "Epoch: [69]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7129.381068734729  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [69]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 6477.220664527182  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0195  data: 0.0003  max mem: 1118\n",
      "Epoch: [69]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7169.5589327208145  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [69]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7157.515358361775  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [69] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5630  data: 0.5532  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019893436604238385\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:13:48 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [70]  [  0/468]  eta: 0:05:00  lr: 0.01  img/s: 3838.1094517404326  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6426  data: 0.6092  max mem: 1118\n",
      "Epoch: [70]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7165.826830928578  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0189  data: 0.0003  max mem: 1118\n",
      "Epoch: [70]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7147.414756237186  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [70]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7162.1941594738455  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [70]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7161.8119872470415  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [70] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5534  data: 0.5360  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019833935689935578\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:13:58 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [71]  [  0/468]  eta: 0:04:25  lr: 0.01  img/s: 3930.6437848681417  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5678  data: 0.5352  max mem: 1118\n",
      "Epoch: [71]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 9133.719729835486  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [71]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7161.047765135852  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0002  max mem: 1118\n",
      "Epoch: [71]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7063.440367334588  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [71]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7132.601461405607  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [71] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3933  data: 0.3808  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019795482889808053\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:14:08 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [72]  [  0/468]  eta: 0:04:01  lr: 0.01  img/s: 4479.33679863168  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5168  data: 0.4881  max mem: 1118\n",
      "Epoch: [72]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7209.4176290487185  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [72]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7076.66133263033  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0003  max mem: 1118\n",
      "Epoch: [72]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7074.143677858009  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [72]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7173.9658987653  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0003  max mem: 1118\n",
      "Epoch: [72] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0106 (0.0106)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5703  data: 0.5546  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.019906798725405447\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:14:18 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [73]  [  0/468]  eta: 0:04:21  lr: 0.01  img/s: 3955.607792284342  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5589  data: 0.5265  max mem: 1118\n",
      "Epoch: [73]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 9705.526646901439  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [73]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7153.12857409332  loss: 0.0086 (0.0085)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [73]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6949.965202982601  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 1118\n",
      "Epoch: [73]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7185.968759620404  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [73] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0116 (0.0116)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5457  data: 0.5359  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.01980177867167358\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:14:29 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [74]  [  0/468]  eta: 0:04:36  lr: 0.01  img/s: 4366.792295679334  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5908  data: 0.5614  max mem: 1118\n",
      "Epoch: [74]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 8731.028004553586  loss: 0.0084 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [74]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7176.459189947868  loss: 0.0083 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [74]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6385.5429849184075  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0191  data: 0.0004  max mem: 1118\n",
      "Epoch: [74]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7612.166969147005  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0179  data: 0.0002  max mem: 1118\n",
      "Epoch: [74] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3689  data: 0.3578  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.01979808527033163\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:14:39 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [75]  [  0/468]  eta: 0:03:20  lr: 0.01  img/s: 4604.934657677594  loss: 0.0092 (0.0092)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4288  data: 0.4009  max mem: 1118\n",
      "Epoch: [75]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7156.179680627016  loss: 0.0085 (0.0087)  acc1: 100.0000 (99.9923)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0003  max mem: 1118\n",
      "Epoch: [75]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 5691.834568450961  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0003  max mem: 1118\n",
      "Epoch: [75]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7170.7080539601975  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0192  data: 0.0002  max mem: 1118\n",
      "Epoch: [75]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6372.355038575668  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 1118\n",
      "Epoch: [75] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5591  data: 0.5464  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019863265030133196\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:14:49 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [76]  [  0/468]  eta: 0:05:02  lr: 0.01  img/s: 3982.958276455576  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6466  data: 0.6144  max mem: 1118\n",
      "Epoch: [76]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6339.472551867465  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [76]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7158.756077071805  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [76]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5771.812505375419  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0189  data: 0.0002  max mem: 1118\n",
      "Epoch: [76]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6378.411690626114  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [76] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5327  data: 0.5189  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.01975497602826998\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:15:00 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [77]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 3749.517487987485  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6112  data: 0.5770  max mem: 1118\n",
      "Epoch: [77]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7315.015219435096  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [77]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7258.347240624071  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0177  data: 0.0002  max mem: 1118\n",
      "Epoch: [77]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7089.838254714489  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [77]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7207.77219574411  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [77] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5385  data: 0.5264  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019892482605727412\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:15:10 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [78]  [  0/468]  eta: 0:04:26  lr: 0.01  img/s: 4051.366717981225  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5689  data: 0.5372  max mem: 1118\n",
      "Epoch: [78]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7149.699187641497  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [78]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7172.624074816299  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [78]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7266.402901846137  loss: 0.0086 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [78]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7176.746988918149  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 1118\n",
      "Epoch: [78] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5111  data: 0.4963  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.66, Acc@5 = 100.0, loss = 0.019624280678462003\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:15:21 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [79]  [  0/468]  eta: 0:04:11  lr: 0.01  img/s: 3759.9161834327815  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5364  data: 0.5022  max mem: 1118\n",
      "Epoch: [79]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 6337.003210576015  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [79]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7123.138012471806  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0002  max mem: 1118\n",
      "Epoch: [79]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5931.423243070056  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [79]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7187.604252014888  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [79] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5614  data: 0.5469  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01966971988919415\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:15:31 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [80]  [  0/468]  eta: 0:04:26  lr: 0.01  img/s: 3794.0334690185437  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5687  data: 0.5349  max mem: 1118\n",
      "Epoch: [80]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 6325.057869934025  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0003  max mem: 1118\n",
      "Epoch: [80]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7162.576372490161  loss: 0.0084 (0.0087)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [80]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7178.85822023133  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 1118\n",
      "Epoch: [80]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6363.668725182244  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [80] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5176  data: 0.5063  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019714278770209866\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:15:41 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [81]  [  0/468]  eta: 0:05:07  lr: 0.01  img/s: 4459.505199853806  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6569  data: 0.6282  max mem: 1118\n",
      "Epoch: [81]  [100/468]  eta: 0:00:10  lr: 0.01  img/s: 7134.402360101527  loss: 0.0085 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [81]  [200/468]  eta: 0:00:06  lr: 0.01  img/s: 8109.465009138558  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0003  max mem: 1118\n",
      "Epoch: [81]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6386.2266049698455  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [81]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7146.368212978369  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0003  max mem: 1118\n",
      "Epoch: [81] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5784  data: 0.5635  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01966355739845128\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:15:52 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [82]  [  0/468]  eta: 0:04:23  lr: 0.01  img/s: 3985.382762972311  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5634  data: 0.5313  max mem: 1118\n",
      "Epoch: [82]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6291.185675615501  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0192  data: 0.0003  max mem: 1118\n",
      "Epoch: [82]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7179.338218775074  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0190  data: 0.0002  max mem: 1118\n",
      "Epoch: [82]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6348.693439288586  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0195  data: 0.0003  max mem: 1118\n",
      "Epoch: [82]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6495.08713010235  loss: 0.0086 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0003  max mem: 1118\n",
      "Epoch: [82] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5429  data: 0.5308  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.01995696143919154\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:16:03 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [83]  [  0/468]  eta: 0:05:20  lr: 0.01  img/s: 3788.010301349759  loss: 0.0080 (0.0080)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6848  data: 0.6509  max mem: 1118\n",
      "Epoch: [83]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7159.233391118816  loss: 0.0085 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [83]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7146.558470774597  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [83]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7258.0528599818845  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [83]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7268.075216267074  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [83] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:39  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5043  data: 0.4911  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019699102798123147\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:16:13 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [84]  [  0/468]  eta: 0:04:24  lr: 0.01  img/s: 4401.050210268308  loss: 0.0090 (0.0090)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5653  data: 0.5361  max mem: 1118\n",
      "Epoch: [84]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7152.842666240324  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0002  max mem: 1118\n",
      "Epoch: [84]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7151.9850797964455  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0003  max mem: 1118\n",
      "Epoch: [84]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7191.455407613792  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [84]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6974.7952139061745  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 1118\n",
      "Epoch: [84] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 0.0116 (0.0116)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6310  data: 0.6147  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.65, Acc@5 = 100.0, loss = 0.019648521407684194\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:16:24 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [85]  [  0/468]  eta: 0:04:20  lr: 0.01  img/s: 3627.653229184967  loss: 0.0089 (0.0089)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5563  data: 0.5210  max mem: 1118\n",
      "Epoch: [85]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7135.160905333387  loss: 0.0087 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [85]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7254.816248209508  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0003  max mem: 1118\n",
      "Epoch: [85]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7347.451203656818  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0178  data: 0.0003  max mem: 1118\n",
      "Epoch: [85]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7154.272434103568  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0179  data: 0.0003  max mem: 1118\n",
      "Epoch: [85] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0114 (0.0114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5427  data: 0.5265  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019823867756920525\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:16:34 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [86]  [  0/468]  eta: 0:04:18  lr: 0.01  img/s: 3941.8413779938032  loss: 0.0078 (0.0078)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5532  data: 0.5206  max mem: 1118\n",
      "Epoch: [86]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7278.816019957158  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [86]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7249.526196391919  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0186  data: 0.0003  max mem: 1118\n",
      "Epoch: [86]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 5838.663114049875  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0188  data: 0.0002  max mem: 1118\n",
      "Epoch: [86]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7353.993096268698  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [86] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5659  data: 0.5525  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.01994167423889607\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:16:45 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [87]  [  0/468]  eta: 0:04:14  lr: 0.01  img/s: 4498.516154980561  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5432  data: 0.5147  max mem: 1118\n",
      "Epoch: [87]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7234.774509143343  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0164  data: 0.0003  max mem: 1118\n",
      "Epoch: [87]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7279.210781788106  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0179  data: 0.0003  max mem: 1118\n",
      "Epoch: [87]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7621.568575119603  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [87]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7133.454405336097  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [87] Total time: 0:00:08\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5496  data: 0.5395  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.02001287386740876\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:16:54 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [88]  [  0/468]  eta: 0:04:08  lr: 0.01  img/s: 3843.6325835135094  loss: 0.0095 (0.0095)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5305  data: 0.4971  max mem: 1118\n",
      "Epoch: [88]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7249.1346475830405  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [88]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7359.941215984646  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [88]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7957.7693915363525  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [88]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7169.750427350427  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0003  max mem: 1118\n",
      "Epoch: [88] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0111 (0.0111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5476  data: 0.5355  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019809451649743546\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:17:05 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [89]  [  0/468]  eta: 0:04:37  lr: 0.01  img/s: 3832.055046395432  loss: 0.0092 (0.0092)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5934  data: 0.5599  max mem: 1118\n",
      "Epoch: [89]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 6363.819589156384  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 1118\n",
      "Epoch: [89]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7195.310692363363  loss: 0.0082 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0003  max mem: 1118\n",
      "Epoch: [89]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6302.929300993214  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [89]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6334.012647475224  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [89] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5834  data: 0.5700  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.019942042447296502\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:17:15 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [90]  [  0/468]  eta: 0:04:01  lr: 0.01  img/s: 4077.7070636487924  loss: 0.0092 (0.0092)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5170  data: 0.4855  max mem: 1118\n",
      "Epoch: [90]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7145.131784183768  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [90]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7176.075493891518  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [90]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7158.278826666667  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [90]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6560.326897697834  loss: 0.0083 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0002  max mem: 1118\n",
      "Epoch: [90] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0108 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5601  data: 0.5466  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01984754583762982\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:17:25 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [91]  [  0/468]  eta: 0:04:16  lr: 0.01  img/s: 4872.71541763857  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5475  data: 0.5212  max mem: 1118\n",
      "Epoch: [91]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7192.804287245444  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [91]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7152.270919094627  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [91]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7154.558456269407  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0185  data: 0.0003  max mem: 1118\n",
      "Epoch: [91]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7232.435397610163  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [91] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5617  data: 0.5487  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019778849798714436\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:17:36 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [92]  [  0/468]  eta: 0:04:34  lr: 0.01  img/s: 4315.647880644046  loss: 0.0088 (0.0088)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5863  data: 0.5566  max mem: 1118\n",
      "Epoch: [92]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7221.636652228888  loss: 0.0085 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [92]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7215.812908255154  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [92]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7188.759165528508  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [92]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7178.0903560493625  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [92] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0112 (0.0112)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5439  data: 0.5314  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019624678199945747\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:17:46 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [93]  [  0/468]  eta: 0:04:02  lr: 0.01  img/s: 3567.7701192200852  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5177  data: 0.4817  max mem: 1118\n",
      "Epoch: [93]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7188.759165528508  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0003  max mem: 1118\n",
      "Epoch: [93]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7160.474705576376  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [93]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6350.120196345141  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [93]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7122.854496968411  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0187  data: 0.0003  max mem: 1118\n",
      "Epoch: [93] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5366  data: 0.5160  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.019806743469796603\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:17:56 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [94]  [  0/468]  eta: 0:04:12  lr: 0.01  img/s: 3647.121762995571  loss: 0.0081 (0.0081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5397  data: 0.5046  max mem: 1118\n",
      "Epoch: [94]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 6476.439297432928  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [94]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7262.176363169072  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0179  data: 0.0002  max mem: 1118\n",
      "Epoch: [94]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7134.591981288788  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0003  max mem: 1118\n",
      "Epoch: [94]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7690.899235022777  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [94] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 0.0108 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6284  data: 0.6152  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019986239149930734\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:18:07 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [95]  [  0/468]  eta: 0:04:42  lr: 0.01  img/s: 4398.021741445552  loss: 0.0084 (0.0084)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6039  data: 0.5747  max mem: 1118\n",
      "Epoch: [95]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7169.750427350427  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [95]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7212.323168274269  loss: 0.0083 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0003  max mem: 1118\n",
      "Epoch: [95]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7196.7574900467835  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [95]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 6402.982957052727  loss: 0.0085 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0194  data: 0.0003  max mem: 1118\n",
      "Epoch: [95] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 0.0116 (0.0116)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5121  data: 0.4979  max mem: 1118\n",
      "Test: Total time: 0:00:00\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01968395215447379\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:18:17 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [96]  [  0/468]  eta: 0:04:55  lr: 0.01  img/s: 4523.417998601363  loss: 0.0092 (0.0092)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6319  data: 0.6035  max mem: 1118\n",
      "Epoch: [96]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 5684.120993954537  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0190  data: 0.0003  max mem: 1118\n",
      "Epoch: [96]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7276.9414858289165  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [96]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7228.832229223892  loss: 0.0087 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0182  data: 0.0002  max mem: 1118\n",
      "Epoch: [96]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7620.486749655789  loss: 0.0085 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0002  max mem: 1118\n",
      "Epoch: [96] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 0.0110 (0.0110)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5553  data: 0.5415  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.63, Acc@5 = 100.0, loss = 0.019991381677409895\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:18:28 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [97]  [  0/468]  eta: 0:04:48  lr: 0.01  img/s: 3388.90867314733  loss: 0.0083 (0.0083)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6156  data: 0.5778  max mem: 1118\n",
      "Epoch: [97]  [100/468]  eta: 0:00:09  lr: 0.01  img/s: 7167.931641276919  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0191  data: 0.0003  max mem: 1118\n",
      "Epoch: [97]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7174.828765017975  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9961)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0003  max mem: 1118\n",
      "Epoch: [97]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7144.6563485620745  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0181  data: 0.0002  max mem: 1118\n",
      "Epoch: [97]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7094.5227158601365  loss: 0.0084 (0.0086)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [97] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 0.0113 (0.0113)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5431  data: 0.5320  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.62, Acc@5 = 100.0, loss = 0.02003349433947779\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:18:38 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [98]  [  0/468]  eta: 0:04:02  lr: 0.01  img/s: 4246.522962048945  loss: 0.0087 (0.0087)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5171  data: 0.4869  max mem: 1118\n",
      "Epoch: [98]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7153.414504803401  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0184  data: 0.0003  max mem: 1118\n",
      "Epoch: [98]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7148.93754827026  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [98]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 6387.290304926653  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0004  max mem: 1118\n",
      "Epoch: [98]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7315.513598953507  loss: 0.0086 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [98] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0116 (0.0116)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5660  data: 0.5511  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.01971198109131825\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:18:49 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n",
      "Epoch: [99]  [  0/468]  eta: 0:04:08  lr: 0.01  img/s: 4002.8251082961165  loss: 0.0085 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5319  data: 0.4999  max mem: 1118\n",
      "Epoch: [99]  [100/468]  eta: 0:00:08  lr: 0.01  img/s: 7052.306172580031  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0183  data: 0.0002  max mem: 1118\n",
      "Epoch: [99]  [200/468]  eta: 0:00:05  lr: 0.01  img/s: 7192.418841434007  loss: 0.0084 (0.0085)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0179  data: 0.0002  max mem: 1118\n",
      "Epoch: [99]  [300/468]  eta: 0:00:03  lr: 0.01  img/s: 7200.521888412017  loss: 0.0083 (0.0086)  acc1: 100.0000 (99.9974)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [99]  [400/468]  eta: 0:00:01  lr: 0.01  img/s: 7435.679233262236  loss: 0.0084 (0.0085)  acc1: 100.0000 (99.9981)  acc5: 100.0000 (100.0000)  time: 0.0180  data: 0.0002  max mem: 1118\n",
      "Epoch: [99] Total time: 0:00:09\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 0.0108 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5620  data: 0.5493  max mem: 1118\n",
      "Test: Total time: 0:00:01\n",
      " * Acc@1 = 99.64, Acc@5 = 100.0, loss = 0.019825948455335595\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__44\n",
      "Training time 0:18:59 max_test_acc1 99.66 test_acc5_at_max_test_acc1 100.0 train_acc1 99.99833066239316 train_acc5 99.99833066239316\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    save_max = False\n",
    "\n",
    "    train_loss, train_acc1, train_acc5 = train_one_epoch(net, criterion,data_loader, device, epoch, args.print_freq,lr=args.lr)\n",
    "\n",
    "    if utils.is_main_process():\n",
    "        train_tb_writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc1', train_acc1, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc5', train_acc5, epoch)\n",
    "\n",
    "    test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "    if te_tb_writer is not None:\n",
    "        if utils.is_main_process():\n",
    "            te_tb_writer.add_scalar('test_loss', test_loss, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc1', test_acc1, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc5', test_acc5, epoch)\n",
    "\n",
    "    if max_test_acc1 < test_acc1:\n",
    "        max_test_acc1 = test_acc1\n",
    "        test_acc5_at_max_test_acc1 = test_acc5\n",
    "        save_max = True\n",
    "\n",
    "    if output_dir:\n",
    "\n",
    "        checkpoint = {\n",
    "            'model': net.state_dict(),\n",
    "            'pre-train_epoch': epoch,\n",
    "            'args': args,\n",
    "            'max_test_acc1': max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1': test_acc5_at_max_test_acc1,\n",
    "        }\n",
    "\n",
    "        utils.save_on_master(\n",
    "            checkpoint,\n",
    "            os.path.join(output_dir, 'checkpoint_latest.pth'))\n",
    "        save_flag = False\n",
    "\n",
    "        if epoch % 64 == 0 or epoch == args.epochs - 1:\n",
    "            save_flag = True\n",
    "\n",
    "\n",
    "        if save_flag:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir, f'checkpoint_{epoch}.pth'))\n",
    "\n",
    "        if save_max:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net,os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net.state_dict(),os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth'))\n",
    "    print(args)\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(output_dir)\n",
    "\n",
    "    print('Training time {}'.format(total_time_str), 'max_test_acc1', max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1', test_acc5_at_max_test_acc1,'train_acc1', train_acc1,\n",
    "            'train_acc5', train_acc1)\n",
    "\n",
    "    Train_logs= {\n",
    "        'Epoch:': epoch,\n",
    "        'max_test_acc1 ': max_test_acc1 ,\n",
    "        'test_acc5_at_max_test_acc1 ': test_acc5_at_max_test_acc1,\n",
    "        'train_acc1 ': train_acc1,\n",
    "        'train_acc5 ': train_acc1,\n",
    "        'args': args\n",
    "    }\n",
    "    with open(output_dir + '_logs/args.txt', 'a', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(str(Train_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_ann.txt', 'a') as file:\n",
    "    line = str(max_test_acc1)\n",
    "    file.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
