{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import math\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.distributed.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import layer,functional,neuron,surrogate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "np.int = int\n",
    "\n",
    "train_tb_writer = None\n",
    "te_tb_writer = None\n",
    "device = torch.device('cuda:0')\n",
    "deviceIds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Classification Training')\n",
    "\n",
    "    parser.add_argument('--device', default='cuda:0', help='device')\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int)\n",
    "    parser.add_argument('--data-path', default='./data/', help='dataset')\n",
    "    parser.add_argument('--epochs', default=320, type=int, metavar='N',\n",
    "                        help='number of total epochs to pre-train')\n",
    "    parser.add_argument('-j', '--workers', default=16, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 16)')\n",
    "    parser.add_argument('--lr', default=0.0025, type=float, help='initial learning rate')\n",
    "\n",
    "    parser.add_argument('--print-freq', default=10, type=int, help='print frequency')\n",
    "    parser.add_argument('--output-dir', default='./logs', help='path where to save')\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--tb', action='store_true',\n",
    "                        help='Use TensorBoard to record logs')\n",
    "    parser.add_argument(\n",
    "        \"--cache-dataset\",\n",
    "        dest=\"cache_dataset\",\n",
    "        help=\"Cache the datasets for quicker initialization. It also serializes the transforms\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(args=['--data-path','../data','--lr','0.01','-b','128','--epochs','100','--print-freq','100','--tb','--cache-dataset'])\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkB(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkB, self).__init__()\n",
    "        self.T = 10\n",
    "        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, padding=3) \n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.sn1 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.conv2 = layer.SeqToANNContainer(nn.Conv2d(96, 96, kernel_size=3, padding=1),nn.BatchNorm2d(96)) \n",
    "        self.sn2 = neuron.IFNode(detach_reset=True)\n",
    "        self.pool1 = layer.SeqToANNContainer(nn.MaxPool2d(2)) \n",
    "\n",
    "        self.conv3 = layer.SeqToANNContainer(nn.Conv2d(96, 128, kernel_size=3, padding=1),nn.BatchNorm2d(128)) \n",
    "        self.sn3 = neuron.IFNode(detach_reset=True)\n",
    "      \n",
    "        self.conv4 = layer.SeqToANNContainer(nn.Conv2d(128, 128, kernel_size=3, padding=1),nn.BatchNorm2d(128)) \n",
    "        self.sn4 = neuron.IFNode(detach_reset=True)\n",
    "        self.pool2 = layer.SeqToANNContainer(nn.MaxPool2d(2)) \n",
    "\n",
    "        self.conv5 = layer.SeqToANNContainer(nn.Conv2d(128, 256, kernel_size=3, padding=1),nn.BatchNorm2d(256)) \n",
    "        self.sn5 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "\n",
    "        self.pool3 = layer.SeqToANNContainer(nn.MaxPool2d(2)) \n",
    "\n",
    "        self.conv8 = layer.SeqToANNContainer(nn.Conv2d(256, 512, kernel_size=3, padding=1),nn.BatchNorm2d(512)) \n",
    "        self.sn8 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.conv10 = layer.SeqToANNContainer(nn.Conv2d(512, 512, kernel_size=3, padding=1),nn.BatchNorm2d(512)) \n",
    "        self.sn10 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.pool4 = layer.SeqToANNContainer(nn.MaxPool2d(2)) \n",
    "\n",
    "        self.conv11 = layer.SeqToANNContainer(nn.Conv2d(512, 256, kernel_size=3, padding=1),nn.BatchNorm2d(256)) \n",
    "        self.sn11 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.conv13 = layer.SeqToANNContainer(nn.Conv2d(256, 128, kernel_size=3, padding=1),nn.BatchNorm2d(128)) \n",
    "        self.sn13 = neuron.IFNode(detach_reset=True)\n",
    "\n",
    "        self.fc1 = layer.SeqToANNContainer(nn.Linear(512, 256),nn.BatchNorm1d(256))\n",
    "        self.sn14 = neuron.IFNode(detach_reset=True)\n",
    "        self.fc2 = layer.SeqToANNContainer(nn.Linear(256, 10),nn.BatchNorm1d(10))\n",
    "        self.sn15 = neuron.IFNode(detach_reset=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        T = self.T\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x.unsqueeze_(0)\n",
    "        x = x.repeat(10, 1, 1, 1, 1)\n",
    "        x = self.sn1(x)\n",
    "\n",
    "        x = self.sn2(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.sn3(self.conv3(x))\n",
    "        x = self.sn4(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.sn5(self.conv5(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.sn8(self.conv8(x))\n",
    "        x = self.sn10(self.conv10(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.sn11(self.conv11(x))\n",
    "\n",
    "        x = x[:T, :, :, :, :]\n",
    "       \n",
    "        x = self.sn13(self.conv13(x))\n",
    "      \n",
    "        x = torch.flatten(x,2)\n",
    "\n",
    "        x = self.sn14(self.fc1(x))\n",
    "        x = self.sn15(self.fc2(x))\n",
    "       \n",
    "        return x.mean(0)\n",
    "    \n",
    "    def set_T(self, T):\n",
    "        self.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "max_test_acc1 = 0.\n",
    "test_acc5_at_max_test_acc1 = 0.\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "print(args)\n",
    "output_dir = os.path.join(args.output_dir, f'b_{args.batch_size}_lr{args.lr}')\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "output_dir += f'_{time_now.year}_{time_now.month}_{time_now.day}_{time_now.hour}__{time_now.minute}'\n",
    "\n",
    "\n",
    "if output_dir:\n",
    "    utils.mkdir(output_dir)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Creating model\")\n",
    "\n",
    "net = NetworkB().to(device)\n",
    "functional.set_step_mode(net,step_mode='m')\n",
    "functional.set_backend(net, backend='cupy')\n",
    "net.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4, last_epoch=-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    args.start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc1 = checkpoint['max_test_acc1']\n",
    "    test_acc5_at_max_test_acc1 = checkpoint['test_acc5_at_max_test_acc1']\n",
    "\n",
    "\n",
    "if args.tb and utils.is_main_process():\n",
    "    purge_step_train = args.start_epoch\n",
    "    purge_step_te = args.start_epoch\n",
    "    train_tb_writer = SummaryWriter(output_dir + '_logs/train', purge_step=purge_step_train)\n",
    "    te_tb_writer = SummaryWriter(output_dir + '_logs/te', purge_step=purge_step_te)\n",
    "    with open(output_dir + '_logs/args.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "\n",
    "    with open(output_dir + '_logs/resluts.txt', 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('Results\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(net, criterion, data_loader, device, epoch, print_freq, scaler=None,lr = 1e-2):\n",
    "    net.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n",
    "    metric_logger.add_meter('img/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n",
    "\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "\n",
    "    for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        start_time = time.time()\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        functional.reset_net(net)\n",
    "\n",
    "        acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "        batch_size = image.shape[0]\n",
    "        loss_s = loss.item()\n",
    "        if math.isnan(loss_s):\n",
    "            raise ValueError('loss is Nan')\n",
    "        acc1_s = acc1.item()\n",
    "        acc5_s = acc5.item()\n",
    "\n",
    "        metric_logger.update(loss=loss_s, lr=lr)\n",
    "\n",
    "        metric_logger.meters['acc1'].update(acc1_s, n=batch_size)\n",
    "        metric_logger.meters['acc5'].update(acc5_s, n=batch_size)\n",
    "        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n",
    "\n",
    " \n",
    "    metric_logger.synchronize_between_processes()\n",
    "    return metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, data_loader, device, print_freq=100, header='Test:'):\n",
    "    net.eval()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    with torch.no_grad():\n",
    "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
    "            image = image.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = net(image)\n",
    "            loss = criterion(output, target)\n",
    "            functional.reset_net(net)\n",
    "\n",
    "            acc1, acc5 = utils.accuracy(output, target, topk=(1, 5))\n",
    "           \n",
    "            batch_size = image.shape[0]\n",
    "            metric_logger.update(loss=loss.item())\n",
    "            metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "            metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    \n",
    "    metric_logger.synchronize_between_processes()\n",
    "\n",
    "    loss, acc1, acc5 = metric_logger.loss.global_avg, metric_logger.acc1.global_avg, metric_logger.acc5.global_avg\n",
    "    print(f' * Acc@1 = {acc1}, Acc@5 = {acc5}, loss = {loss}')\n",
    "    return loss, acc1, acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0]  [  0/468]  eta: 0:28:10  lr: 0.01  img/s: 41.13945467537418  loss: 2.3051 (2.3051)  acc1: 6.2500 (6.2500)  acc5: 54.6875 (54.6875)  time: 3.6127  data: 0.5013  max mem: 10434\n",
      "Epoch: [0]  [100/468]  eta: 0:01:16  lr: 0.01  img/s: 703.8742213895484  loss: 1.5493 (1.7661)  acc1: 92.1875 (70.4440)  acc5: 99.2188 (94.0439)  time: 0.1642  data: 0.0004  max mem: 10434\n",
      "Epoch: [0]  [200/468]  eta: 0:00:49  lr: 0.01  img/s: 944.9340798406074  loss: 1.5008 (1.6426)  acc1: 96.0938 (82.7309)  acc5: 99.2188 (96.7390)  time: 0.1236  data: 0.0004  max mem: 10434\n",
      "Epoch: [0]  [300/468]  eta: 0:00:30  lr: 0.01  img/s: 705.1472522853841  loss: 1.4937 (1.5936)  acc1: 96.8750 (87.4143)  acc5: 99.2188 (97.6900)  time: 0.1759  data: 0.0004  max mem: 10434\n",
      "Epoch: [0]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 701.7324175070092  loss: 1.4906 (1.5671)  acc1: 97.6562 (89.9509)  acc5: 100.0000 (98.2135)  time: 0.1751  data: 0.0004  max mem: 10434\n",
      "Epoch: [0] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:13:14  loss: 1.4754 (1.4754)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 10.0603  data: 0.5646  max mem: 10434\n",
      "Test: Total time: 0:00:14\n",
      " * Acc@1 = 98.28, Acc@5 = 99.88, loss = 1.4782425949845133\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:01:38 max_test_acc1 98.28 test_acc5_at_max_test_acc1 99.88 train_acc1 91.01896367521367 train_acc5 91.01896367521367\n",
      "Epoch: [1]  [  0/468]  eta: 0:05:44  lr: 0.01  img/s: 689.9333058321736  loss: 1.4762 (1.4762)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.7370  data: 0.5514  max mem: 10434\n",
      "Epoch: [1]  [100/468]  eta: 0:01:05  lr: 0.01  img/s: 702.264808335023  loss: 1.4801 (1.4823)  acc1: 97.6562 (97.8419)  acc5: 100.0000 (99.7602)  time: 0.1872  data: 0.0004  max mem: 10434\n",
      "Epoch: [1]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 1080.4949172327044  loss: 1.4823 (1.4808)  acc1: 97.6562 (98.0061)  acc5: 100.0000 (99.7746)  time: 0.1851  data: 0.0004  max mem: 10434\n",
      "Epoch: [1]  [300/468]  eta: 0:00:28  lr: 0.01  img/s: 678.2561114578306  loss: 1.4692 (1.4800)  acc1: 99.2188 (98.1234)  acc5: 100.0000 (99.7924)  time: 0.1643  data: 0.0003  max mem: 10434\n",
      "Epoch: [1]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 697.5239248467872  loss: 1.4747 (1.4788)  acc1: 98.4375 (98.2193)  acc5: 100.0000 (99.8052)  time: 0.1875  data: 0.0004  max mem: 10434\n",
      "Epoch: [1] Total time: 0:01:20\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4707 (1.4707)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6031  data: 0.5399  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.73, Acc@5 = 99.86, loss = 1.4730624292470231\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:03:05 max_test_acc1 98.73 test_acc5_at_max_test_acc1 99.86 train_acc1 98.30228365384616 train_acc5 98.30228365384616\n",
      "Epoch: [2]  [  0/468]  eta: 0:05:43  lr: 0.01  img/s: 1027.085440767687  loss: 1.4726 (1.4726)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.7347  data: 0.6100  max mem: 10434\n",
      "Epoch: [2]  [100/468]  eta: 0:01:06  lr: 0.01  img/s: 680.5448101368515  loss: 1.4675 (1.4721)  acc1: 99.2188 (98.8939)  acc5: 100.0000 (99.8685)  time: 0.1911  data: 0.0004  max mem: 10434\n",
      "Epoch: [2]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 676.7249126159501  loss: 1.4698 (1.4726)  acc1: 99.2188 (98.8029)  acc5: 100.0000 (99.8717)  time: 0.1882  data: 0.0004  max mem: 10434\n",
      "Epoch: [2]  [300/468]  eta: 0:00:28  lr: 0.01  img/s: 693.946365858419  loss: 1.4674 (1.4721)  acc1: 99.2188 (98.8320)  acc5: 100.0000 (99.8780)  time: 0.1431  data: 0.0004  max mem: 10434\n",
      "Epoch: [2]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 667.648580688005  loss: 1.4723 (1.4726)  acc1: 98.4375 (98.7862)  acc5: 100.0000 (99.8636)  time: 0.1866  data: 0.0004  max mem: 10434\n",
      "Epoch: [2] Total time: 0:01:20\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4660 (1.4660)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6318  data: 0.5688  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.99, Acc@5 = 99.86, loss = 1.471508579918101\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:04:32 max_test_acc1 98.99 test_acc5_at_max_test_acc1 99.86 train_acc1 98.78305288461539 train_acc5 98.78305288461539\n",
      "Epoch: [3]  [  0/468]  eta: 0:05:43  lr: 0.01  img/s: 1030.8066647978403  loss: 1.4727 (1.4727)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.7349  data: 0.6107  max mem: 10434\n",
      "Epoch: [3]  [100/468]  eta: 0:01:03  lr: 0.01  img/s: 700.3675034831115  loss: 1.4681 (1.4698)  acc1: 99.2188 (99.1646)  acc5: 100.0000 (99.8685)  time: 0.1632  data: 0.0005  max mem: 10434\n",
      "Epoch: [3]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 676.9348183247572  loss: 1.4733 (1.4718)  acc1: 98.4375 (98.9739)  acc5: 100.0000 (99.8640)  time: 0.1877  data: 0.0004  max mem: 10434\n",
      "Epoch: [3]  [300/468]  eta: 0:00:28  lr: 0.01  img/s: 1055.7580415207358  loss: 1.4682 (1.4714)  acc1: 99.2188 (98.9774)  acc5: 100.0000 (99.8780)  time: 0.1842  data: 0.0004  max mem: 10434\n",
      "Epoch: [3]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 711.1899757713365  loss: 1.4661 (1.4709)  acc1: 99.2188 (99.0142)  acc5: 100.0000 (99.8812)  time: 0.1627  data: 0.0004  max mem: 10434\n",
      "Epoch: [3] Total time: 0:01:19\n",
      "Test:  [ 0/79]  eta: 0:00:55  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7048  data: 0.6425  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.85, Acc@5 = 99.79, loss = 1.4716071720364727\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:05:57 max_test_acc1 98.99 test_acc5_at_max_test_acc1 99.86 train_acc1 99.0367922008547 train_acc5 99.0367922008547\n",
      "Epoch: [4]  [  0/468]  eta: 0:04:17  lr: 0.01  img/s: 666.8027652265066  loss: 1.4702 (1.4702)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.5508  data: 0.3588  max mem: 10434\n",
      "Epoch: [4]  [100/468]  eta: 0:01:03  lr: 0.01  img/s: 1083.8782534260404  loss: 1.4663 (1.4676)  acc1: 99.2188 (99.3657)  acc5: 100.0000 (99.8762)  time: 0.1576  data: 0.0004  max mem: 10434\n",
      "Epoch: [4]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 687.757297809024  loss: 1.4684 (1.4681)  acc1: 99.2188 (99.3043)  acc5: 100.0000 (99.9028)  time: 0.1862  data: 0.0005  max mem: 10434\n",
      "Epoch: [4]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 696.6061957064727  loss: 1.4676 (1.4686)  acc1: 99.2188 (99.2473)  acc5: 100.0000 (99.8962)  time: 0.1870  data: 0.0005  max mem: 10434\n",
      "Epoch: [4]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 1067.732624787695  loss: 1.4665 (1.4687)  acc1: 99.2188 (99.2343)  acc5: 100.0000 (99.8889)  time: 0.1550  data: 0.0004  max mem: 10434\n",
      "Epoch: [4] Total time: 0:01:16\n",
      "Test:  [ 0/79]  eta: 0:00:50  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6421  data: 0.5969  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.11, Acc@5 = 99.85, loss = 1.4698357265206832\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:07:18 max_test_acc1 99.11 test_acc5_at_max_test_acc1 99.85 train_acc1 99.26382211538461 train_acc5 99.26382211538461\n",
      "Epoch: [5]  [  0/468]  eta: 0:05:21  lr: 0.01  img/s: 993.4658124877407  loss: 1.4674 (1.4674)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6880  data: 0.5591  max mem: 10434\n",
      "Epoch: [5]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1107.0233747381271  loss: 1.4693 (1.4678)  acc1: 99.2188 (99.3425)  acc5: 100.0000 (99.9226)  time: 0.1207  data: 0.0004  max mem: 10434\n",
      "Epoch: [5]  [200/468]  eta: 0:00:31  lr: 0.01  img/s: 1059.7028802425468  loss: 1.4653 (1.4678)  acc1: 100.0000 (99.3548)  acc5: 100.0000 (99.9184)  time: 0.1065  data: 0.0003  max mem: 10434\n",
      "Epoch: [5]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1106.3595152279504  loss: 1.4674 (1.4680)  acc1: 99.2188 (99.3330)  acc5: 100.0000 (99.9118)  time: 0.1205  data: 0.0004  max mem: 10434\n",
      "Epoch: [5]  [400/468]  eta: 0:00:07  lr: 0.01  img/s: 1064.3331192260418  loss: 1.4657 (1.4678)  acc1: 99.2188 (99.3376)  acc5: 100.0000 (99.9201)  time: 0.1206  data: 0.0004  max mem: 10434\n",
      "Epoch: [5] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4744 (1.4744)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6284  data: 0.5840  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 98.67, Acc@5 = 99.84, loss = 1.4742428773566136\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:08:17 max_test_acc1 99.11 test_acc5_at_max_test_acc1 99.85 train_acc1 99.32725694444444 train_acc5 99.32725694444444\n",
      "Epoch: [6]  [  0/468]  eta: 0:05:21  lr: 0.01  img/s: 1003.6471098482016  loss: 1.4662 (1.4662)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6869  data: 0.5593  max mem: 10434\n",
      "Epoch: [6]  [100/468]  eta: 0:00:45  lr: 0.01  img/s: 1048.4101382398487  loss: 1.4643 (1.4671)  acc1: 100.0000 (99.4044)  acc5: 100.0000 (99.9226)  time: 0.1076  data: 0.0004  max mem: 10434\n",
      "Epoch: [6]  [200/468]  eta: 0:00:32  lr: 0.01  img/s: 1074.4918192898642  loss: 1.4656 (1.4668)  acc1: 100.0000 (99.4481)  acc5: 100.0000 (99.9262)  time: 0.1207  data: 0.0003  max mem: 10434\n",
      "Epoch: [6]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1026.8379214251424  loss: 1.4672 (1.4669)  acc1: 99.2188 (99.4212)  acc5: 100.0000 (99.9273)  time: 0.1209  data: 0.0003  max mem: 10434\n",
      "Epoch: [6]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 1045.468182473195  loss: 1.4652 (1.4670)  acc1: 99.2188 (99.4097)  acc5: 100.0000 (99.9240)  time: 0.1137  data: 0.0003  max mem: 10434\n",
      "Epoch: [6] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:39  loss: 1.4621 (1.4621)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4959  data: 0.4489  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.06, Acc@5 = 99.81, loss = 1.4699998369699792\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:09:16 max_test_acc1 99.11 test_acc5_at_max_test_acc1 99.85 train_acc1 99.40237713675214 train_acc5 99.40237713675214\n",
      "Epoch: [7]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 1344.7086941166747  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6118  data: 0.5165  max mem: 10434\n",
      "Epoch: [7]  [100/468]  eta: 0:00:45  lr: 0.01  img/s: 1071.748372028028  loss: 1.4628 (1.4661)  acc1: 100.0000 (99.5746)  acc5: 100.0000 (99.9381)  time: 0.1201  data: 0.0004  max mem: 10434\n",
      "Epoch: [7]  [200/468]  eta: 0:00:31  lr: 0.01  img/s: 1066.4388507500635  loss: 1.4658 (1.4664)  acc1: 100.0000 (99.5103)  acc5: 100.0000 (99.9339)  time: 0.1204  data: 0.0003  max mem: 10434\n",
      "Epoch: [7]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1068.5274102380383  loss: 1.4669 (1.4661)  acc1: 99.2188 (99.5354)  acc5: 100.0000 (99.9351)  time: 0.1208  data: 0.0003  max mem: 10434\n",
      "Epoch: [7]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 1174.0400669166931  loss: 1.4646 (1.4661)  acc1: 99.2188 (99.5285)  acc5: 100.0000 (99.9357)  time: 0.1082  data: 0.0003  max mem: 10434\n",
      "Epoch: [7] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:50  loss: 1.4641 (1.4641)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6378  data: 0.5949  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.44, Acc@5 = 99.94, loss = 1.4661120629008813\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:10:16 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.5342548076923 train_acc5 99.5342548076923\n",
      "Epoch: [8]  [  0/468]  eta: 0:05:11  lr: 0.01  img/s: 1026.215721505631  loss: 1.4705 (1.4705)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.6657  data: 0.5409  max mem: 10434\n",
      "Epoch: [8]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1063.2686280140615  loss: 1.4668 (1.4655)  acc1: 99.2188 (99.5900)  acc5: 100.0000 (99.9459)  time: 0.1196  data: 0.0003  max mem: 10434\n",
      "Epoch: [8]  [200/468]  eta: 0:00:31  lr: 0.01  img/s: 1067.2677776607102  loss: 1.4633 (1.4654)  acc1: 100.0000 (99.6074)  acc5: 100.0000 (99.9378)  time: 0.1202  data: 0.0003  max mem: 10434\n",
      "Epoch: [8]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1100.5986318135133  loss: 1.4654 (1.4655)  acc1: 99.2188 (99.5847)  acc5: 100.0000 (99.9377)  time: 0.1085  data: 0.0004  max mem: 10434\n",
      "Epoch: [8]  [400/468]  eta: 0:00:07  lr: 0.01  img/s: 1036.3803136914241  loss: 1.4653 (1.4655)  acc1: 99.2188 (99.5714)  acc5: 100.0000 (99.9377)  time: 0.1207  data: 0.0004  max mem: 10434\n",
      "Epoch: [8] Total time: 0:00:54\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4632 (1.4632)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6071  data: 0.5638  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.33, Acc@5 = 99.91, loss = 1.466833212707616\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:11:15 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.54760950854701 train_acc5 99.54760950854701\n",
      "Epoch: [9]  [  0/468]  eta: 0:05:20  lr: 0.01  img/s: 1008.818312669821  loss: 1.4621 (1.4621)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6841  data: 0.5572  max mem: 10434\n",
      "Epoch: [9]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1080.2079487814055  loss: 1.4634 (1.4655)  acc1: 100.0000 (99.5978)  acc5: 100.0000 (99.9381)  time: 0.1201  data: 0.0004  max mem: 10434\n",
      "Epoch: [9]  [200/468]  eta: 0:00:31  lr: 0.01  img/s: 1096.4895971831618  loss: 1.4659 (1.4654)  acc1: 99.2188 (99.5802)  acc5: 100.0000 (99.9534)  time: 0.1066  data: 0.0003  max mem: 10434\n",
      "Epoch: [9]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1062.0108521274008  loss: 1.4637 (1.4655)  acc1: 100.0000 (99.5847)  acc5: 100.0000 (99.9481)  time: 0.1208  data: 0.0003  max mem: 10434\n",
      "Epoch: [9]  [400/468]  eta: 0:00:07  lr: 0.01  img/s: 1050.6855796403718  loss: 1.4634 (1.4656)  acc1: 100.0000 (99.5675)  acc5: 100.0000 (99.9493)  time: 0.1207  data: 0.0003  max mem: 10434\n",
      "Epoch: [9] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4625 (1.4625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6287  data: 0.5804  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.23, Acc@5 = 99.86, loss = 1.4679903727543504\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:12:14 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.56263354700855 train_acc5 99.56263354700855\n",
      "Epoch: [10]  [  0/468]  eta: 0:05:50  lr: 0.01  img/s: 1030.1658102273818  loss: 1.4673 (1.4673)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.7494  data: 0.6251  max mem: 10434\n",
      "Epoch: [10]  [100/468]  eta: 0:00:45  lr: 0.01  img/s: 1103.260666389929  loss: 1.4631 (1.4646)  acc1: 100.0000 (99.6674)  acc5: 100.0000 (99.9613)  time: 0.1090  data: 0.0003  max mem: 10434\n",
      "Epoch: [10]  [200/468]  eta: 0:00:32  lr: 0.01  img/s: 1022.5099837730359  loss: 1.4640 (1.4651)  acc1: 99.2188 (99.5997)  acc5: 100.0000 (99.9611)  time: 0.1219  data: 0.0003  max mem: 10434\n",
      "Epoch: [10]  [300/468]  eta: 0:00:20  lr: 0.01  img/s: 1080.688489611221  loss: 1.4642 (1.4653)  acc1: 100.0000 (99.5795)  acc5: 100.0000 (99.9611)  time: 0.1217  data: 0.0002  max mem: 10434\n",
      "Epoch: [10]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 1068.2871498130546  loss: 1.4639 (1.4653)  acc1: 99.2188 (99.5987)  acc5: 100.0000 (99.9571)  time: 0.1233  data: 0.0003  max mem: 10434\n",
      "Epoch: [10] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4626 (1.4626)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6096  data: 0.5663  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.24, Acc@5 = 99.86, loss = 1.4678418274167218\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:13:13 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.5826655982906 train_acc5 99.5826655982906\n",
      "Epoch: [11]  [  0/468]  eta: 0:05:30  lr: 0.01  img/s: 975.6233806118647  loss: 1.4761 (1.4761)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.7055  data: 0.5742  max mem: 10434\n",
      "Epoch: [11]  [100/468]  eta: 0:00:46  lr: 0.01  img/s: 1006.8223684580662  loss: 1.4621 (1.4652)  acc1: 100.0000 (99.5900)  acc5: 100.0000 (99.9381)  time: 0.1212  data: 0.0003  max mem: 10434\n",
      "Epoch: [11]  [200/468]  eta: 0:00:32  lr: 0.01  img/s: 1067.8005815641768  loss: 1.4641 (1.4649)  acc1: 100.0000 (99.6269)  acc5: 100.0000 (99.9378)  time: 0.1213  data: 0.0003  max mem: 10434\n",
      "Epoch: [11]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1064.2888107826286  loss: 1.4660 (1.4651)  acc1: 99.2188 (99.6314)  acc5: 100.0000 (99.9507)  time: 0.1205  data: 0.0003  max mem: 10434\n",
      "Epoch: [11]  [400/468]  eta: 0:00:07  lr: 0.01  img/s: 1097.5678263749473  loss: 1.4652 (1.4651)  acc1: 100.0000 (99.6318)  acc5: 100.0000 (99.9591)  time: 0.0957  data: 0.0003  max mem: 10434\n",
      "Epoch: [11] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4625 (1.4625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6207  data: 0.5777  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.28, Acc@5 = 99.85, loss = 1.4684862245487262\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:14:12 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.59935897435898 train_acc5 99.59935897435898\n",
      "Epoch: [12]  [  0/468]  eta: 0:06:02  lr: 0.01  img/s: 1098.23465323648  loss: 1.4720 (1.4720)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.7749  data: 0.6583  max mem: 10434\n",
      "Epoch: [12]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1041.3071877169912  loss: 1.4620 (1.4649)  acc1: 100.0000 (99.5978)  acc5: 100.0000 (99.9845)  time: 0.1205  data: 0.0003  max mem: 10434\n",
      "Epoch: [12]  [200/468]  eta: 0:00:31  lr: 0.01  img/s: 1051.4181145910038  loss: 1.4636 (1.4645)  acc1: 100.0000 (99.6502)  acc5: 100.0000 (99.9845)  time: 0.1217  data: 0.0003  max mem: 10434\n",
      "Epoch: [12]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1115.589829691383  loss: 1.4644 (1.4647)  acc1: 100.0000 (99.6548)  acc5: 100.0000 (99.9714)  time: 0.0958  data: 0.0003  max mem: 10434\n",
      "Epoch: [12]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 1063.5866982055336  loss: 1.4635 (1.4648)  acc1: 100.0000 (99.6474)  acc5: 100.0000 (99.9688)  time: 0.1206  data: 0.0003  max mem: 10434\n",
      "Epoch: [12] Total time: 0:00:54\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4625 (1.4625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5752  data: 0.5302  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.33, Acc@5 = 99.89, loss = 1.467255850381489\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:15:11 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.64276175213675 train_acc5 99.64276175213675\n",
      "Epoch: [13]  [  0/468]  eta: 0:05:41  lr: 0.01  img/s: 1026.021561189095  loss: 1.4624 (1.4624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7302  data: 0.6054  max mem: 10434\n",
      "Epoch: [13]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1080.9800665254545  loss: 1.4624 (1.4637)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (99.9691)  time: 0.1194  data: 0.0003  max mem: 10434\n",
      "Epoch: [13]  [200/468]  eta: 0:00:31  lr: 0.01  img/s: 1544.4500407061876  loss: 1.4621 (1.4638)  acc1: 100.0000 (99.7707)  acc5: 100.0000 (99.9611)  time: 0.0938  data: 0.0004  max mem: 10434\n",
      "Epoch: [13]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1052.0444590760162  loss: 1.4626 (1.4643)  acc1: 100.0000 (99.7093)  acc5: 100.0000 (99.9637)  time: 0.1212  data: 0.0004  max mem: 10434\n",
      "Epoch: [13]  [400/468]  eta: 0:00:07  lr: 0.01  img/s: 1067.26989933046  loss: 1.4627 (1.4644)  acc1: 100.0000 (99.6844)  acc5: 100.0000 (99.9649)  time: 0.1205  data: 0.0003  max mem: 10434\n",
      "Epoch: [13] Total time: 0:00:54\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4645 (1.4645)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5641  data: 0.5209  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.37, Acc@5 = 99.87, loss = 1.4670497873161412\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:16:10 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.69284188034187 train_acc5 99.69284188034187\n",
      "Epoch: [14]  [  0/468]  eta: 0:05:22  lr: 0.01  img/s: 1021.4594438271511  loss: 1.4664 (1.4664)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6886  data: 0.5632  max mem: 10434\n",
      "Epoch: [14]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1076.838812424533  loss: 1.4618 (1.4644)  acc1: 100.0000 (99.7293)  acc5: 100.0000 (99.9613)  time: 0.0975  data: 0.0003  max mem: 10434\n",
      "Epoch: [14]  [200/468]  eta: 0:00:32  lr: 0.01  img/s: 1062.9444344350093  loss: 1.4623 (1.4647)  acc1: 100.0000 (99.6852)  acc5: 100.0000 (99.9650)  time: 0.1203  data: 0.0003  max mem: 10434\n",
      "Epoch: [14]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1030.8581259600614  loss: 1.4654 (1.4649)  acc1: 99.2188 (99.6418)  acc5: 100.0000 (99.9637)  time: 0.1211  data: 0.0003  max mem: 10434\n",
      "Epoch: [14]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 1059.7928307615168  loss: 1.4626 (1.4648)  acc1: 100.0000 (99.6532)  acc5: 100.0000 (99.9610)  time: 0.1199  data: 0.0003  max mem: 10434\n",
      "Epoch: [14] Total time: 0:00:55\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4659 (1.4659)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6004  data: 0.5566  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.43, Acc@5 = 99.85, loss = 1.4661591158637517\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:17:10 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.65277777777777 train_acc5 99.65277777777777\n",
      "Epoch: [15]  [  0/468]  eta: 0:05:22  lr: 0.01  img/s: 1065.7085132272928  loss: 1.4627 (1.4627)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6893  data: 0.5691  max mem: 10434\n",
      "Epoch: [15]  [100/468]  eta: 0:00:46  lr: 0.01  img/s: 1063.7552893436418  loss: 1.4626 (1.4640)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (99.9691)  time: 0.1204  data: 0.0004  max mem: 10434\n",
      "Epoch: [15]  [200/468]  eta: 0:00:32  lr: 0.01  img/s: 1060.7686237317605  loss: 1.4629 (1.4642)  acc1: 100.0000 (99.7707)  acc5: 100.0000 (99.9650)  time: 0.1206  data: 0.0003  max mem: 10434\n",
      "Epoch: [15]  [300/468]  eta: 0:00:19  lr: 0.01  img/s: 1039.2149466137062  loss: 1.4628 (1.4643)  acc1: 100.0000 (99.7560)  acc5: 100.0000 (99.9611)  time: 0.1239  data: 0.0003  max mem: 10434\n",
      "Epoch: [15]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 690.8077471421733  loss: 1.4629 (1.4644)  acc1: 100.0000 (99.7253)  acc5: 100.0000 (99.9532)  time: 0.1508  data: 0.0003  max mem: 10434\n",
      "Epoch: [15] Total time: 0:01:03\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4616 (1.4616)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6153  data: 0.5374  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.31, Acc@5 = 99.89, loss = 1.4673509778855722\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:18:19 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.7245592948718 train_acc5 99.7245592948718\n",
      "Epoch: [16]  [  0/468]  eta: 0:06:13  lr: 0.01  img/s: 696.101299960843  loss: 1.4615 (1.4615)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7980  data: 0.6140  max mem: 10434\n",
      "Epoch: [16]  [100/468]  eta: 0:01:05  lr: 0.01  img/s: 733.6938162208553  loss: 1.4622 (1.4636)  acc1: 100.0000 (99.8221)  acc5: 100.0000 (99.9613)  time: 0.1713  data: 0.0003  max mem: 10434\n",
      "Epoch: [16]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 686.7324041669225  loss: 1.4626 (1.4638)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (99.9572)  time: 0.1845  data: 0.0005  max mem: 10434\n",
      "Epoch: [16]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 653.9414770450329  loss: 1.4629 (1.4640)  acc1: 100.0000 (99.7664)  acc5: 100.0000 (99.9585)  time: 0.1902  data: 0.0004  max mem: 10434\n",
      "Epoch: [16]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 675.4792551585305  loss: 1.4623 (1.4641)  acc1: 100.0000 (99.7311)  acc5: 100.0000 (99.9571)  time: 0.1584  data: 0.0003  max mem: 10434\n",
      "Epoch: [16] Total time: 0:01:21\n",
      "Test:  [ 0/79]  eta: 0:00:51  loss: 1.4725 (1.4725)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6508  data: 0.6051  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.06, Acc@5 = 99.86, loss = 1.4693988576720032\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:19:47 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.73123664529915 train_acc5 99.73123664529915\n",
      "Epoch: [17]  [  0/468]  eta: 0:05:34  lr: 0.01  img/s: 673.2058724689148  loss: 1.4620 (1.4620)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7155  data: 0.5253  max mem: 10434\n",
      "Epoch: [17]  [100/468]  eta: 0:01:06  lr: 0.01  img/s: 1020.4343343723865  loss: 1.4631 (1.4653)  acc1: 100.0000 (99.6055)  acc5: 100.0000 (99.9691)  time: 0.1856  data: 0.0004  max mem: 10434\n",
      "Epoch: [17]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 669.6848132103079  loss: 1.4651 (1.4648)  acc1: 100.0000 (99.6813)  acc5: 100.0000 (99.9611)  time: 0.1592  data: 0.0004  max mem: 10434\n",
      "Epoch: [17]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 700.8173103030556  loss: 1.4650 (1.4648)  acc1: 100.0000 (99.6937)  acc5: 100.0000 (99.9637)  time: 0.1895  data: 0.0003  max mem: 10434\n",
      "Epoch: [17]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 1054.3440030322133  loss: 1.4633 (1.4649)  acc1: 100.0000 (99.6610)  acc5: 100.0000 (99.9591)  time: 0.1842  data: 0.0004  max mem: 10434\n",
      "Epoch: [17] Total time: 0:01:21\n",
      "Test:  [ 0/79]  eta: 0:00:52  loss: 1.4694 (1.4694)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6668  data: 0.5936  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.32, Acc@5 = 99.89, loss = 1.4677194537995737\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:21:14 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.6494391025641 train_acc5 99.6494391025641\n",
      "Epoch: [18]  [  0/468]  eta: 0:06:51  lr: 0.01  img/s: 671.4327492840081  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.8786  data: 0.6879  max mem: 10434\n",
      "Epoch: [18]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 682.836847969312  loss: 1.4625 (1.4637)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (99.9536)  time: 0.1874  data: 0.0004  max mem: 10434\n",
      "Epoch: [18]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 1087.023071892381  loss: 1.4635 (1.4641)  acc1: 100.0000 (99.7551)  acc5: 100.0000 (99.9572)  time: 0.1604  data: 0.0004  max mem: 10434\n",
      "Epoch: [18]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 670.7809192532925  loss: 1.4623 (1.4642)  acc1: 100.0000 (99.7560)  acc5: 100.0000 (99.9585)  time: 0.1888  data: 0.0003  max mem: 10434\n",
      "Epoch: [18]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 678.5638692243426  loss: 1.4626 (1.4639)  acc1: 100.0000 (99.7643)  acc5: 100.0000 (99.9630)  time: 0.1888  data: 0.0004  max mem: 10434\n",
      "Epoch: [18] Total time: 0:01:21\n",
      "Test:  [ 0/79]  eta: 0:00:53  loss: 1.4668 (1.4668)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6744  data: 0.6118  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.33, Acc@5 = 99.83, loss = 1.4681580474105063\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:22:40 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.74959935897436 train_acc5 99.74959935897436\n",
      "Epoch: [19]  [  0/468]  eta: 0:06:03  lr: 0.01  img/s: 691.5320564178528  loss: 1.4700 (1.4700)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.7764  data: 0.5912  max mem: 10434\n",
      "Epoch: [19]  [100/468]  eta: 0:01:06  lr: 0.01  img/s: 666.5064084419615  loss: 1.4625 (1.4644)  acc1: 100.0000 (99.7293)  acc5: 100.0000 (99.9613)  time: 0.1895  data: 0.0004  max mem: 10434\n",
      "Epoch: [19]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 886.4712306419628  loss: 1.4618 (1.4644)  acc1: 100.0000 (99.7124)  acc5: 100.0000 (99.9495)  time: 0.1877  data: 0.0003  max mem: 10434\n",
      "Epoch: [19]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 700.4378619636024  loss: 1.4631 (1.4642)  acc1: 100.0000 (99.7093)  acc5: 100.0000 (99.9559)  time: 0.1557  data: 0.0003  max mem: 10434\n",
      "Epoch: [19]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 829.4555516587692  loss: 1.4638 (1.4642)  acc1: 100.0000 (99.7097)  acc5: 100.0000 (99.9610)  time: 0.1888  data: 0.0004  max mem: 10434\n",
      "Epoch: [19] Total time: 0:01:21\n",
      "Test:  [ 0/79]  eta: 0:00:55  loss: 1.4639 (1.4639)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6984  data: 0.6281  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27, Acc@5 = 99.81, loss = 1.4685064705112312\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:24:07 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.70786591880342 train_acc5 99.70786591880342\n",
      "Epoch: [20]  [  0/468]  eta: 0:05:25  lr: 0.01  img/s: 1482.9500178162523  loss: 1.4627 (1.4627)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6966  data: 0.6102  max mem: 10434\n",
      "Epoch: [20]  [100/468]  eta: 0:01:04  lr: 0.01  img/s: 898.450531501861  loss: 1.4631 (1.4651)  acc1: 100.0000 (99.6906)  acc5: 100.0000 (99.9613)  time: 0.1719  data: 0.0004  max mem: 10434\n",
      "Epoch: [20]  [200/468]  eta: 0:00:46  lr: 0.01  img/s: 905.5121539841995  loss: 1.4626 (1.4645)  acc1: 100.0000 (99.7279)  acc5: 100.0000 (99.9650)  time: 0.1649  data: 0.0004  max mem: 10434\n",
      "Epoch: [20]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 1544.7166676737072  loss: 1.4674 (1.4649)  acc1: 99.2188 (99.6756)  acc5: 100.0000 (99.9585)  time: 0.1294  data: 0.0004  max mem: 10434\n",
      "Epoch: [20]  [400/468]  eta: 0:00:11  lr: 0.01  img/s: 663.4572232891169  loss: 1.4627 (1.4649)  acc1: 100.0000 (99.6630)  acc5: 100.0000 (99.9571)  time: 0.1435  data: 0.0004  max mem: 10434\n",
      "Epoch: [20] Total time: 0:01:16\n",
      "Test:  [ 0/79]  eta: 0:01:00  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7707  data: 0.7013  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.27, Acc@5 = 99.84, loss = 1.468048792851122\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:25:29 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.65277777777777 train_acc5 99.65277777777777\n",
      "Epoch: [21]  [  0/468]  eta: 0:06:13  lr: 0.01  img/s: 702.9415580249532  loss: 1.4625 (1.4625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7991  data: 0.6169  max mem: 10434\n",
      "Epoch: [21]  [100/468]  eta: 0:00:55  lr: 0.01  img/s: 1079.6127581789772  loss: 1.4627 (1.4644)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9691)  time: 0.1457  data: 0.0004  max mem: 10434\n",
      "Epoch: [21]  [200/468]  eta: 0:00:38  lr: 0.01  img/s: 870.900409600052  loss: 1.4627 (1.4646)  acc1: 100.0000 (99.6618)  acc5: 100.0000 (99.9611)  time: 0.1181  data: 0.0004  max mem: 10434\n",
      "Epoch: [21]  [300/468]  eta: 0:00:24  lr: 0.01  img/s: 923.0121017586147  loss: 1.4647 (1.4647)  acc1: 99.2188 (99.6444)  acc5: 100.0000 (99.9559)  time: 0.1585  data: 0.0004  max mem: 10434\n",
      "Epoch: [21]  [400/468]  eta: 0:00:09  lr: 0.01  img/s: 753.5654348921524  loss: 1.4629 (1.4648)  acc1: 100.0000 (99.6376)  acc5: 100.0000 (99.9454)  time: 0.1586  data: 0.0004  max mem: 10434\n",
      "Epoch: [21] Total time: 0:01:08\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4630 (1.4630)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6061  data: 0.5411  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4666231734843194\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:26:42 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.66780181623932 train_acc5 99.66780181623932\n",
      "Epoch: [22]  [  0/468]  eta: 0:05:54  lr: 0.01  img/s: 846.6352931529057  loss: 1.4615 (1.4615)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7582  data: 0.6070  max mem: 10434\n",
      "Epoch: [22]  [100/468]  eta: 0:00:54  lr: 0.01  img/s: 862.7647765914365  loss: 1.4621 (1.4637)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (99.9691)  time: 0.1257  data: 0.0003  max mem: 10434\n",
      "Epoch: [22]  [200/468]  eta: 0:00:39  lr: 0.01  img/s: 703.2850286097546  loss: 1.4632 (1.4640)  acc1: 100.0000 (99.7590)  acc5: 100.0000 (99.9572)  time: 0.1526  data: 0.0003  max mem: 10434\n",
      "Epoch: [22]  [300/468]  eta: 0:00:24  lr: 0.01  img/s: 763.7572119146321  loss: 1.4617 (1.4641)  acc1: 100.0000 (99.7612)  acc5: 100.0000 (99.9585)  time: 0.1532  data: 0.0004  max mem: 10434\n",
      "Epoch: [22]  [400/468]  eta: 0:00:09  lr: 0.01  img/s: 1402.2020439984642  loss: 1.4630 (1.4639)  acc1: 100.0000 (99.7682)  acc5: 100.0000 (99.9591)  time: 0.1488  data: 0.0004  max mem: 10434\n",
      "Epoch: [22] Total time: 0:01:08\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4633  data: 0.3949  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.03, Acc@5 = 99.83, loss = 1.470467058918144\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:27:56 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.75293803418803 train_acc5 99.75293803418803\n",
      "Epoch: [23]  [  0/468]  eta: 0:06:02  lr: 0.01  img/s: 923.2359065192344  loss: 1.4664 (1.4664)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7737  data: 0.6350  max mem: 10434\n",
      "Epoch: [23]  [100/468]  eta: 0:00:54  lr: 0.01  img/s: 895.6745567263482  loss: 1.4629 (1.4646)  acc1: 100.0000 (99.7215)  acc5: 100.0000 (99.9691)  time: 0.1422  data: 0.0004  max mem: 10434\n",
      "Epoch: [23]  [200/468]  eta: 0:00:37  lr: 0.01  img/s: 919.9816165067593  loss: 1.4649 (1.4653)  acc1: 99.2188 (99.6618)  acc5: 100.0000 (99.9495)  time: 0.1415  data: 0.0003  max mem: 10434\n",
      "Epoch: [23]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 1546.924315026062  loss: 1.4625 (1.4654)  acc1: 100.0000 (99.6444)  acc5: 100.0000 (99.9585)  time: 0.1017  data: 0.0003  max mem: 10434\n",
      "Epoch: [23]  [400/468]  eta: 0:00:09  lr: 0.01  img/s: 899.9973379154269  loss: 1.4633 (1.4652)  acc1: 100.0000 (99.6552)  acc5: 100.0000 (99.9610)  time: 0.1421  data: 0.0003  max mem: 10434\n",
      "Epoch: [23] Total time: 0:01:02\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4705 (1.4705)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.6058  data: 0.5569  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.19, Acc@5 = 99.86, loss = 1.468261748929567\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:29:03 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.65110844017094 train_acc5 99.65110844017094\n",
      "Epoch: [24]  [  0/468]  eta: 0:04:07  lr: 0.01  img/s: 876.3393701571424  loss: 1.4614 (1.4614)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5289  data: 0.3827  max mem: 10434\n",
      "Epoch: [24]  [100/468]  eta: 0:00:48  lr: 0.01  img/s: 1549.3081613630263  loss: 1.4618 (1.4648)  acc1: 100.0000 (99.6364)  acc5: 100.0000 (99.9845)  time: 0.1135  data: 0.0002  max mem: 10434\n",
      "Epoch: [24]  [200/468]  eta: 0:00:35  lr: 0.01  img/s: 901.1378753545831  loss: 1.4621 (1.4643)  acc1: 100.0000 (99.6774)  acc5: 100.0000 (99.9689)  time: 0.1211  data: 0.0003  max mem: 10434\n",
      "Epoch: [24]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 889.1005372319637  loss: 1.4639 (1.4642)  acc1: 99.2188 (99.6885)  acc5: 100.0000 (99.9689)  time: 0.1443  data: 0.0002  max mem: 10434\n",
      "Epoch: [24]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 869.8801836747259  loss: 1.4627 (1.4642)  acc1: 100.0000 (99.7019)  acc5: 100.0000 (99.9669)  time: 0.1452  data: 0.0002  max mem: 10434\n",
      "Epoch: [24] Total time: 0:01:01\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4713 (1.4713)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.5854  data: 0.5358  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.24, Acc@5 = 99.87, loss = 1.4681093285355387\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:30:09 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.68783386752136 train_acc5 99.68783386752136\n",
      "Epoch: [25]  [  0/468]  eta: 0:05:25  lr: 0.01  img/s: 927.1565233459575  loss: 1.4624 (1.4624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6954  data: 0.5572  max mem: 10434\n",
      "Epoch: [25]  [100/468]  eta: 0:00:51  lr: 0.01  img/s: 887.4574132909279  loss: 1.4626 (1.4648)  acc1: 100.0000 (99.7061)  acc5: 100.0000 (99.9691)  time: 0.1440  data: 0.0002  max mem: 10434\n",
      "Epoch: [25]  [200/468]  eta: 0:00:36  lr: 0.01  img/s: 881.4195942196494  loss: 1.4619 (1.4643)  acc1: 100.0000 (99.7396)  acc5: 100.0000 (99.9650)  time: 0.1426  data: 0.0003  max mem: 10434\n",
      "Epoch: [25]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 1549.0667643842494  loss: 1.4627 (1.4639)  acc1: 100.0000 (99.7768)  acc5: 100.0000 (99.9714)  time: 0.1300  data: 0.0003  max mem: 10434\n",
      "Epoch: [25]  [400/468]  eta: 0:00:09  lr: 0.01  img/s: 884.234462471939  loss: 1.4633 (1.4641)  acc1: 100.0000 (99.7643)  acc5: 100.0000 (99.9688)  time: 0.1144  data: 0.0003  max mem: 10434\n",
      "Epoch: [25] Total time: 0:01:02\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4720 (1.4720)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5733  data: 0.5236  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.37, Acc@5 = 99.85, loss = 1.4667397028283229\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:31:16 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.76796207264957 train_acc5 99.76796207264957\n",
      "Epoch: [26]  [  0/468]  eta: 0:04:18  lr: 0.01  img/s: 886.6366624058238  loss: 1.4627 (1.4627)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5520  data: 0.4076  max mem: 10434\n",
      "Epoch: [26]  [100/468]  eta: 0:00:51  lr: 0.01  img/s: 869.0381497500712  loss: 1.4637 (1.4635)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (99.9691)  time: 0.1458  data: 0.0003  max mem: 10434\n",
      "Epoch: [26]  [200/468]  eta: 0:00:35  lr: 0.01  img/s: 1293.5277030869017  loss: 1.4622 (1.4640)  acc1: 100.0000 (99.7512)  acc5: 100.0000 (99.9650)  time: 0.0927  data: 0.0003  max mem: 10434\n",
      "Epoch: [26]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 885.2273487249331  loss: 1.4623 (1.4638)  acc1: 100.0000 (99.7664)  acc5: 100.0000 (99.9740)  time: 0.1445  data: 0.0003  max mem: 10434\n",
      "Epoch: [26]  [400/468]  eta: 0:00:09  lr: 0.01  img/s: 967.4883801395537  loss: 1.4624 (1.4639)  acc1: 100.0000 (99.7545)  acc5: 100.0000 (99.9669)  time: 0.1419  data: 0.0002  max mem: 10434\n",
      "Epoch: [26] Total time: 0:01:02\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4628 (1.4628)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6045  data: 0.5543  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.28, Acc@5 = 99.87, loss = 1.4674017685878127\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:32:22 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.75460737179488 train_acc5 99.75460737179488\n",
      "Epoch: [27]  [  0/468]  eta: 0:04:12  lr: 0.01  img/s: 1466.8083155516333  loss: 1.4617 (1.4617)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5406  data: 0.4533  max mem: 10434\n",
      "Epoch: [27]  [100/468]  eta: 0:00:49  lr: 0.01  img/s: 882.3800603186864  loss: 1.4624 (1.4631)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (99.9845)  time: 0.1269  data: 0.0003  max mem: 10434\n",
      "Epoch: [27]  [200/468]  eta: 0:00:35  lr: 0.01  img/s: 882.4511280667208  loss: 1.4635 (1.4635)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (99.9806)  time: 0.1453  data: 0.0003  max mem: 10434\n",
      "Epoch: [27]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 881.5976222340819  loss: 1.4627 (1.4637)  acc1: 100.0000 (99.7664)  acc5: 100.0000 (99.9663)  time: 0.1435  data: 0.0003  max mem: 10434\n",
      "Epoch: [27]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 1546.0868032657058  loss: 1.4641 (1.4639)  acc1: 100.0000 (99.7604)  acc5: 100.0000 (99.9591)  time: 0.0951  data: 0.0003  max mem: 10434\n",
      "Epoch: [27] Total time: 0:01:02\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4707 (1.4707)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5928  data: 0.5597  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 98.98, Acc@5 = 99.76, loss = 1.4719759301294255\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:33:29 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.72622863247864 train_acc5 99.72622863247864\n",
      "Epoch: [28]  [  0/468]  eta: 0:05:38  lr: 0.01  img/s: 918.6985773004644  loss: 1.4706 (1.4706)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.7233  data: 0.5839  max mem: 10434\n",
      "Epoch: [28]  [100/468]  eta: 0:00:50  lr: 0.01  img/s: 934.9389217927977  loss: 1.4627 (1.4649)  acc1: 100.0000 (99.6132)  acc5: 100.0000 (99.9459)  time: 0.1407  data: 0.0003  max mem: 10434\n",
      "Epoch: [28]  [200/468]  eta: 0:00:36  lr: 0.01  img/s: 1050.3813429331665  loss: 1.4626 (1.4644)  acc1: 100.0000 (99.7007)  acc5: 100.0000 (99.9534)  time: 0.1445  data: 0.0003  max mem: 10434\n",
      "Epoch: [28]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 1550.2118323751663  loss: 1.4647 (1.4645)  acc1: 99.2188 (99.7015)  acc5: 100.0000 (99.9507)  time: 0.0917  data: 0.0003  max mem: 10434\n",
      "Epoch: [28]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 884.2650468262569  loss: 1.4638 (1.4644)  acc1: 100.0000 (99.7097)  acc5: 100.0000 (99.9513)  time: 0.1445  data: 0.0003  max mem: 10434\n",
      "Epoch: [28] Total time: 0:01:01\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4675 (1.4675)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5828  data: 0.5338  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.31, Acc@5 = 99.82, loss = 1.4684337151201465\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:34:35 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.71287393162393 train_acc5 99.71287393162393\n",
      "Epoch: [29]  [  0/468]  eta: 0:04:32  lr: 0.01  img/s: 919.2271019748445  loss: 1.4656 (1.4656)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5817  data: 0.4424  max mem: 10434\n",
      "Epoch: [29]  [100/468]  eta: 0:00:49  lr: 0.01  img/s: 1548.0930001874306  loss: 1.4636 (1.4654)  acc1: 100.0000 (99.6287)  acc5: 100.0000 (99.9304)  time: 0.1132  data: 0.0002  max mem: 10434\n",
      "Epoch: [29]  [200/468]  eta: 0:00:35  lr: 0.01  img/s: 878.3968952574796  loss: 1.4623 (1.4646)  acc1: 100.0000 (99.7007)  acc5: 100.0000 (99.9495)  time: 0.1245  data: 0.0002  max mem: 10434\n",
      "Epoch: [29]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 911.1119800152059  loss: 1.4649 (1.4645)  acc1: 100.0000 (99.7067)  acc5: 100.0000 (99.9507)  time: 0.1438  data: 0.0002  max mem: 10434\n",
      "Epoch: [29]  [400/468]  eta: 0:00:09  lr: 0.01  img/s: 890.8916567931473  loss: 1.4634 (1.4648)  acc1: 100.0000 (99.6785)  acc5: 100.0000 (99.9474)  time: 0.1449  data: 0.0003  max mem: 10434\n",
      "Epoch: [29] Total time: 0:01:01\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4655 (1.4655)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5674  data: 0.5161  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.16, Acc@5 = 99.77, loss = 1.46897014334232\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:35:41 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.66279380341881 train_acc5 99.66279380341881\n",
      "Epoch: [30]  [  0/468]  eta: 0:03:51  lr: 0.01  img/s: 868.1233387287424  loss: 1.4640 (1.4640)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4936  data: 0.3462  max mem: 10434\n",
      "Epoch: [30]  [100/468]  eta: 0:00:50  lr: 0.01  img/s: 884.3072858415869  loss: 1.4631 (1.4639)  acc1: 100.0000 (99.7293)  acc5: 100.0000 (99.9923)  time: 0.1442  data: 0.0003  max mem: 10434\n",
      "Epoch: [30]  [200/468]  eta: 0:00:36  lr: 0.01  img/s: 898.5031589059391  loss: 1.4630 (1.4641)  acc1: 100.0000 (99.7318)  acc5: 100.0000 (99.9689)  time: 0.1405  data: 0.0003  max mem: 10434\n",
      "Epoch: [30]  [300/468]  eta: 0:00:22  lr: 0.01  img/s: 1549.4467751059187  loss: 1.4640 (1.4648)  acc1: 100.0000 (99.6704)  acc5: 100.0000 (99.9507)  time: 0.1340  data: 0.0003  max mem: 10434\n",
      "Epoch: [30]  [400/468]  eta: 0:00:08  lr: 0.01  img/s: 886.3921965523106  loss: 1.4629 (1.4649)  acc1: 100.0000 (99.6766)  acc5: 100.0000 (99.9493)  time: 0.1041  data: 0.0003  max mem: 10434\n",
      "Epoch: [30] Total time: 0:01:01\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4697 (1.4697)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5719  data: 0.5323  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.4, Acc@5 = 99.84, loss = 1.4673941044867793\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:36:46 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.65945512820512 train_acc5 99.65945512820512\n",
      "Epoch: [31]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 1265.6467831404545  loss: 1.4651 (1.4651)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6088  data: 0.5076  max mem: 10434\n",
      "Epoch: [31]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1552.363403992008  loss: 1.4636 (1.4653)  acc1: 100.0000 (99.6442)  acc5: 100.0000 (99.9536)  time: 0.0829  data: 0.0002  max mem: 10434\n",
      "Epoch: [31]  [200/468]  eta: 0:00:22  lr: 0.01  img/s: 1549.5183273877556  loss: 1.4634 (1.4648)  acc1: 100.0000 (99.6852)  acc5: 100.0000 (99.9689)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [31]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1547.7627346346892  loss: 1.4623 (1.4647)  acc1: 100.0000 (99.6859)  acc5: 100.0000 (99.9585)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [31]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1549.7956549100209  loss: 1.4668 (1.4648)  acc1: 99.2188 (99.6883)  acc5: 100.0000 (99.9532)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [31] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:52  loss: 1.4685 (1.4685)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6665  data: 0.6354  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 98.91, Acc@5 = 99.88, loss = 1.4717153899277313\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:37:29 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.64443108974359 train_acc5 99.64443108974359\n",
      "Epoch: [32]  [  0/468]  eta: 0:05:00  lr: 0.01  img/s: 1211.020709598688  loss: 1.4627 (1.4627)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6414  data: 0.5357  max mem: 10434\n",
      "Epoch: [32]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1551.0314152158965  loss: 1.4634 (1.4652)  acc1: 100.0000 (99.6906)  acc5: 100.0000 (99.9459)  time: 0.0827  data: 0.0002  max mem: 10434\n",
      "Epoch: [32]  [200/468]  eta: 0:00:22  lr: 0.01  img/s: 1548.8969375243425  loss: 1.4654 (1.4660)  acc1: 99.2188 (99.5686)  acc5: 100.0000 (99.9378)  time: 0.0829  data: 0.0002  max mem: 10434\n",
      "Epoch: [32]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1549.8135504171357  loss: 1.4629 (1.4657)  acc1: 100.0000 (99.5977)  acc5: 100.0000 (99.9325)  time: 0.0827  data: 0.0002  max mem: 10434\n",
      "Epoch: [32]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1549.5585784504729  loss: 1.4626 (1.4654)  acc1: 100.0000 (99.6103)  acc5: 100.0000 (99.9338)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [32] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 1.4665 (1.4665)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5194  data: 0.4862  max mem: 10434\n",
      "Test: Total time: 0:00:02\n",
      " * Acc@1 = 99.31, Acc@5 = 99.83, loss = 1.467401315894308\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:38:12 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.63441506410257 train_acc5 99.63441506410257\n",
      "Epoch: [33]  [  0/468]  eta: 0:05:13  lr: 0.01  img/s: 1364.982728943829  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6704  data: 0.5766  max mem: 10434\n",
      "Epoch: [33]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1549.4512469299348  loss: 1.4633 (1.4645)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9923)  time: 0.0828  data: 0.0003  max mem: 10434\n",
      "Epoch: [33]  [200/468]  eta: 0:00:22  lr: 0.01  img/s: 1549.7867073114405  loss: 1.4630 (1.4648)  acc1: 100.0000 (99.6696)  acc5: 100.0000 (99.9650)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [33]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1549.7374973659673  loss: 1.4645 (1.4654)  acc1: 100.0000 (99.6159)  acc5: 100.0000 (99.9663)  time: 0.0829  data: 0.0003  max mem: 10434\n",
      "Epoch: [33]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1548.8075699222525  loss: 1.4632 (1.4652)  acc1: 100.0000 (99.6162)  acc5: 100.0000 (99.9669)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [33] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4768 (1.4768)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.5591  data: 0.5160  max mem: 10434\n",
      "Test: Total time: 0:00:02\n",
      " * Acc@1 = 99.14, Acc@5 = 99.82, loss = 1.4699395306502716\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:38:54 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.61271367521367 train_acc5 99.61271367521367\n",
      "Epoch: [34]  [  0/468]  eta: 0:04:43  lr: 0.01  img/s: 1254.4973256658964  loss: 1.4718 (1.4718)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.6057  data: 0.5036  max mem: 10434\n",
      "Epoch: [34]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1550.1312644547684  loss: 1.4634 (1.4642)  acc1: 99.2188 (99.6983)  acc5: 100.0000 (99.9613)  time: 0.0829  data: 0.0003  max mem: 10434\n",
      "Epoch: [34]  [200/468]  eta: 0:00:22  lr: 0.01  img/s: 1549.8269723186886  loss: 1.4625 (1.4638)  acc1: 100.0000 (99.7590)  acc5: 100.0000 (99.9767)  time: 0.0829  data: 0.0002  max mem: 10434\n",
      "Epoch: [34]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1554.4039352957698  loss: 1.4645 (1.4643)  acc1: 100.0000 (99.7197)  acc5: 100.0000 (99.9663)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [34]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1552.3589153428445  loss: 1.4615 (1.4640)  acc1: 100.0000 (99.7467)  acc5: 100.0000 (99.9630)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [34] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4652 (1.4652)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5979  data: 0.5636  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.26, Acc@5 = 99.86, loss = 1.467341181598132\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:39:37 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.75794604700855 train_acc5 99.75794604700855\n",
      "Epoch: [35]  [  0/468]  eta: 0:05:54  lr: 0.01  img/s: 1385.0837106465535  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7580  data: 0.6655  max mem: 10434\n",
      "Epoch: [35]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1551.7128207499725  loss: 1.4616 (1.4634)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (99.9845)  time: 0.0828  data: 0.0003  max mem: 10434\n",
      "Epoch: [35]  [200/468]  eta: 0:00:23  lr: 0.01  img/s: 1555.81386021549  loss: 1.4624 (1.4636)  acc1: 100.0000 (99.7785)  acc5: 100.0000 (99.9650)  time: 0.0827  data: 0.0002  max mem: 10434\n",
      "Epoch: [35]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1552.7899440629826  loss: 1.4633 (1.4636)  acc1: 100.0000 (99.7846)  acc5: 100.0000 (99.9689)  time: 0.0826  data: 0.0002  max mem: 10434\n",
      "Epoch: [35]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1551.793553160986  loss: 1.4633 (1.4638)  acc1: 100.0000 (99.7643)  acc5: 100.0000 (99.9630)  time: 0.0828  data: 0.0003  max mem: 10434\n",
      "Epoch: [35] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4709 (1.4709)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5696  data: 0.5367  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.29, Acc@5 = 99.79, loss = 1.4686172974260547\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:40:19 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.76295405982906 train_acc5 99.76295405982906\n",
      "Epoch: [36]  [  0/468]  eta: 0:04:49  lr: 0.01  img/s: 1411.269506883236  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6183  data: 0.5276  max mem: 10434\n",
      "Epoch: [36]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1549.0399471410888  loss: 1.4641 (1.4661)  acc1: 99.2188 (99.6519)  acc5: 100.0000 (99.9613)  time: 0.0829  data: 0.0002  max mem: 10434\n",
      "Epoch: [36]  [200/468]  eta: 0:00:22  lr: 0.01  img/s: 1549.4378315353224  loss: 1.4682 (1.4661)  acc1: 100.0000 (99.6385)  acc5: 100.0000 (99.9572)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [36]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1549.5406888311  loss: 1.4629 (1.4657)  acc1: 100.0000 (99.6548)  acc5: 100.0000 (99.9559)  time: 0.0830  data: 0.0002  max mem: 10434\n",
      "Epoch: [36]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1551.6141592101917  loss: 1.4627 (1.4654)  acc1: 100.0000 (99.6688)  acc5: 100.0000 (99.9571)  time: 0.0828  data: 0.0002  max mem: 10434\n",
      "Epoch: [36] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4629 (1.4629)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5610  data: 0.5254  max mem: 10434\n",
      "Test: Total time: 0:00:02\n",
      " * Acc@1 = 99.2, Acc@5 = 99.79, loss = 1.4687588018707083\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:41:02 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.68115651709402 train_acc5 99.68115651709402\n",
      "Epoch: [37]  [  0/468]  eta: 0:05:14  lr: 0.01  img/s: 1292.9015689532685  loss: 1.4688 (1.4688)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6728  data: 0.5737  max mem: 10434\n",
      "Epoch: [37]  [100/468]  eta: 0:00:32  lr: 0.01  img/s: 1550.2163086163087  loss: 1.4619 (1.4642)  acc1: 100.0000 (99.7138)  acc5: 100.0000 (99.9613)  time: 0.0831  data: 0.0003  max mem: 10434\n",
      "Epoch: [37]  [200/468]  eta: 0:00:22  lr: 0.01  img/s: 1547.2274683059118  loss: 1.4639 (1.4645)  acc1: 100.0000 (99.7007)  acc5: 100.0000 (99.9611)  time: 0.0829  data: 0.0002  max mem: 10434\n",
      "Epoch: [37]  [300/468]  eta: 0:00:14  lr: 0.01  img/s: 1550.0059532230264  loss: 1.4639 (1.4648)  acc1: 99.2188 (99.6652)  acc5: 100.0000 (99.9403)  time: 0.0827  data: 0.0003  max mem: 10434\n",
      "Epoch: [37]  [400/468]  eta: 0:00:05  lr: 0.01  img/s: 1548.2492559695468  loss: 1.4624 (1.4647)  acc1: 100.0000 (99.6863)  acc5: 100.0000 (99.9454)  time: 0.0829  data: 0.0002  max mem: 10434\n",
      "Epoch: [37] Total time: 0:00:39\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4621 (1.4621)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5710  data: 0.5323  max mem: 10434\n",
      "Test: Total time: 0:00:03\n",
      " * Acc@1 = 99.27, Acc@5 = 99.82, loss = 1.468138666092595\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:41:44 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.69618055555556 train_acc5 99.69618055555556\n",
      "Epoch: [38]  [  0/468]  eta: 0:05:13  lr: 0.01  img/s: 1217.9743460604823  loss: 1.4615 (1.4615)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6705  data: 0.5653  max mem: 10434\n",
      "Epoch: [38]  [100/468]  eta: 0:00:33  lr: 0.01  img/s: 1407.3738747476866  loss: 1.4618 (1.4640)  acc1: 100.0000 (99.7602)  acc5: 100.0000 (99.9459)  time: 0.0884  data: 0.0003  max mem: 10434\n",
      "Epoch: [38]  [200/468]  eta: 0:00:27  lr: 0.01  img/s: 1048.230002206303  loss: 1.4645 (1.4643)  acc1: 100.0000 (99.7201)  acc5: 100.0000 (99.9378)  time: 0.1204  data: 0.0002  max mem: 10434\n",
      "Epoch: [38]  [300/468]  eta: 0:00:16  lr: 0.01  img/s: 1388.90346481504  loss: 1.4654 (1.4644)  acc1: 100.0000 (99.7093)  acc5: 100.0000 (99.9559)  time: 0.0933  data: 0.0002  max mem: 10434\n",
      "Epoch: [38]  [400/468]  eta: 0:00:07  lr: 0.01  img/s: 1063.9323675709954  loss: 1.4619 (1.4644)  acc1: 100.0000 (99.7000)  acc5: 100.0000 (99.9571)  time: 0.1214  data: 0.0002  max mem: 10434\n",
      "Epoch: [38] Total time: 0:00:49\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4699 (1.4699)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6319  data: 0.5838  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.17, Acc@5 = 99.77, loss = 1.4689817172062547\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:42:38 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.6895032051282 train_acc5 99.6895032051282\n",
      "Epoch: [39]  [  0/468]  eta: 0:05:19  lr: 0.01  img/s: 1052.3579112435314  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6824  data: 0.5607  max mem: 10434\n",
      "Epoch: [39]  [100/468]  eta: 0:00:44  lr: 0.01  img/s: 1044.1485653605512  loss: 1.4645 (1.4645)  acc1: 99.2188 (99.6597)  acc5: 100.0000 (99.9613)  time: 0.1116  data: 0.0002  max mem: 10434\n",
      "Epoch: [39]  [200/468]  eta: 0:00:42  lr: 0.01  img/s: 553.934875850577  loss: 1.4629 (1.4654)  acc1: 100.0000 (99.6385)  acc5: 100.0000 (99.9495)  time: 0.2308  data: 0.0003  max mem: 10434\n",
      "Epoch: [39]  [300/468]  eta: 0:00:30  lr: 0.01  img/s: 544.9077565006278  loss: 1.4641 (1.4658)  acc1: 100.0000 (99.6340)  acc5: 100.0000 (99.9481)  time: 0.2367  data: 0.0002  max mem: 10434\n",
      "Epoch: [39]  [400/468]  eta: 0:00:13  lr: 0.01  img/s: 491.56035331269567  loss: 1.4625 (1.4656)  acc1: 100.0000 (99.6357)  acc5: 100.0000 (99.9493)  time: 0.2304  data: 0.0002  max mem: 10434\n",
      "Epoch: [39] Total time: 0:01:33\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4696 (1.4696)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.3931  data: 0.3301  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.27, Acc@5 = 99.74, loss = 1.4681744469872005\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:44:18 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.63942307692308 train_acc5 99.63942307692308\n",
      "Epoch: [40]  [  0/468]  eta: 0:05:42  lr: 0.01  img/s: 555.3645515671874  loss: 1.4624 (1.4624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7324  data: 0.5019  max mem: 10434\n",
      "Epoch: [40]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 1058.445174340432  loss: 1.4622 (1.4644)  acc1: 100.0000 (99.7447)  acc5: 100.0000 (99.9691)  time: 0.2196  data: 0.0003  max mem: 10434\n",
      "Epoch: [40]  [200/468]  eta: 0:00:50  lr: 0.01  img/s: 954.5305087608566  loss: 1.4623 (1.4640)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (99.9689)  time: 0.2133  data: 0.0002  max mem: 10434\n",
      "Epoch: [40]  [300/468]  eta: 0:00:33  lr: 0.01  img/s: 553.2310609339385  loss: 1.4692 (1.4648)  acc1: 100.0000 (99.7560)  acc5: 100.0000 (99.9481)  time: 0.2230  data: 0.0003  max mem: 10434\n",
      "Epoch: [40]  [400/468]  eta: 0:00:14  lr: 0.01  img/s: 555.1107407185294  loss: 1.4625 (1.4648)  acc1: 100.0000 (99.7526)  acc5: 100.0000 (99.9571)  time: 0.2317  data: 0.0003  max mem: 10434\n",
      "Epoch: [40] Total time: 0:01:38\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4618 (1.4618)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4876  data: 0.4053  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.11, Acc@5 = 99.7, loss = 1.4697165836261799\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:46:04 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.74793002136752 train_acc5 99.74793002136752\n",
      "Epoch: [41]  [  0/468]  eta: 0:04:25  lr: 0.01  img/s: 717.659349326147  loss: 1.4623 (1.4623)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5681  data: 0.3897  max mem: 10434\n",
      "Epoch: [41]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 553.2544356014662  loss: 1.4621 (1.4632)  acc1: 100.0000 (99.8453)  acc5: 100.0000 (99.9923)  time: 0.2307  data: 0.0003  max mem: 10434\n",
      "Epoch: [41]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 535.1296002806866  loss: 1.4617 (1.4632)  acc1: 100.0000 (99.8368)  acc5: 100.0000 (99.9767)  time: 0.2361  data: 0.0003  max mem: 10434\n",
      "Epoch: [41]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 711.4170966673292  loss: 1.4625 (1.4634)  acc1: 100.0000 (99.8313)  acc5: 100.0000 (99.9689)  time: 0.2169  data: 0.0003  max mem: 10434\n",
      "Epoch: [41]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 552.6393711778167  loss: 1.4650 (1.4639)  acc1: 99.2188 (99.7896)  acc5: 100.0000 (99.9532)  time: 0.2305  data: 0.0003  max mem: 10434\n",
      "Epoch: [41] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4617 (1.4617)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4749  data: 0.3955  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.09, Acc@5 = 99.71, loss = 1.4691499049150492\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:47:58 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.75794604700855 train_acc5 99.75794604700855\n",
      "Epoch: [42]  [  0/468]  eta: 0:04:30  lr: 0.01  img/s: 565.8957025856163  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5789  data: 0.3527  max mem: 10434\n",
      "Epoch: [42]  [100/468]  eta: 0:01:24  lr: 0.01  img/s: 574.690734550001  loss: 1.4649 (1.4668)  acc1: 100.0000 (99.7912)  acc5: 100.0000 (99.9381)  time: 0.2176  data: 0.0003  max mem: 10434\n",
      "Epoch: [42]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 547.6553409744693  loss: 1.4626 (1.4658)  acc1: 100.0000 (99.7512)  acc5: 100.0000 (99.9611)  time: 0.2340  data: 0.0003  max mem: 10434\n",
      "Epoch: [42]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 555.944822929902  loss: 1.4625 (1.4656)  acc1: 100.0000 (99.7067)  acc5: 100.0000 (99.9481)  time: 0.2365  data: 0.0002  max mem: 10434\n",
      "Epoch: [42]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 551.6467707546636  loss: 1.4639 (1.4653)  acc1: 100.0000 (99.7175)  acc5: 100.0000 (99.9591)  time: 0.2242  data: 0.0002  max mem: 10434\n",
      "Epoch: [42] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 1.4669 (1.4669)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5307  data: 0.4503  max mem: 10434\n",
      "Test: Total time: 0:00:07\n",
      " * Acc@1 = 99.4, Acc@5 = 99.82, loss = 1.4670897586436211\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:49:52 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.70452724358974 train_acc5 99.70452724358974\n",
      "Epoch: [43]  [  0/468]  eta: 0:05:51  lr: 0.01  img/s: 556.2397358417454  loss: 1.4691 (1.4691)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.7517  data: 0.5215  max mem: 10434\n",
      "Epoch: [43]  [100/468]  eta: 0:01:26  lr: 0.01  img/s: 555.4352234741774  loss: 1.4634 (1.4654)  acc1: 100.0000 (99.6674)  acc5: 100.0000 (99.9304)  time: 0.2235  data: 0.0002  max mem: 10434\n",
      "Epoch: [43]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 551.7646964513102  loss: 1.4623 (1.4647)  acc1: 100.0000 (99.7201)  acc5: 100.0000 (99.9495)  time: 0.2322  data: 0.0003  max mem: 10434\n",
      "Epoch: [43]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 544.5949014878015  loss: 1.4630 (1.4645)  acc1: 100.0000 (99.7223)  acc5: 100.0000 (99.9507)  time: 0.2381  data: 0.0002  max mem: 10434\n",
      "Epoch: [43]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 556.8328114579563  loss: 1.4635 (1.4651)  acc1: 100.0000 (99.6805)  acc5: 100.0000 (99.9513)  time: 0.2233  data: 0.0002  max mem: 10434\n",
      "Epoch: [43] Total time: 0:01:47\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4614 (1.4614)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4843  data: 0.4027  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.26, Acc@5 = 99.76, loss = 1.4682237724714642\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:51:46 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.69284188034187 train_acc5 99.69284188034187\n",
      "Epoch: [44]  [  0/468]  eta: 0:05:22  lr: 0.01  img/s: 535.5497108633002  loss: 1.4620 (1.4620)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6886  data: 0.4495  max mem: 10434\n",
      "Epoch: [44]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 555.0539234792569  loss: 1.4626 (1.4634)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (99.9768)  time: 0.2182  data: 0.0002  max mem: 10434\n",
      "Epoch: [44]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 550.8752629343162  loss: 1.4622 (1.4635)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (99.9689)  time: 0.2327  data: 0.0002  max mem: 10434\n",
      "Epoch: [44]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 540.131143582665  loss: 1.4664 (1.4638)  acc1: 100.0000 (99.7768)  acc5: 100.0000 (99.9637)  time: 0.2362  data: 0.0003  max mem: 10434\n",
      "Epoch: [44]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 556.1135531666732  loss: 1.4689 (1.4644)  acc1: 99.2188 (99.7195)  acc5: 100.0000 (99.9474)  time: 0.2188  data: 0.0003  max mem: 10434\n",
      "Epoch: [44] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4633 (1.4633)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6068  data: 0.5214  max mem: 10434\n",
      "Test: Total time: 0:00:07\n",
      " * Acc@1 = 99.13, Acc@5 = 99.72, loss = 1.469969660420961\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:53:40 max_test_acc1 99.44 test_acc5_at_max_test_acc1 99.94 train_acc1 99.67280982905983 train_acc5 99.67280982905983\n",
      "Epoch: [45]  [  0/468]  eta: 0:05:38  lr: 0.01  img/s: 564.7717668246725  loss: 1.4661 (1.4661)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.7236  data: 0.4969  max mem: 10434\n",
      "Epoch: [45]  [100/468]  eta: 0:01:26  lr: 0.01  img/s: 656.0607484801271  loss: 1.4639 (1.4651)  acc1: 99.2188 (99.5668)  acc5: 100.0000 (99.9536)  time: 0.2277  data: 0.0002  max mem: 10434\n",
      "Epoch: [45]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 552.5068560255223  loss: 1.4646 (1.4666)  acc1: 100.0000 (99.5569)  acc5: 100.0000 (99.9417)  time: 0.2239  data: 0.0003  max mem: 10434\n",
      "Epoch: [45]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 550.2835225793491  loss: 1.4636 (1.4666)  acc1: 100.0000 (99.5795)  acc5: 100.0000 (99.9377)  time: 0.2344  data: 0.0002  max mem: 10434\n",
      "Epoch: [45]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 546.4284927669873  loss: 1.4658 (1.4664)  acc1: 99.2188 (99.5675)  acc5: 100.0000 (99.9318)  time: 0.2233  data: 0.0002  max mem: 10434\n",
      "Epoch: [45] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4703  data: 0.3876  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:55:34 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.5960202991453 train_acc5 99.5960202991453\n",
      "Epoch: [46]  [  0/468]  eta: 0:04:30  lr: 0.01  img/s: 544.8369733879045  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5777  data: 0.3427  max mem: 10434\n",
      "Epoch: [46]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 555.4168355560521  loss: 1.4630 (1.4643)  acc1: 100.0000 (99.7293)  acc5: 100.0000 (99.9691)  time: 0.2318  data: 0.0002  max mem: 10434\n",
      "Epoch: [46]  [200/468]  eta: 0:01:00  lr: 0.01  img/s: 1020.0601391187373  loss: 1.4628 (1.4642)  acc1: 100.0000 (99.7474)  acc5: 100.0000 (99.9650)  time: 0.2152  data: 0.0003  max mem: 10434\n",
      "Epoch: [46]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 552.3903179837536  loss: 1.4708 (1.4646)  acc1: 99.2188 (99.7041)  acc5: 100.0000 (99.9429)  time: 0.2328  data: 0.0002  max mem: 10434\n",
      "Epoch: [46]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 717.5289045229891  loss: 1.4632 (1.4647)  acc1: 100.0000 (99.7000)  acc5: 100.0000 (99.9396)  time: 0.2208  data: 0.0002  max mem: 10434\n",
      "Epoch: [46] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4666 (1.4666)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4794  data: 0.4124  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.07, Acc@5 = 99.75, loss = 1.4718069034286692\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:57:28 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.69117254273505 train_acc5 99.69117254273505\n",
      "Epoch: [47]  [  0/468]  eta: 0:04:40  lr: 0.01  img/s: 543.7273134222546  loss: 1.4642 (1.4642)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5983  data: 0.3629  max mem: 10434\n",
      "Epoch: [47]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 555.5633980922105  loss: 1.4630 (1.4649)  acc1: 100.0000 (99.6983)  acc5: 100.0000 (99.9226)  time: 0.2317  data: 0.0002  max mem: 10434\n",
      "Epoch: [47]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 1035.7385067117332  loss: 1.4623 (1.4643)  acc1: 100.0000 (99.7707)  acc5: 100.0000 (99.9378)  time: 0.2202  data: 0.0002  max mem: 10434\n",
      "Epoch: [47]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 551.8509048110973  loss: 1.4617 (1.4638)  acc1: 100.0000 (99.8079)  acc5: 100.0000 (99.9559)  time: 0.2356  data: 0.0003  max mem: 10434\n",
      "Epoch: [47]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 547.5497752670329  loss: 1.4633 (1.4642)  acc1: 100.0000 (99.7779)  acc5: 100.0000 (99.9552)  time: 0.2230  data: 0.0002  max mem: 10434\n",
      "Epoch: [47] Total time: 0:01:47\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4704 (1.4704)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4169  data: 0.3345  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.22, Acc@5 = 99.82, loss = 1.4688025833685188\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 0:59:22 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.76629273504274 train_acc5 99.76629273504274\n",
      "Epoch: [48]  [  0/468]  eta: 0:04:50  lr: 0.01  img/s: 544.0309027105739  loss: 1.4615 (1.4615)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6200  data: 0.3847  max mem: 10434\n",
      "Epoch: [48]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 640.5351150138398  loss: 1.4632 (1.4645)  acc1: 100.0000 (99.6983)  acc5: 100.0000 (99.9459)  time: 0.2251  data: 0.0002  max mem: 10434\n",
      "Epoch: [48]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 1032.5453304074053  loss: 1.4671 (1.4650)  acc1: 100.0000 (99.6891)  acc5: 100.0000 (99.9339)  time: 0.2250  data: 0.0002  max mem: 10434\n",
      "Epoch: [48]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 550.567941242224  loss: 1.4631 (1.4654)  acc1: 100.0000 (99.6859)  acc5: 100.0000 (99.9429)  time: 0.2343  data: 0.0002  max mem: 10434\n",
      "Epoch: [48]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 710.6016444390324  loss: 1.4635 (1.4651)  acc1: 100.0000 (99.6902)  acc5: 100.0000 (99.9493)  time: 0.2164  data: 0.0003  max mem: 10434\n",
      "Epoch: [48] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4680 (1.4680)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4870  data: 0.3999  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.25, Acc@5 = 99.8, loss = 1.4701493586165995\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:01:15 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.66780181623932 train_acc5 99.66780181623932\n",
      "Epoch: [49]  [  0/468]  eta: 0:04:14  lr: 0.01  img/s: 540.8090837478519  loss: 1.4682 (1.4682)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5447  data: 0.3079  max mem: 10434\n",
      "Epoch: [49]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 552.9831830031632  loss: 1.4632 (1.4653)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (99.9768)  time: 0.2311  data: 0.0003  max mem: 10434\n",
      "Epoch: [49]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 545.9039852438297  loss: 1.4619 (1.4651)  acc1: 100.0000 (99.7201)  acc5: 100.0000 (99.9572)  time: 0.2220  data: 0.0002  max mem: 10434\n",
      "Epoch: [49]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 539.9529635157479  loss: 1.4649 (1.4653)  acc1: 100.0000 (99.7119)  acc5: 100.0000 (99.9507)  time: 0.2364  data: 0.0003  max mem: 10434\n",
      "Epoch: [49]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 549.3190305513235  loss: 1.4627 (1.4652)  acc1: 100.0000 (99.6863)  acc5: 100.0000 (99.9571)  time: 0.2365  data: 0.0002  max mem: 10434\n",
      "Epoch: [49] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4734 (1.4734)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4657  data: 0.3799  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.09, Acc@5 = 99.73, loss = 1.4696009928667093\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:03:09 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.65611645299145 train_acc5 99.65611645299145\n",
      "Epoch: [50]  [  0/468]  eta: 0:05:10  lr: 0.01  img/s: 564.2695860187252  loss: 1.4684 (1.4684)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6643  data: 0.4374  max mem: 10434\n",
      "Epoch: [50]  [100/468]  eta: 0:01:26  lr: 0.01  img/s: 551.3782244638688  loss: 1.4663 (1.4682)  acc1: 100.0000 (99.6519)  acc5: 100.0000 (99.9613)  time: 0.2306  data: 0.0002  max mem: 10434\n",
      "Epoch: [50]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 711.4236957077718  loss: 1.4629 (1.4664)  acc1: 100.0000 (99.6696)  acc5: 100.0000 (99.9572)  time: 0.2256  data: 0.0003  max mem: 10434\n",
      "Epoch: [50]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 535.8570704227601  loss: 1.4624 (1.4658)  acc1: 100.0000 (99.6808)  acc5: 100.0000 (99.9481)  time: 0.2322  data: 0.0002  max mem: 10434\n",
      "Epoch: [50]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 552.475016362132  loss: 1.4652 (1.4656)  acc1: 100.0000 (99.6824)  acc5: 100.0000 (99.9552)  time: 0.2304  data: 0.0003  max mem: 10434\n",
      "Epoch: [50] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4644 (1.4644)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4561  data: 0.3712  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.35, Acc@5 = 99.81, loss = 1.467716526381577\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:05:03 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.68282585470085 train_acc5 99.68282585470085\n",
      "Epoch: [51]  [  0/468]  eta: 0:04:26  lr: 0.01  img/s: 559.9106764241785  loss: 1.4624 (1.4624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5699  data: 0.3413  max mem: 10434\n",
      "Epoch: [51]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 557.1980542158484  loss: 1.4642 (1.4636)  acc1: 100.0000 (99.8298)  acc5: 100.0000 (100.0000)  time: 0.2309  data: 0.0004  max mem: 10434\n",
      "Epoch: [51]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 551.6564070209762  loss: 1.4620 (1.4639)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (99.9883)  time: 0.2353  data: 0.0002  max mem: 10434\n",
      "Epoch: [51]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 554.5774611805733  loss: 1.4624 (1.4638)  acc1: 100.0000 (99.8053)  acc5: 100.0000 (99.9766)  time: 0.2236  data: 0.0002  max mem: 10434\n",
      "Epoch: [51]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 555.3335305568945  loss: 1.4707 (1.4646)  acc1: 100.0000 (99.7798)  acc5: 100.0000 (99.9727)  time: 0.2349  data: 0.0002  max mem: 10434\n",
      "Epoch: [51] Total time: 0:01:46\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4630 (1.4630)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4169  data: 0.3345  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 99.21, Acc@5 = 99.76, loss = 1.4686871540697315\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:06:56 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.75794604700855 train_acc5 99.75794604700855\n",
      "Epoch: [52]  [  0/468]  eta: 0:04:44  lr: 0.01  img/s: 556.9957245227308  loss: 1.4623 (1.4623)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6085  data: 0.3786  max mem: 10434\n",
      "Epoch: [52]  [100/468]  eta: 0:01:25  lr: 0.01  img/s: 535.736222680363  loss: 1.4626 (1.4642)  acc1: 100.0000 (99.7447)  acc5: 100.0000 (99.9845)  time: 0.2340  data: 0.0002  max mem: 10434\n",
      "Epoch: [52]  [200/468]  eta: 0:01:01  lr: 0.01  img/s: 536.8199141081598  loss: 1.4650 (1.4645)  acc1: 100.0000 (99.7396)  acc5: 100.0000 (99.9650)  time: 0.2364  data: 0.0002  max mem: 10434\n",
      "Epoch: [52]  [300/468]  eta: 0:00:38  lr: 0.01  img/s: 547.5145957412091  loss: 1.4640 (1.4648)  acc1: 100.0000 (99.7093)  acc5: 100.0000 (99.9611)  time: 0.2259  data: 0.0003  max mem: 10434\n",
      "Epoch: [52]  [400/468]  eta: 0:00:15  lr: 0.01  img/s: 539.6615016249024  loss: 1.4629 (1.4646)  acc1: 100.0000 (99.7409)  acc5: 100.0000 (99.9649)  time: 0.2370  data: 0.0002  max mem: 10434\n",
      "Epoch: [52] Total time: 0:01:47\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4838 (1.4838)  acc1: 97.6562 (97.6562)  acc5: 98.4375 (98.4375)  time: 0.4865  data: 0.3980  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 98.46, Acc@5 = 99.5, loss = 1.4760558273218856\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:08:51 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73624465811966 train_acc5 99.73624465811966\n",
      "Epoch: [53]  [  0/468]  eta: 0:04:26  lr: 0.01  img/s: 558.4598529971644  loss: 1.4781 (1.4781)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.5697  data: 0.3405  max mem: 10434\n",
      "Epoch: [53]  [100/468]  eta: 0:01:26  lr: 0.01  img/s: 553.6749466302274  loss: 1.4632 (1.4649)  acc1: 100.0000 (99.6674)  acc5: 100.0000 (99.9459)  time: 0.2341  data: 0.0003  max mem: 10434\n",
      "Epoch: [53]  [200/468]  eta: 0:00:58  lr: 0.01  img/s: 702.1196976889869  loss: 1.4624 (1.4646)  acc1: 100.0000 (99.7007)  acc5: 100.0000 (99.9495)  time: 0.1969  data: 0.0003  max mem: 10434\n",
      "Epoch: [53]  [300/468]  eta: 0:00:34  lr: 0.01  img/s: 712.1928503584372  loss: 1.4654 (1.4647)  acc1: 99.2188 (99.6885)  acc5: 100.0000 (99.9325)  time: 0.1961  data: 0.0003  max mem: 10434\n",
      "Epoch: [53]  [400/468]  eta: 0:00:13  lr: 0.01  img/s: 703.3237246081007  loss: 1.4646 (1.4648)  acc1: 100.0000 (99.6824)  acc5: 100.0000 (99.9357)  time: 0.1966  data: 0.0003  max mem: 10434\n",
      "Epoch: [53] Total time: 0:01:35\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4825 (1.4825)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.4838  data: 0.4155  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.83, loss = 1.4775604432142233\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:10:32 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.65277777777777 train_acc5 99.65277777777777\n",
      "Epoch: [54]  [  0/468]  eta: 0:04:46  lr: 0.01  img/s: 497.3979111676467  loss: 1.4712 (1.4712)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6121  data: 0.3547  max mem: 10434\n",
      "Epoch: [54]  [100/468]  eta: 0:01:14  lr: 0.01  img/s: 502.02204752683  loss: 1.4663 (1.4678)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (99.9691)  time: 0.2029  data: 0.0002  max mem: 10434\n",
      "Epoch: [54]  [200/468]  eta: 0:00:53  lr: 0.01  img/s: 701.0158843737718  loss: 1.4630 (1.4664)  acc1: 100.0000 (99.7746)  acc5: 100.0000 (99.9611)  time: 0.1984  data: 0.0003  max mem: 10434\n",
      "Epoch: [54]  [300/468]  eta: 0:00:33  lr: 0.01  img/s: 525.4265953271787  loss: 1.4627 (1.4664)  acc1: 100.0000 (99.7301)  acc5: 100.0000 (99.9507)  time: 0.1994  data: 0.0002  max mem: 10434\n",
      "Epoch: [54]  [400/468]  eta: 0:00:13  lr: 0.01  img/s: 616.3555010613737  loss: 1.4627 (1.4661)  acc1: 100.0000 (99.7175)  acc5: 100.0000 (99.9552)  time: 0.1985  data: 0.0003  max mem: 10434\n",
      "Epoch: [54] Total time: 0:01:32\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4705 (1.4705)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4864  data: 0.4060  max mem: 10434\n",
      "Test: Total time: 0:00:06\n",
      " * Acc@1 = 98.99, Acc@5 = 99.68, loss = 1.4706627749189545\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:12:11 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73457532051282 train_acc5 99.73457532051282\n",
      "Epoch: [55]  [  0/468]  eta: 0:04:22  lr: 0.01  img/s: 568.8330735708738  loss: 1.4641 (1.4641)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5612  data: 0.3361  max mem: 10434\n",
      "Epoch: [55]  [100/468]  eta: 0:01:11  lr: 0.01  img/s: 711.4340658758176  loss: 1.4633 (1.4645)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (99.9691)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [55]  [200/468]  eta: 0:00:49  lr: 0.01  img/s: 708.6357027079824  loss: 1.4639 (1.4646)  acc1: 100.0000 (99.7357)  acc5: 100.0000 (99.9728)  time: 0.1750  data: 0.0003  max mem: 10434\n",
      "Epoch: [55]  [300/468]  eta: 0:00:30  lr: 0.01  img/s: 711.6283267013597  loss: 1.4636 (1.4647)  acc1: 100.0000 (99.7223)  acc5: 100.0000 (99.9792)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [55]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.8189185175756  loss: 1.4648 (1.4648)  acc1: 100.0000 (99.7058)  acc5: 100.0000 (99.9708)  time: 0.1801  data: 0.0003  max mem: 10434\n",
      "Epoch: [55] Total time: 0:01:24\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4726 (1.4726)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.6294  data: 0.5638  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.36, Acc@5 = 99.82, loss = 1.4719234780420232\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:13:41 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.71120459401709 train_acc5 99.71120459401709\n",
      "Epoch: [56]  [  0/468]  eta: 0:04:19  lr: 0.01  img/s: 709.1879918945552  loss: 1.4657 (1.4657)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5549  data: 0.3744  max mem: 10434\n",
      "Epoch: [56]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.6802104004528  loss: 1.4640 (1.4643)  acc1: 100.0000 (99.8376)  acc5: 100.0000 (99.9536)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [56]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 713.1663458639026  loss: 1.4622 (1.4638)  acc1: 100.0000 (99.8678)  acc5: 100.0000 (99.9689)  time: 0.1689  data: 0.0002  max mem: 10434\n",
      "Epoch: [56]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 715.5912604898647  loss: 1.4637 (1.4638)  acc1: 100.0000 (99.8572)  acc5: 100.0000 (99.9740)  time: 0.1801  data: 0.0004  max mem: 10434\n",
      "Epoch: [56]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 712.0672183309216  loss: 1.4672 (1.4641)  acc1: 100.0000 (99.8363)  acc5: 100.0000 (99.9727)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [56] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4750 (1.4750)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5947  data: 0.5263  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23, Acc@5 = 99.85, loss = 1.4692017337943934\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:15:10 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.81470352564102 train_acc5 99.81470352564102\n",
      "Epoch: [57]  [  0/468]  eta: 0:05:15  lr: 0.01  img/s: 717.7121162090876  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6736  data: 0.4952  max mem: 10434\n",
      "Epoch: [57]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 710.6562006094316  loss: 1.4663 (1.4645)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (99.9536)  time: 0.1801  data: 0.0003  max mem: 10434\n",
      "Epoch: [57]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 703.7607319822772  loss: 1.4637 (1.4656)  acc1: 100.0000 (99.6891)  acc5: 100.0000 (99.9339)  time: 0.1648  data: 0.0003  max mem: 10434\n",
      "Epoch: [57]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.8085371270228  loss: 1.4643 (1.4654)  acc1: 100.0000 (99.7145)  acc5: 100.0000 (99.9481)  time: 0.1802  data: 0.0004  max mem: 10434\n",
      "Epoch: [57]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 712.9958630984397  loss: 1.4631 (1.4649)  acc1: 100.0000 (99.7448)  acc5: 100.0000 (99.9552)  time: 0.1802  data: 0.0004  max mem: 10434\n",
      "Epoch: [57] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4641 (1.4641)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5341  data: 0.4672  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.15, Acc@5 = 99.7, loss = 1.4709520355055603\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:16:39 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73958333333333 train_acc5 99.73958333333333\n",
      "Epoch: [58]  [  0/468]  eta: 0:04:05  lr: 0.01  img/s: 708.3823123094198  loss: 1.4626 (1.4626)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5254  data: 0.3447  max mem: 10434\n",
      "Epoch: [58]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 712.8926659301436  loss: 1.4690 (1.4684)  acc1: 100.0000 (99.6906)  acc5: 100.0000 (99.9613)  time: 0.1801  data: 0.0003  max mem: 10434\n",
      "Epoch: [58]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 712.5652837541178  loss: 1.4694 (1.4680)  acc1: 100.0000 (99.7240)  acc5: 100.0000 (99.9572)  time: 0.1526  data: 0.0003  max mem: 10434\n",
      "Epoch: [58]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 718.6315037064601  loss: 1.4683 (1.4684)  acc1: 99.2188 (99.6885)  acc5: 100.0000 (99.9455)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [58]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 718.3641871567883  loss: 1.4662 (1.4684)  acc1: 99.2188 (99.6396)  acc5: 100.0000 (99.9260)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [58] Total time: 0:01:22\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4730 (1.4730)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3963  data: 0.3299  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.87, Acc@5 = 99.7, loss = 1.473348202584665\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:18:07 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.62439903846153 train_acc5 99.62439903846153\n",
      "Epoch: [59]  [  0/468]  eta: 0:03:47  lr: 0.01  img/s: 704.8537792266276  loss: 1.4705 (1.4705)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4865  data: 0.3048  max mem: 10434\n",
      "Epoch: [59]  [100/468]  eta: 0:01:06  lr: 0.01  img/s: 716.7874220957121  loss: 1.4656 (1.4671)  acc1: 100.0000 (99.6519)  acc5: 100.0000 (99.9691)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [59]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 710.2848199319179  loss: 1.4639 (1.4662)  acc1: 100.0000 (99.6385)  acc5: 100.0000 (99.9495)  time: 0.1550  data: 0.0002  max mem: 10434\n",
      "Epoch: [59]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.4095550567276  loss: 1.4629 (1.4659)  acc1: 100.0000 (99.6704)  acc5: 100.0000 (99.9559)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [59]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.8218016581886  loss: 1.4644 (1.4657)  acc1: 100.0000 (99.6727)  acc5: 100.0000 (99.9552)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [59] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3961  data: 0.3318  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.3, Acc@5 = 99.77, loss = 1.468410230890105\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:19:36 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.67447916666667 train_acc5 99.67447916666667\n",
      "Epoch: [60]  [  0/468]  eta: 0:04:16  lr: 0.01  img/s: 716.7778522468445  loss: 1.4638 (1.4638)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5477  data: 0.3691  max mem: 10434\n",
      "Epoch: [60]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 712.547314829193  loss: 1.4636 (1.4652)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (99.9613)  time: 0.1796  data: 0.0003  max mem: 10434\n",
      "Epoch: [60]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 703.68048108191  loss: 1.4644 (1.4649)  acc1: 100.0000 (99.8057)  acc5: 100.0000 (99.9495)  time: 0.1432  data: 0.0003  max mem: 10434\n",
      "Epoch: [60]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 712.0341646374782  loss: 1.4652 (1.4654)  acc1: 100.0000 (99.7353)  acc5: 100.0000 (99.9351)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [60]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 716.9108960603152  loss: 1.4643 (1.4656)  acc1: 100.0000 (99.7156)  acc5: 100.0000 (99.9377)  time: 0.1796  data: 0.0003  max mem: 10434\n",
      "Epoch: [60] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4749 (1.4749)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4487  data: 0.3813  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.32, Acc@5 = 99.77, loss = 1.4714957445482664\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:21:05 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.6978498931624 train_acc5 99.6978498931624\n",
      "Epoch: [61]  [  0/468]  eta: 0:05:33  lr: 0.01  img/s: 723.1909305946948  loss: 1.4718 (1.4718)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.7116  data: 0.5346  max mem: 10434\n",
      "Epoch: [61]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 716.3704138600967  loss: 1.4676 (1.4689)  acc1: 99.2188 (99.6364)  acc5: 100.0000 (99.9381)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [61]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 710.4615299107409  loss: 1.4639 (1.4688)  acc1: 100.0000 (99.6580)  acc5: 100.0000 (99.9378)  time: 0.1576  data: 0.0002  max mem: 10434\n",
      "Epoch: [61]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.1259180962145  loss: 1.4658 (1.4677)  acc1: 100.0000 (99.6756)  acc5: 100.0000 (99.9533)  time: 0.1803  data: 0.0003  max mem: 10434\n",
      "Epoch: [61]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.2370843661115  loss: 1.4669 (1.4675)  acc1: 100.0000 (99.6727)  acc5: 100.0000 (99.9513)  time: 0.1803  data: 0.0003  max mem: 10434\n",
      "Epoch: [61] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4750 (1.4750)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5816  data: 0.5166  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.85, loss = 1.4694084034690373\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:22:35 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.6761485042735 train_acc5 99.6761485042735\n",
      "Epoch: [62]  [  0/468]  eta: 0:06:21  lr: 0.01  img/s: 701.9562904261259  loss: 1.4662 (1.4662)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.8162  data: 0.6338  max mem: 10434\n",
      "Epoch: [62]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 710.6326839915656  loss: 1.4636 (1.4658)  acc1: 100.0000 (99.7989)  acc5: 100.0000 (99.9613)  time: 0.1802  data: 0.0004  max mem: 10434\n",
      "Epoch: [62]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 703.0833255848978  loss: 1.4638 (1.4651)  acc1: 100.0000 (99.7940)  acc5: 100.0000 (99.9650)  time: 0.1643  data: 0.0004  max mem: 10434\n",
      "Epoch: [62]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.3445153015593  loss: 1.4646 (1.4649)  acc1: 100.0000 (99.8105)  acc5: 100.0000 (99.9611)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [62]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.468949568974  loss: 1.4733 (1.4661)  acc1: 100.0000 (99.7526)  acc5: 100.0000 (99.9571)  time: 0.1802  data: 0.0004  max mem: 10434\n",
      "Epoch: [62] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4734 (1.4734)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6208  data: 0.5573  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19, Acc@5 = 99.79, loss = 1.4698694868932796\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:24:04 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73958333333333 train_acc5 99.73958333333333\n",
      "Epoch: [63]  [  0/468]  eta: 0:05:51  lr: 0.01  img/s: 698.4140913230128  loss: 1.4660 (1.4660)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.7516  data: 0.5683  max mem: 10434\n",
      "Epoch: [63]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 711.26535251871  loss: 1.4639 (1.4660)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9536)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [63]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 701.9682220897271  loss: 1.4650 (1.4654)  acc1: 100.0000 (99.7474)  acc5: 100.0000 (99.9611)  time: 0.1766  data: 0.0003  max mem: 10434\n",
      "Epoch: [63]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 719.3093398716454  loss: 1.4624 (1.4654)  acc1: 100.0000 (99.7404)  acc5: 100.0000 (99.9481)  time: 0.1795  data: 0.0004  max mem: 10434\n",
      "Epoch: [63]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 713.7684228439542  loss: 1.4634 (1.4651)  acc1: 100.0000 (99.7623)  acc5: 100.0000 (99.9474)  time: 0.1792  data: 0.0003  max mem: 10434\n",
      "Epoch: [63] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4714 (1.4714)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6119  data: 0.5437  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.01, Acc@5 = 99.71, loss = 1.4736530041392846\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:25:33 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.74292200854701 train_acc5 99.74292200854701\n",
      "Epoch: [64]  [  0/468]  eta: 0:03:58  lr: 0.01  img/s: 717.8915816667648  loss: 1.4723 (1.4723)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5097  data: 0.3314  max mem: 10434\n",
      "Epoch: [64]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 710.9648828678505  loss: 1.4701 (1.4739)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9226)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [64]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 703.9203657594793  loss: 1.4653 (1.4712)  acc1: 100.0000 (99.7007)  acc5: 100.0000 (99.9300)  time: 0.1688  data: 0.0003  max mem: 10434\n",
      "Epoch: [64]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 718.1806424513372  loss: 1.4672 (1.4693)  acc1: 99.2188 (99.7015)  acc5: 100.0000 (99.9377)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [64]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 718.039444154663  loss: 1.4649 (1.4689)  acc1: 100.0000 (99.6454)  acc5: 100.0000 (99.9260)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [64] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4654 (1.4654)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.4198  data: 0.3521  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.19, Acc@5 = 99.82, loss = 1.4685948875885975\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:27:02 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.66112446581197 train_acc5 99.66112446581197\n",
      "Epoch: [65]  [  0/468]  eta: 0:04:25  lr: 0.01  img/s: 711.3237804886128  loss: 1.4631 (1.4631)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5684  data: 0.3884  max mem: 10434\n",
      "Epoch: [65]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 717.4397305947361  loss: 1.4636 (1.4642)  acc1: 100.0000 (99.8144)  acc5: 100.0000 (99.9613)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [65]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.7377629886917  loss: 1.4650 (1.4655)  acc1: 100.0000 (99.7823)  acc5: 100.0000 (99.9689)  time: 0.1684  data: 0.0003  max mem: 10434\n",
      "Epoch: [65]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 712.4329024090534  loss: 1.4683 (1.4662)  acc1: 100.0000 (99.7716)  acc5: 100.0000 (99.9663)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [65]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.5424993737715  loss: 1.4638 (1.4659)  acc1: 100.0000 (99.7701)  acc5: 100.0000 (99.9630)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [65] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4753 (1.4753)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.6075  data: 0.5437  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.21, Acc@5 = 99.84, loss = 1.4692687173432941\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:28:31 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.76295405982906 train_acc5 99.76295405982906\n",
      "Epoch: [66]  [  0/468]  eta: 0:04:13  lr: 0.01  img/s: 701.838831085471  loss: 1.4728 (1.4728)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5413  data: 0.3589  max mem: 10434\n",
      "Epoch: [66]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.3228380258364  loss: 1.4647 (1.4655)  acc1: 100.0000 (99.7834)  acc5: 100.0000 (99.9304)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [66]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.8736617667728  loss: 1.4706 (1.4670)  acc1: 99.2188 (99.7124)  acc5: 100.0000 (99.9145)  time: 0.1636  data: 0.0002  max mem: 10434\n",
      "Epoch: [66]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.0468039568607  loss: 1.4658 (1.4670)  acc1: 100.0000 (99.6782)  acc5: 100.0000 (99.9247)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [66]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.990727306967  loss: 1.4684 (1.4675)  acc1: 100.0000 (99.6610)  acc5: 100.0000 (99.9240)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [66] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4695 (1.4695)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5863  data: 0.5176  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.12, Acc@5 = 99.82, loss = 1.4695852014082897\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:30:00 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.63441506410257 train_acc5 99.63441506410257\n",
      "Epoch: [67]  [  0/468]  eta: 0:03:57  lr: 0.01  img/s: 707.0398487071361  loss: 1.4654 (1.4654)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5080  data: 0.3269  max mem: 10434\n",
      "Epoch: [67]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.1240342216353  loss: 1.4629 (1.4653)  acc1: 100.0000 (99.8066)  acc5: 100.0000 (99.9768)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [67]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 708.938887186909  loss: 1.4642 (1.4650)  acc1: 100.0000 (99.7629)  acc5: 100.0000 (99.9611)  time: 0.1657  data: 0.0003  max mem: 10434\n",
      "Epoch: [67]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 712.1295565032266  loss: 1.4635 (1.4652)  acc1: 100.0000 (99.7846)  acc5: 100.0000 (99.9611)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [67]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 717.8954214805306  loss: 1.4668 (1.4657)  acc1: 100.0000 (99.7487)  acc5: 100.0000 (99.9493)  time: 0.1787  data: 0.0002  max mem: 10434\n",
      "Epoch: [67] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4657 (1.4657)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.3749  data: 0.3094  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.13, Acc@5 = 99.73, loss = 1.4717891910408116\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:31:29 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73624465811966 train_acc5 99.73624465811966\n",
      "Epoch: [68]  [  0/468]  eta: 0:04:28  lr: 0.01  img/s: 712.7743573199082  loss: 1.4656 (1.4656)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5732  data: 0.3935  max mem: 10434\n",
      "Epoch: [68]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 716.9951507721237  loss: 1.4633 (1.4649)  acc1: 100.0000 (99.7602)  acc5: 100.0000 (99.9381)  time: 0.1785  data: 0.0001  max mem: 10434\n",
      "Epoch: [68]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 707.9684884864821  loss: 1.4662 (1.4651)  acc1: 100.0000 (99.7474)  acc5: 100.0000 (99.9456)  time: 0.1605  data: 0.0002  max mem: 10434\n",
      "Epoch: [68]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.9206345002563  loss: 1.4642 (1.4663)  acc1: 100.0000 (99.7197)  acc5: 100.0000 (99.9533)  time: 0.1803  data: 0.0002  max mem: 10434\n",
      "Epoch: [68]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.2841992021632  loss: 1.4655 (1.4665)  acc1: 99.2188 (99.6824)  acc5: 100.0000 (99.9435)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [68] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4666 (1.4666)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5940  data: 0.5262  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.3, Acc@5 = 99.83, loss = 1.4684830149517785\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:32:58 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.69451121794872 train_acc5 99.69451121794872\n",
      "Epoch: [69]  [  0/468]  eta: 0:05:20  lr: 0.01  img/s: 705.4659980867682  loss: 1.4620 (1.4620)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6844  data: 0.5029  max mem: 10434\n",
      "Epoch: [69]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 711.0835333322738  loss: 1.4629 (1.4644)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (99.9613)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [69]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 711.8566715814709  loss: 1.4646 (1.4649)  acc1: 100.0000 (99.7785)  acc5: 100.0000 (99.9534)  time: 0.1681  data: 0.0002  max mem: 10434\n",
      "Epoch: [69]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.6726632104022  loss: 1.4651 (1.4648)  acc1: 100.0000 (99.7872)  acc5: 100.0000 (99.9481)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [69]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 712.2656049544213  loss: 1.4631 (1.4649)  acc1: 100.0000 (99.7662)  acc5: 100.0000 (99.9513)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [69] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4788 (1.4788)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5544  data: 0.4861  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.02, Acc@5 = 99.76, loss = 1.4748904478700855\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:34:27 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73123664529915 train_acc5 99.73123664529915\n",
      "Epoch: [70]  [  0/468]  eta: 0:04:02  lr: 0.01  img/s: 706.7513111611938  loss: 1.4790 (1.4790)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5180  data: 0.3368  max mem: 10434\n",
      "Epoch: [70]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.0194948296321  loss: 1.4646 (1.4696)  acc1: 100.0000 (99.7061)  acc5: 100.0000 (99.9304)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [70]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 712.5492062522977  loss: 1.4626 (1.4672)  acc1: 100.0000 (99.7512)  acc5: 100.0000 (99.9456)  time: 0.1650  data: 0.0002  max mem: 10434\n",
      "Epoch: [70]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.1475833713057  loss: 1.4615 (1.4660)  acc1: 100.0000 (99.7742)  acc5: 100.0000 (99.9533)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [70]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.2417955688388  loss: 1.4644 (1.4660)  acc1: 100.0000 (99.7428)  acc5: 100.0000 (99.9416)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [70] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4704 (1.4704)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5759  data: 0.5087  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.07, Acc@5 = 99.83, loss = 1.4731103091300288\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:35:56 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.74125267094017 train_acc5 99.74125267094017\n",
      "Epoch: [71]  [  0/468]  eta: 0:04:00  lr: 0.01  img/s: 710.8914524210549  loss: 1.4693 (1.4693)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5141  data: 0.3340  max mem: 10434\n",
      "Epoch: [71]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.5123232553485  loss: 1.4635 (1.4665)  acc1: 100.0000 (99.6906)  acc5: 100.0000 (99.9381)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [71]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 712.4243938623881  loss: 1.4629 (1.4682)  acc1: 100.0000 (99.6269)  acc5: 100.0000 (99.9184)  time: 0.1605  data: 0.0002  max mem: 10434\n",
      "Epoch: [71]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.9761812061162  loss: 1.4623 (1.4696)  acc1: 100.0000 (99.6548)  acc5: 100.0000 (99.9247)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [71]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.9771227505141  loss: 1.4662 (1.4686)  acc1: 100.0000 (99.6435)  acc5: 100.0000 (99.9396)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [71] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4643 (1.4643)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5994  data: 0.5301  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.3, Acc@5 = 99.76, loss = 1.4686908284320106\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:37:25 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.65110844017094 train_acc5 99.65110844017094\n",
      "Epoch: [72]  [  0/468]  eta: 0:03:34  lr: 0.01  img/s: 709.4353967847053  loss: 1.4625 (1.4625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4583  data: 0.2778  max mem: 10434\n",
      "Epoch: [72]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 712.2495409728192  loss: 1.4630 (1.4652)  acc1: 100.0000 (99.7602)  acc5: 100.0000 (99.9768)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [72]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.7792821100248  loss: 1.4642 (1.4652)  acc1: 100.0000 (99.8018)  acc5: 100.0000 (99.9689)  time: 0.1511  data: 0.0002  max mem: 10434\n",
      "Epoch: [72]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 717.4550707671666  loss: 1.4652 (1.4651)  acc1: 100.0000 (99.7846)  acc5: 100.0000 (99.9714)  time: 0.1791  data: 0.0002  max mem: 10434\n",
      "Epoch: [72]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 717.0392008900369  loss: 1.4641 (1.4653)  acc1: 100.0000 (99.7565)  acc5: 100.0000 (99.9591)  time: 0.1787  data: 0.0002  max mem: 10434\n",
      "Epoch: [72] Total time: 0:01:22\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4716 (1.4716)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4155  data: 0.3479  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.17, Acc@5 = 99.76, loss = 1.4694132503074935\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:38:54 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.7646233974359 train_acc5 99.7646233974359\n",
      "Epoch: [73]  [  0/468]  eta: 0:04:25  lr: 0.01  img/s: 708.2748397753029  loss: 1.4683 (1.4683)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5674  data: 0.3866  max mem: 10434\n",
      "Epoch: [73]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.5019508057676  loss: 1.4662 (1.4650)  acc1: 100.0000 (99.7061)  acc5: 100.0000 (99.9613)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [73]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 701.9911687367528  loss: 1.4659 (1.4676)  acc1: 100.0000 (99.7124)  acc5: 100.0000 (99.9534)  time: 0.1517  data: 0.0002  max mem: 10434\n",
      "Epoch: [73]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.9479360337311  loss: 1.4623 (1.4671)  acc1: 100.0000 (99.7145)  acc5: 100.0000 (99.9429)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [73]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 712.0039468030365  loss: 1.4651 (1.4669)  acc1: 100.0000 (99.6844)  acc5: 100.0000 (99.9318)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [73] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5689  data: 0.5001  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.31, Acc@5 = 99.76, loss = 1.468227658090712\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:40:23 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.67447916666667 train_acc5 99.67447916666667\n",
      "Epoch: [74]  [  0/468]  eta: 0:04:18  lr: 0.01  img/s: 703.7182981913893  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5523  data: 0.3704  max mem: 10434\n",
      "Epoch: [74]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.6868143230589  loss: 1.4625 (1.4661)  acc1: 100.0000 (99.7061)  acc5: 100.0000 (99.9768)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [74]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.8510030458986  loss: 1.4637 (1.4656)  acc1: 100.0000 (99.7085)  acc5: 100.0000 (99.9417)  time: 0.1451  data: 0.0002  max mem: 10434\n",
      "Epoch: [74]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.4076696790607  loss: 1.4631 (1.4652)  acc1: 100.0000 (99.7223)  acc5: 100.0000 (99.9455)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [74]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.2276621478941  loss: 1.4629 (1.4649)  acc1: 100.0000 (99.7448)  acc5: 100.0000 (99.9532)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [74] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4700 (1.4700)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5771  data: 0.5121  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.28, Acc@5 = 99.76, loss = 1.4688416659077512\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:41:52 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.7646233974359 train_acc5 99.7646233974359\n",
      "Epoch: [75]  [  0/468]  eta: 0:04:00  lr: 0.01  img/s: 714.515080292476  loss: 1.4621 (1.4621)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5138  data: 0.3346  max mem: 10434\n",
      "Epoch: [75]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.1051960248006  loss: 1.4661 (1.4696)  acc1: 100.0000 (99.6210)  acc5: 100.0000 (99.8840)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [75]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 703.0317671292253  loss: 1.4643 (1.4667)  acc1: 100.0000 (99.7435)  acc5: 100.0000 (99.9300)  time: 0.1451  data: 0.0002  max mem: 10434\n",
      "Epoch: [75]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.7766300822158  loss: 1.4663 (1.4663)  acc1: 100.0000 (99.7690)  acc5: 100.0000 (99.9273)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [75]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.5481576809351  loss: 1.4670 (1.4672)  acc1: 100.0000 (99.7428)  acc5: 100.0000 (99.9357)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [75] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4805 (1.4805)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5932  data: 0.5262  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.36, Acc@5 = 99.84, loss = 1.472737253466739\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:43:21 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.72789797008546 train_acc5 99.72789797008546\n",
      "Epoch: [76]  [  0/468]  eta: 0:04:09  lr: 0.01  img/s: 701.0067310215876  loss: 1.4675 (1.4675)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5338  data: 0.3511  max mem: 10434\n",
      "Epoch: [76]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.7028529310782  loss: 1.4627 (1.4681)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9149)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [76]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.8426746349231  loss: 1.4695 (1.4674)  acc1: 100.0000 (99.7124)  acc5: 100.0000 (99.9378)  time: 0.1447  data: 0.0002  max mem: 10434\n",
      "Epoch: [76]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.8613314972724  loss: 1.4630 (1.4664)  acc1: 100.0000 (99.7612)  acc5: 100.0000 (99.9455)  time: 0.1802  data: 0.0003  max mem: 10434\n",
      "Epoch: [76]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.1541774127103  loss: 1.4634 (1.4664)  acc1: 100.0000 (99.7623)  acc5: 100.0000 (99.9474)  time: 0.1801  data: 0.0003  max mem: 10434\n",
      "Epoch: [76] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4733 (1.4733)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5965  data: 0.5311  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.32, Acc@5 = 99.79, loss = 1.4691940364958365\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:44:50 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.77463942307692 train_acc5 99.77463942307692\n",
      "Epoch: [77]  [  0/468]  eta: 0:04:18  lr: 0.01  img/s: 708.834053340375  loss: 1.4682 (1.4682)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5523  data: 0.3717  max mem: 10434\n",
      "Epoch: [77]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 717.1234857642808  loss: 1.4626 (1.4639)  acc1: 100.0000 (99.8530)  acc5: 100.0000 (99.9768)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [77]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.8093629590732  loss: 1.4629 (1.4639)  acc1: 100.0000 (99.8678)  acc5: 100.0000 (99.9689)  time: 0.1478  data: 0.0002  max mem: 10434\n",
      "Epoch: [77]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.4095550567276  loss: 1.4635 (1.4639)  acc1: 100.0000 (99.8521)  acc5: 100.0000 (99.9585)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [77]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.9968957589499  loss: 1.4884 (1.4655)  acc1: 100.0000 (99.8149)  acc5: 100.0000 (99.9571)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [77] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4693 (1.4693)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5873  data: 0.5223  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.1, Acc@5 = 99.68, loss = 1.4707165367995636\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:46:19 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.78966346153847 train_acc5 99.78966346153847\n",
      "Epoch: [78]  [  0/468]  eta: 0:03:58  lr: 0.01  img/s: 713.3719807276815  loss: 1.4744 (1.4744)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.5098  data: 0.3303  max mem: 10434\n",
      "Epoch: [78]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 710.9573508418329  loss: 1.4620 (1.4660)  acc1: 100.0000 (99.7757)  acc5: 100.0000 (99.9304)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [78]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.3886116140544  loss: 1.4640 (1.4652)  acc1: 100.0000 (99.7979)  acc5: 100.0000 (99.9456)  time: 0.1468  data: 0.0002  max mem: 10434\n",
      "Epoch: [78]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.9705319920967  loss: 1.4632 (1.4655)  acc1: 100.0000 (99.7638)  acc5: 100.0000 (99.9455)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [78]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.9567365710178  loss: 1.4674 (1.4657)  acc1: 100.0000 (99.7370)  acc5: 100.0000 (99.9416)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [78] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4628 (1.4628)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5648  data: 0.5016  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.3, Acc@5 = 99.73, loss = 1.4694341390947752\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:47:48 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.73457532051282 train_acc5 99.73457532051282\n",
      "Epoch: [79]  [  0/468]  eta: 0:04:24  lr: 0.01  img/s: 700.0086211729854  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5654  data: 0.3824  max mem: 10434\n",
      "Epoch: [79]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 710.9554678602643  loss: 1.4676 (1.4694)  acc1: 100.0000 (99.7215)  acc5: 100.0000 (99.9226)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [79]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 713.5796311089194  loss: 1.4645 (1.4686)  acc1: 100.0000 (99.6502)  acc5: 100.0000 (99.9106)  time: 0.1475  data: 0.0002  max mem: 10434\n",
      "Epoch: [79]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.751223593612  loss: 1.4756 (1.4688)  acc1: 100.0000 (99.6730)  acc5: 100.0000 (99.9299)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [79]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.9416306189944  loss: 1.4630 (1.4678)  acc1: 100.0000 (99.7078)  acc5: 100.0000 (99.9377)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [79] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:48  loss: 1.4699 (1.4699)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6080  data: 0.5404  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.78, loss = 1.4696956948388982\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:49:17 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.71955128205128 train_acc5 99.71955128205128\n",
      "Epoch: [80]  [  0/468]  eta: 0:04:00  lr: 0.01  img/s: 713.2288766401898  loss: 1.4634 (1.4634)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5149  data: 0.3353  max mem: 10434\n",
      "Epoch: [80]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 710.4521282297284  loss: 1.4654 (1.4659)  acc1: 100.0000 (99.6674)  acc5: 100.0000 (99.9226)  time: 0.1803  data: 0.0003  max mem: 10434\n",
      "Epoch: [80]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.772353678628  loss: 1.4631 (1.4660)  acc1: 100.0000 (99.6929)  acc5: 100.0000 (99.9262)  time: 0.1444  data: 0.0002  max mem: 10434\n",
      "Epoch: [80]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.303989294752  loss: 1.4708 (1.4664)  acc1: 100.0000 (99.6756)  acc5: 100.0000 (99.9247)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [80]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.9775083017707  loss: 1.4647 (1.4668)  acc1: 100.0000 (99.6435)  acc5: 100.0000 (99.9143)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [80] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4775 (1.4775)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5786  data: 0.5131  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.06, Acc@5 = 99.66, loss = 1.4726281392423413\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:50:46 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.66112446581197 train_acc5 99.66112446581197\n",
      "Epoch: [81]  [  0/468]  eta: 0:05:35  lr: 0.01  img/s: 703.1026619554883  loss: 1.4697 (1.4697)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7162  data: 0.5341  max mem: 10434\n",
      "Epoch: [81]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 712.1229443614687  loss: 1.4742 (1.4706)  acc1: 99.2188 (99.5359)  acc5: 100.0000 (99.9149)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [81]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 704.5864408648155  loss: 1.4654 (1.4689)  acc1: 100.0000 (99.6346)  acc5: 100.0000 (99.9300)  time: 0.1451  data: 0.0002  max mem: 10434\n",
      "Epoch: [81]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.2587564154538  loss: 1.4628 (1.4675)  acc1: 100.0000 (99.6756)  acc5: 100.0000 (99.9325)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [81]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.9727873474427  loss: 1.4635 (1.4668)  acc1: 100.0000 (99.7000)  acc5: 100.0000 (99.9318)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [81] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4763 (1.4763)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.5873  data: 0.5189  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.29, Acc@5 = 99.75, loss = 1.4690086237991913\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:52:16 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.71287393162393 train_acc5 99.71287393162393\n",
      "Epoch: [82]  [  0/468]  eta: 0:03:58  lr: 0.01  img/s: 701.1990016286879  loss: 1.4621 (1.4621)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5106  data: 0.3280  max mem: 10434\n",
      "Epoch: [82]  [100/468]  eta: 0:01:06  lr: 0.01  img/s: 718.2757664788265  loss: 1.4637 (1.4665)  acc1: 100.0000 (99.8530)  acc5: 100.0000 (99.9691)  time: 0.1785  data: 0.0001  max mem: 10434\n",
      "Epoch: [82]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.3737345898217  loss: 1.4635 (1.4651)  acc1: 100.0000 (99.8368)  acc5: 100.0000 (99.9534)  time: 0.1552  data: 0.0001  max mem: 10434\n",
      "Epoch: [82]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 717.3956312528312  loss: 1.4623 (1.4647)  acc1: 100.0000 (99.8650)  acc5: 100.0000 (99.9689)  time: 0.1786  data: 0.0001  max mem: 10434\n",
      "Epoch: [82]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 716.2929955851333  loss: 1.4671 (1.4648)  acc1: 100.0000 (99.8578)  acc5: 100.0000 (99.9747)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [82] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4702 (1.4702)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6034  data: 0.5347  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.29, Acc@5 = 99.69, loss = 1.4689957989922053\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:53:45 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.84809027777777 train_acc5 99.84809027777777\n",
      "Epoch: [83]  [  0/468]  eta: 0:04:11  lr: 0.01  img/s: 706.3942232795099  loss: 1.4616 (1.4616)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5371  data: 0.3558  max mem: 10434\n",
      "Epoch: [83]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 712.2382021279418  loss: 1.4652 (1.4663)  acc1: 100.0000 (99.7602)  acc5: 100.0000 (99.9768)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [83]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 702.4182499954208  loss: 1.4659 (1.4660)  acc1: 100.0000 (99.7357)  acc5: 100.0000 (99.9611)  time: 0.1459  data: 0.0003  max mem: 10434\n",
      "Epoch: [83]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 717.0392008900369  loss: 1.4636 (1.4666)  acc1: 100.0000 (99.7508)  acc5: 100.0000 (99.9559)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [83]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 717.9971915146295  loss: 1.4674 (1.4664)  acc1: 100.0000 (99.7292)  acc5: 100.0000 (99.9435)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [83] Total time: 0:01:22\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4733 (1.4733)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.4391  data: 0.3716  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.11, Acc@5 = 99.79, loss = 1.470353589782232\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:55:13 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.71788194444444 train_acc5 99.71788194444444\n",
      "Epoch: [84]  [  0/468]  eta: 0:04:01  lr: 0.01  img/s: 719.5474633538975  loss: 1.4650 (1.4650)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5157  data: 0.3378  max mem: 10434\n",
      "Epoch: [84]  [100/468]  eta: 0:01:06  lr: 0.01  img/s: 718.3228573913392  loss: 1.4640 (1.4661)  acc1: 100.0000 (99.7293)  acc5: 100.0000 (99.9691)  time: 0.1786  data: 0.0001  max mem: 10434\n",
      "Epoch: [84]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.5328126148257  loss: 1.4685 (1.4659)  acc1: 100.0000 (99.7590)  acc5: 100.0000 (99.9495)  time: 0.1581  data: 0.0001  max mem: 10434\n",
      "Epoch: [84]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.8727178463125  loss: 1.4660 (1.4661)  acc1: 99.2188 (99.7560)  acc5: 100.0000 (99.9533)  time: 0.1801  data: 0.0003  max mem: 10434\n",
      "Epoch: [84]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.588711515929  loss: 1.4720 (1.4672)  acc1: 99.2188 (99.6688)  acc5: 100.0000 (99.9143)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [84] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4722 (1.4722)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.5819  data: 0.5149  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.02, Acc@5 = 99.7, loss = 1.4716802941092961\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:56:42 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.65444711538461 train_acc5 99.65444711538461\n",
      "Epoch: [85]  [  0/468]  eta: 0:05:12  lr: 0.01  img/s: 704.846376126614  loss: 1.4682 (1.4682)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.6685  data: 0.4869  max mem: 10434\n",
      "Epoch: [85]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 711.4010709359227  loss: 1.4662 (1.4667)  acc1: 100.0000 (99.6597)  acc5: 100.0000 (99.9304)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [85]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 701.857181516193  loss: 1.4656 (1.4662)  acc1: 100.0000 (99.6891)  acc5: 100.0000 (99.9378)  time: 0.1450  data: 0.0002  max mem: 10434\n",
      "Epoch: [85]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.157945491274  loss: 1.4721 (1.4698)  acc1: 99.2188 (99.6159)  acc5: 100.0000 (99.9247)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [85]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.0486874222725  loss: 1.4675 (1.4692)  acc1: 100.0000 (99.6065)  acc5: 100.0000 (99.9182)  time: 0.1801  data: 0.0003  max mem: 10434\n",
      "Epoch: [85] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4735 (1.4735)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5505  data: 0.4815  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.8, Acc@5 = 99.56, loss = 1.4747205188002768\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:58:12 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.59768963675214 train_acc5 99.59768963675214\n",
      "Epoch: [86]  [  0/468]  eta: 0:04:55  lr: 0.01  img/s: 696.8204782090653  loss: 1.4733 (1.4733)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6321  data: 0.4484  max mem: 10434\n",
      "Epoch: [86]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 710.5696671299054  loss: 1.4648 (1.4721)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9613)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [86]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.6955718201006  loss: 1.4655 (1.4704)  acc1: 100.0000 (99.6696)  acc5: 100.0000 (99.9534)  time: 0.1469  data: 0.0002  max mem: 10434\n",
      "Epoch: [86]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.2766604089301  loss: 1.4663 (1.4692)  acc1: 100.0000 (99.6859)  acc5: 100.0000 (99.9429)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [86]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.9818305099111  loss: 1.4635 (1.4680)  acc1: 100.0000 (99.7272)  acc5: 100.0000 (99.9532)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [86] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4674 (1.4674)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.6051  data: 0.5378  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.26, Acc@5 = 99.78, loss = 1.4691119510916215\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 1:59:41 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.72288995726495 train_acc5 99.72288995726495\n",
      "Epoch: [87]  [  0/468]  eta: 0:04:01  lr: 0.01  img/s: 719.2544106791421  loss: 1.4612 (1.4612)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5160  data: 0.3380  max mem: 10434\n",
      "Epoch: [87]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.6122914521044  loss: 1.4760 (1.4688)  acc1: 100.0000 (99.6519)  acc5: 100.0000 (99.8917)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [87]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 704.8186158865192  loss: 1.4719 (1.4704)  acc1: 100.0000 (99.6813)  acc5: 100.0000 (99.9067)  time: 0.1468  data: 0.0002  max mem: 10434\n",
      "Epoch: [87]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 710.7945098111903  loss: 1.4676 (1.4707)  acc1: 100.0000 (99.7171)  acc5: 100.0000 (99.9273)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [87]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 712.2712747679918  loss: 1.4674 (1.4697)  acc1: 100.0000 (99.7233)  acc5: 100.0000 (99.9377)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [87] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4718 (1.4718)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5831  data: 0.5154  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.17, Acc@5 = 99.76, loss = 1.4719404042521609\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:01:10 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.71287393162393 train_acc5 99.71287393162393\n",
      "Epoch: [88]  [  0/468]  eta: 0:04:14  lr: 0.01  img/s: 719.3180136689886  loss: 1.4653 (1.4653)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5431  data: 0.3651  max mem: 10434\n",
      "Epoch: [88]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 717.6679833760428  loss: 1.4663 (1.4684)  acc1: 100.0000 (99.6906)  acc5: 100.0000 (99.9691)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [88]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.9038685432563  loss: 1.4675 (1.4670)  acc1: 99.2188 (99.6968)  acc5: 100.0000 (99.9572)  time: 0.1605  data: 0.0002  max mem: 10434\n",
      "Epoch: [88]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 718.0115952650661  loss: 1.4645 (1.4674)  acc1: 100.0000 (99.6756)  acc5: 100.0000 (99.9533)  time: 0.1785  data: 0.0002  max mem: 10434\n",
      "Epoch: [88]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 717.4675351403073  loss: 1.4624 (1.4668)  acc1: 100.0000 (99.6707)  acc5: 100.0000 (99.9552)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [88] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4679 (1.4679)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.3769  data: 0.3110  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18, Acc@5 = 99.77, loss = 1.470305531839781\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:02:39 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.6577857905983 train_acc5 99.6577857905983\n",
      "Epoch: [89]  [  0/468]  eta: 0:04:21  lr: 0.01  img/s: 713.6744888423331  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5590  data: 0.3796  max mem: 10434\n",
      "Epoch: [89]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 719.0723370514428  loss: 1.4668 (1.4745)  acc1: 100.0000 (99.6829)  acc5: 100.0000 (99.9536)  time: 0.1784  data: 0.0002  max mem: 10434\n",
      "Epoch: [89]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 708.1804777476293  loss: 1.4639 (1.4695)  acc1: 100.0000 (99.7668)  acc5: 100.0000 (99.9572)  time: 0.1624  data: 0.0002  max mem: 10434\n",
      "Epoch: [89]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 716.873562236115  loss: 1.4685 (1.4696)  acc1: 100.0000 (99.7353)  acc5: 100.0000 (99.9507)  time: 0.1788  data: 0.0002  max mem: 10434\n",
      "Epoch: [89]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 717.7504969979585  loss: 1.4676 (1.4688)  acc1: 100.0000 (99.7097)  acc5: 100.0000 (99.9493)  time: 0.1787  data: 0.0002  max mem: 10434\n",
      "Epoch: [89] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4623 (1.4623)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4195  data: 0.3527  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.08, Acc@5 = 99.67, loss = 1.4709331370607208\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:04:07 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.7162126068376 train_acc5 99.7162126068376\n",
      "Epoch: [90]  [  0/468]  eta: 0:04:17  lr: 0.01  img/s: 710.5659052827461  loss: 1.4636 (1.4636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5502  data: 0.3700  max mem: 10434\n",
      "Epoch: [90]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 718.4901280879418  loss: 1.4651 (1.4674)  acc1: 100.0000 (99.6519)  acc5: 100.0000 (99.9768)  time: 0.1783  data: 0.0001  max mem: 10434\n",
      "Epoch: [90]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.8170309694972  loss: 1.4692 (1.4683)  acc1: 99.2188 (99.6191)  acc5: 100.0000 (99.9456)  time: 0.1701  data: 0.0002  max mem: 10434\n",
      "Epoch: [90]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 718.0279202142029  loss: 1.4618 (1.4676)  acc1: 100.0000 (99.5925)  acc5: 100.0000 (99.9325)  time: 0.1787  data: 0.0002  max mem: 10434\n",
      "Epoch: [90]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 718.1585465363594  loss: 1.4615 (1.4666)  acc1: 100.0000 (99.6474)  acc5: 100.0000 (99.9416)  time: 0.1787  data: 0.0002  max mem: 10434\n",
      "Epoch: [90] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4635 (1.4635)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5757  data: 0.5119  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.28, Acc@5 = 99.76, loss = 1.4687472446055352\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:05:36 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.66613247863248 train_acc5 99.66613247863248\n",
      "Epoch: [91]  [  0/468]  eta: 0:05:32  lr: 0.01  img/s: 703.9415942013783  loss: 1.4620 (1.4620)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.7111  data: 0.5292  max mem: 10434\n",
      "Epoch: [91]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 710.3590650114982  loss: 1.4640 (1.4643)  acc1: 100.0000 (99.7834)  acc5: 100.0000 (99.9226)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [91]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 710.2275020703413  loss: 1.4646 (1.4664)  acc1: 100.0000 (99.7551)  acc5: 100.0000 (99.9378)  time: 0.1816  data: 0.0002  max mem: 10434\n",
      "Epoch: [91]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.0420953369852  loss: 1.4623 (1.4655)  acc1: 100.0000 (99.7664)  acc5: 100.0000 (99.9455)  time: 0.1803  data: 0.0002  max mem: 10434\n",
      "Epoch: [91]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.2171670469954  loss: 1.4623 (1.4650)  acc1: 100.0000 (99.7721)  acc5: 100.0000 (99.9493)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [91] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4690 (1.4690)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5929  data: 0.5245  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.23, Acc@5 = 99.73, loss = 1.4696584804148614\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:07:06 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.76963141025641 train_acc5 99.76963141025641\n",
      "Epoch: [92]  [  0/468]  eta: 0:05:11  lr: 0.01  img/s: 713.9145915612825  loss: 1.4730 (1.4730)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.6663  data: 0.4870  max mem: 10434\n",
      "Epoch: [92]  [100/468]  eta: 0:01:08  lr: 0.01  img/s: 711.5990864953204  loss: 1.4634 (1.4650)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (99.8994)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [92]  [200/468]  eta: 0:00:48  lr: 0.01  img/s: 711.7906063474638  loss: 1.4639 (1.4648)  acc1: 100.0000 (99.7746)  acc5: 100.0000 (99.9262)  time: 0.1815  data: 0.0002  max mem: 10434\n",
      "Epoch: [92]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 719.2235769144722  loss: 1.4631 (1.4654)  acc1: 100.0000 (99.7508)  acc5: 100.0000 (99.9143)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [92]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 716.5386890462005  loss: 1.4653 (1.4656)  acc1: 100.0000 (99.7311)  acc5: 100.0000 (99.9104)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [92] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4801 (1.4801)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.4204  data: 0.3528  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.05, Acc@5 = 99.68, loss = 1.4711975779714463\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:08:34 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.74125267094017 train_acc5 99.74125267094017\n",
      "Epoch: [93]  [  0/468]  eta: 0:04:09  lr: 0.01  img/s: 713.7238248310647  loss: 1.4675 (1.4675)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5334  data: 0.3540  max mem: 10434\n",
      "Epoch: [93]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.5623038425651  loss: 1.4634 (1.4647)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (99.9845)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [93]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 710.5151242443171  loss: 1.4638 (1.4646)  acc1: 100.0000 (99.7318)  acc5: 100.0000 (99.9611)  time: 0.1813  data: 0.0002  max mem: 10434\n",
      "Epoch: [93]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.2361421330556  loss: 1.4670 (1.4650)  acc1: 100.0000 (99.7275)  acc5: 100.0000 (99.9637)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [93]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.8887648345819  loss: 1.4671 (1.4696)  acc1: 100.0000 (99.7117)  acc5: 100.0000 (99.9571)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [93] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4796 (1.4796)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5911  data: 0.5273  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.07, Acc@5 = 99.78, loss = 1.472781102868575\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:10:04 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.70786591880342 train_acc5 99.70786591880342\n",
      "Epoch: [94]  [  0/468]  eta: 0:04:11  lr: 0.01  img/s: 711.0675226251985  loss: 1.4647 (1.4647)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5376  data: 0.3575  max mem: 10434\n",
      "Epoch: [94]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 716.6601640037964  loss: 1.4624 (1.4654)  acc1: 100.0000 (99.6055)  acc5: 100.0000 (99.9381)  time: 0.1786  data: 0.0002  max mem: 10434\n",
      "Epoch: [94]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 710.1983768660418  loss: 1.4650 (1.4652)  acc1: 100.0000 (99.6424)  acc5: 100.0000 (99.9417)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [94]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 716.5817266430952  loss: 1.4650 (1.4669)  acc1: 100.0000 (99.5977)  acc5: 100.0000 (99.9221)  time: 0.1786  data: 0.0001  max mem: 10434\n",
      "Epoch: [94]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 712.242926602766  loss: 1.4645 (1.4664)  acc1: 100.0000 (99.6240)  acc5: 100.0000 (99.9396)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [94] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4766 (1.4766)  acc1: 98.4375 (98.4375)  acc5: 99.2188 (99.2188)  time: 0.5701  data: 0.5041  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.18, Acc@5 = 99.69, loss = 1.4720733784422089\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:11:33 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.60603632478633 train_acc5 99.60603632478633\n",
      "Epoch: [95]  [  0/468]  eta: 0:04:06  lr: 0.01  img/s: 713.7323644446572  loss: 1.4647 (1.4647)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5259  data: 0.3465  max mem: 10434\n",
      "Epoch: [95]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.1494673706576  loss: 1.4624 (1.4657)  acc1: 100.0000 (99.7679)  acc5: 100.0000 (99.9768)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [95]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 712.0823296129028  loss: 1.4658 (1.4662)  acc1: 100.0000 (99.6774)  acc5: 100.0000 (99.9534)  time: 0.1809  data: 0.0002  max mem: 10434\n",
      "Epoch: [95]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.411440444388  loss: 1.4799 (1.4678)  acc1: 99.2188 (99.6340)  acc5: 100.0000 (99.9429)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [95]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.3218955655574  loss: 1.4657 (1.4705)  acc1: 100.0000 (99.5850)  acc5: 100.0000 (99.9240)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [95] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4740 (1.4740)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5686  data: 0.4995  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.22, Acc@5 = 99.8, loss = 1.4716644860521149\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:13:02 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.59101228632478 train_acc5 99.59101228632478\n",
      "Epoch: [96]  [  0/468]  eta: 0:03:53  lr: 0.01  img/s: 715.2061301375338  loss: 1.4647 (1.4647)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.4979  data: 0.3189  max mem: 10434\n",
      "Epoch: [96]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.9340778833632  loss: 1.4685 (1.4696)  acc1: 99.2188 (99.6597)  acc5: 100.0000 (99.9536)  time: 0.1803  data: 0.0002  max mem: 10434\n",
      "Epoch: [96]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 711.6377595385039  loss: 1.4646 (1.4692)  acc1: 100.0000 (99.6308)  acc5: 100.0000 (99.9417)  time: 0.1809  data: 0.0002  max mem: 10434\n",
      "Epoch: [96]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 712.4366840505859  loss: 1.4641 (1.4682)  acc1: 99.2188 (99.6340)  acc5: 100.0000 (99.9429)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [96]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.8067438282638  loss: 1.4641 (1.4676)  acc1: 100.0000 (99.6298)  acc5: 100.0000 (99.9318)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [96] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4691 (1.4691)  acc1: 99.2188 (99.2188)  acc5: 99.2188 (99.2188)  time: 0.5612  data: 0.4969  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.14, Acc@5 = 99.69, loss = 1.4690299622620209\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:14:31 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.64109241452991 train_acc5 99.64109241452991\n",
      "Epoch: [97]  [  0/468]  eta: 0:04:07  lr: 0.01  img/s: 716.265281998874  loss: 1.4738 (1.4738)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5279  data: 0.3491  max mem: 10434\n",
      "Epoch: [97]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.0364450754515  loss: 1.4682 (1.4666)  acc1: 99.2188 (99.5978)  acc5: 100.0000 (99.9381)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [97]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 710.1438909633956  loss: 1.4652 (1.4667)  acc1: 100.0000 (99.6035)  acc5: 100.0000 (99.9495)  time: 0.1807  data: 0.0002  max mem: 10434\n",
      "Epoch: [97]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.7132312391295  loss: 1.4644 (1.4663)  acc1: 100.0000 (99.6262)  acc5: 100.0000 (99.9533)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [97]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.1852652550815  loss: 1.4629 (1.4660)  acc1: 100.0000 (99.6337)  acc5: 100.0000 (99.9435)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [97] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4703 (1.4703)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5410  data: 0.4722  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.36, Acc@5 = 99.78, loss = 1.4675322574905203\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:16:00 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.65277777777777 train_acc5 99.65277777777777\n",
      "Epoch: [98]  [  0/468]  eta: 0:03:58  lr: 0.01  img/s: 716.9932356723795  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5105  data: 0.3319  max mem: 10434\n",
      "Epoch: [98]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.8462890896917  loss: 1.4628 (1.4639)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (99.9226)  time: 0.1803  data: 0.0002  max mem: 10434\n",
      "Epoch: [98]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 710.4981988444018  loss: 1.4642 (1.4642)  acc1: 100.0000 (99.7862)  acc5: 100.0000 (99.9300)  time: 0.1811  data: 0.0002  max mem: 10434\n",
      "Epoch: [98]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 712.3232522655203  loss: 1.4659 (1.4645)  acc1: 100.0000 (99.7794)  acc5: 100.0000 (99.9325)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [98]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 711.902924542688  loss: 1.4631 (1.4666)  acc1: 100.0000 (99.7526)  acc5: 100.0000 (99.9377)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [98] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4668 (1.4668)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.5945  data: 0.5275  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.03, Acc@5 = 99.84, loss = 1.4699658472326738\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:17:30 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.74626068376068 train_acc5 99.74626068376068\n",
      "Epoch: [99]  [  0/468]  eta: 0:04:15  lr: 0.01  img/s: 708.5636877399567  loss: 1.4613 (1.4613)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5466  data: 0.3659  max mem: 10434\n",
      "Epoch: [99]  [100/468]  eta: 0:01:07  lr: 0.01  img/s: 711.3586533671122  loss: 1.4636 (1.4652)  acc1: 100.0000 (99.7525)  acc5: 100.0000 (99.9613)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [99]  [200/468]  eta: 0:00:47  lr: 0.01  img/s: 709.1177378856343  loss: 1.4655 (1.4649)  acc1: 99.2188 (99.7201)  acc5: 100.0000 (99.9572)  time: 0.1810  data: 0.0002  max mem: 10434\n",
      "Epoch: [99]  [300/468]  eta: 0:00:29  lr: 0.01  img/s: 711.4312376181863  loss: 1.4631 (1.4648)  acc1: 100.0000 (99.7353)  acc5: 100.0000 (99.9533)  time: 0.1801  data: 0.0002  max mem: 10434\n",
      "Epoch: [99]  [400/468]  eta: 0:00:12  lr: 0.01  img/s: 710.469991636406  loss: 1.4672 (1.4650)  acc1: 100.0000 (99.7409)  acc5: 100.0000 (99.9454)  time: 0.1802  data: 0.0002  max mem: 10434\n",
      "Epoch: [99] Total time: 0:01:23\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4720 (1.4720)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5696  data: 0.5005  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.34, Acc@5 = 99.82, loss = 1.4688781922376608\n",
      "Namespace(batch_size=128, cache_dataset=True, data_path='../data', device='cuda:0', distributed=False, epochs=100, lr=0.01, output_dir='./logs', print_freq=100, resume='', start_epoch=0, tb=True, workers=16)\n",
      "./logs/b_128_lr0.01_2025_3_5_3__26\n",
      "Training time 2:18:59 max_test_acc1 99.45 test_acc5_at_max_test_acc1 99.86 train_acc1 99.75293803418803 train_acc5 99.75293803418803\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    save_max = False\n",
    "\n",
    "    train_loss, train_acc1, train_acc5 = train_one_epoch(net, criterion,data_loader, device, epoch, args.print_freq,lr=args.lr)\n",
    "\n",
    "    if utils.is_main_process():\n",
    "        train_tb_writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc1', train_acc1, epoch)\n",
    "        train_tb_writer.add_scalar('train_acc5', train_acc5, epoch)\n",
    "    \n",
    "    test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "    if te_tb_writer is not None:\n",
    "        if utils.is_main_process():\n",
    "            te_tb_writer.add_scalar('test_loss', test_loss, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc1', test_acc1, epoch)\n",
    "            te_tb_writer.add_scalar('test_acc5', test_acc5, epoch)\n",
    "\n",
    "\n",
    "    if max_test_acc1 < test_acc1:\n",
    "        max_test_acc1 = test_acc1\n",
    "        test_acc5_at_max_test_acc1 = test_acc5\n",
    "        save_max = True\n",
    "\n",
    "    if output_dir:\n",
    "\n",
    "        checkpoint = {\n",
    "            'model': net.state_dict(),\n",
    "            'pre-train_epoch': epoch,\n",
    "            'args': args,\n",
    "            'max_test_acc1': max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1': test_acc5_at_max_test_acc1,\n",
    "        }\n",
    "\n",
    "        utils.save_on_master(\n",
    "            checkpoint,\n",
    "            os.path.join(output_dir, 'checkpoint_latest.pth'))\n",
    "        save_flag = False\n",
    "\n",
    "        if epoch % 64 == 0 or epoch == args.epochs - 1:\n",
    "            save_flag = True\n",
    "\n",
    "\n",
    "        if save_flag:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir, f'checkpoint_{epoch}.pth'))\n",
    "\n",
    "        if save_max:\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net,os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_all_pretrain.pth'))\n",
    "            torch.save(net.state_dict(),os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth'))\n",
    "    print(args)\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(output_dir)\n",
    "\n",
    "    print('Training time {}'.format(total_time_str), 'max_test_acc1', max_test_acc1,\n",
    "            'test_acc5_at_max_test_acc1', test_acc5_at_max_test_acc1,'train_acc1', train_acc1,\n",
    "            'train_acc5', train_acc1)\n",
    "\n",
    "    Train_logs= {\n",
    "        'Epoch:': epoch,\n",
    "        'max_test_acc1 ': max_test_acc1 ,\n",
    "        'test_acc5_at_max_test_acc1 ': test_acc5_at_max_test_acc1,\n",
    "        'train_acc1 ': train_acc1,\n",
    "        'train_acc5 ': train_acc1,\n",
    "        'args': args\n",
    "    }\n",
    "    with open(output_dir + '_logs/args.txt', 'a', encoding='utf-8') as args_txt:\n",
    "        args_txt.write('\\n')\n",
    "        args_txt.write(str(Train_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(output_dir,f'train_maxacc1_{max_test_acc1}_checkpoint_max_test_acc1_state_pretrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [ 0/79]  eta: 0:01:02  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.7888  data: 0.3548  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.4317  data: 0.3608  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.4145  data: 0.3489  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.4481  data: 0.3806  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.5567  data: 0.4923  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.4142  data: 0.3481  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.3901  data: 0.3227  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.5418  data: 0.4768  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.5668  data: 0.4989  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4807 (1.4807)  acc1: 97.6562 (97.6562)  acc5: 99.2188 (99.2188)  time: 0.3870  data: 0.3240  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 98.46, Acc@5 = 99.2, loss = 1.4743724261658102\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5548  data: 0.4321  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4391  data: 0.3698  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3694  data: 0.3041  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5193  data: 0.4517  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4211  data: 0.3541  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3995  data: 0.3353  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4333  data: 0.3673  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3781  data: 0.3104  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3734  data: 0.3416  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4746 (1.4746)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4093  data: 0.3772  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.24, Acc@5 = 99.7, loss = 1.469868869721135\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4771  data: 0.3494  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3879  data: 0.3225  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:43  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5492  data: 0.4855  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4183  data: 0.3539  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:38  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4904  data: 0.4240  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3834  data: 0.3156  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:47  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6007  data: 0.5316  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4295  data: 0.3633  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4295  data: 0.3618  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 1.4729 (1.4729)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5104  data: 0.4435  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.37, Acc@5 = 99.75, loss = 1.4684450430206106\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4259  data: 0.3184  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5376  data: 0.4711  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4092  data: 0.3448  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3718  data: 0.3046  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4234  data: 0.3551  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:42  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5333  data: 0.4711  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:49  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.6323  data: 0.5642  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3976  data: 0.3337  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4276  data: 0.3595  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4721 (1.4721)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4217  data: 0.3542  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.41, Acc@5 = 99.77, loss = 1.4676650219325778\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4288  data: 0.3134  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4347  data: 0.3683  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4483  data: 0.3821  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4039  data: 0.3395  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3528  data: 0.2851  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4125  data: 0.3498  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:31  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3925  data: 0.3265  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5715  data: 0.5073  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3902  data: 0.3272  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:37  loss: 1.4718 (1.4718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4795  data: 0.4120  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.39, Acc@5 = 99.8, loss = 1.4671831342238415\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4534  data: 0.3281  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4059  data: 0.3407  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4212  data: 0.3543  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4236  data: 0.3564  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:44  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5578  data: 0.4930  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4077  data: 0.3442  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3768  data: 0.3129  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4083  data: 0.3408  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3718  data: 0.3053  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4717 (1.4717)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4326  data: 0.3641  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.43, Acc@5 = 99.83, loss = 1.4668805146519142\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4432  data: 0.3218  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3753  data: 0.3077  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3838  data: 0.3214  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3710  data: 0.3028  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4154  data: 0.3514  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3488  data: 0.2853  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4171  data: 0.3534  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3696  data: 0.3034  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4154  data: 0.3485  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4365  data: 0.3679  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.43, Acc@5 = 99.86, loss = 1.4667333153229725\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4636  data: 0.3953  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4187  data: 0.3528  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4337  data: 0.3657  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4385  data: 0.3715  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3796  data: 0.3137  max mem: 10434\n",
      "Test: Total time: 0:00:04\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3760  data: 0.3084  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:36  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4625  data: 0.3974  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4181  data: 0.3517  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4273  data: 0.3610  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4062  data: 0.3412  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.86, loss = 1.4666601464718203\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4403  data: 0.3090  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:41  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5248  data: 0.4545  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3750  data: 0.3110  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:46  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5927  data: 0.5238  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:28  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3656  data: 0.2980  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4315  data: 0.3621  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:34  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4347  data: 0.3689  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:30  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3820  data: 0.3172  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:40  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5104  data: 0.4442  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4725 (1.4725)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4153  data: 0.3488  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.47, Acc@5 = 99.88, loss = 1.4666543248333508\n",
      "Test:  [ 0/79]  eta: 0:00:32  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4167  data: 0.3029  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3726  data: 0.3063  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:35  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4521  data: 0.3844  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4259  data: 0.3573  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3739  data: 0.3079  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4259  data: 0.3574  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:45  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.5727  data: 0.5043  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:29  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3698  data: 0.3032  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:33  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.4225  data: 0.3551  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n",
      "Test:  [ 0/79]  eta: 0:00:27  loss: 1.4731 (1.4731)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.3479  data: 0.2832  max mem: 10434\n",
      "Test: Total time: 0:00:05\n",
      " * Acc@1 = 99.45, Acc@5 = 99.88, loss = 1.4667794553539422\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for time in range(1,11):\n",
    "    acc = 0\n",
    "    for i in range(10):\n",
    "        net = NetworkB().to(device)\n",
    "        functional.reset_net(net)\n",
    "        functional.set_step_mode(net,step_mode='m')\n",
    "        functional.set_backend(net, backend='cupy')\n",
    "        weights = torch.load(model_dir)\n",
    "        net.load_state_dict(weights)\n",
    "        net.set_T(time)\n",
    "        test_loss, test_acc1, test_acc5 = evaluate(net, criterion, data_loader_test, device=device, header='Test:')\n",
    "        acc += test_acc1\n",
    "    acc_list.append(acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_snn.txt', 'a') as file:\n",
    "    line = ' '.join(map(str, acc_list))\n",
    "    file.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
